./data/test.lmdb
Start training
=> 2021-11-10 10:21:53.763167: step 100, loss = 7.649316, learning_rate = 0.010000 (2586.0 examples/sec)
=> 2021-11-10 10:22:13.731174: step 200, loss = 7.393344, learning_rate = 0.010000 (2584.3 examples/sec)
=> 2021-11-10 10:22:33.736058: step 300, loss = 7.160275, learning_rate = 0.010000 (2579.6 examples/sec)
=> 2021-11-10 10:22:53.759179: step 400, loss = 6.970935, learning_rate = 0.010000 (2577.4 examples/sec)
=> 2021-11-10 10:23:14.580051: step 500, loss = 6.730523, learning_rate = 0.010000 (2591.8 examples/sec)
=> 2021-11-10 10:23:34.642139: step 600, loss = 6.485803, learning_rate = 0.010000 (2573.5 examples/sec)
=> 2021-11-10 10:23:54.698799: step 700, loss = 6.303766, learning_rate = 0.010000 (2574.1 examples/sec)
=> 2021-11-10 10:24:14.784787: step 800, loss = 6.137797, learning_rate = 0.009000 (2570.2 examples/sec)
=> 2021-11-10 10:24:35.706815: step 900, loss = 5.864630, learning_rate = 0.009000 (2587.3 examples/sec)
=> 2021-11-10 10:24:55.794450: step 1000, loss = 5.665182, learning_rate = 0.009000 (2570.2 examples/sec)
=> Model saved to file: ./logs_res/model-1000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.066269, best accuracy 0.000000
=> Model saved to file: ./logs_res/model-1000.pdparams
=> patience = 100
=> 2021-11-10 10:25:27.920388: step 1100, loss = 5.318555, learning_rate = 0.009000 (2571.6 examples/sec)
=> 2021-11-10 10:25:47.991408: step 1200, loss = 5.213050, learning_rate = 0.009000 (2572.3 examples/sec)
=> 2021-11-10 10:26:08.885083: step 1300, loss = 5.197656, learning_rate = 0.009000 (2586.4 examples/sec)
=> 2021-11-10 10:26:28.974073: step 1400, loss = 4.913242, learning_rate = 0.009000 (2570.2 examples/sec)
=> 2021-11-10 10:26:49.078989: step 1500, loss = 4.679797, learning_rate = 0.009000 (2568.3 examples/sec)
=> 2021-11-10 10:27:09.175423: step 1600, loss = 4.093139, learning_rate = 0.008100 (2569.2 examples/sec)
=> 2021-11-10 10:27:30.083727: step 1700, loss = 4.441728, learning_rate = 0.008100 (2584.8 examples/sec)
=> 2021-11-10 10:27:50.171489: step 1800, loss = 3.944080, learning_rate = 0.008100 (2570.5 examples/sec)
=> 2021-11-10 10:28:10.264948: step 1900, loss = 3.559308, learning_rate = 0.008100 (2569.4 examples/sec)
=> 2021-11-10 10:28:30.385975: step 2000, loss = 3.343247, learning_rate = 0.008100 (2566.0 examples/sec)
=> Model saved to file: ./logs_res/model-2000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.301806, best accuracy 0.066269
=> Model saved to file: ./logs_res/model-2000.pdparams
=> patience = 100
=> 2021-11-10 10:29:03.164402: step 2100, loss = 3.324301, learning_rate = 0.008100 (2593.2 examples/sec)
=> 2021-11-10 10:29:23.209846: step 2200, loss = 3.153177, learning_rate = 0.008100 (2575.6 examples/sec)
=> 2021-11-10 10:29:43.282233: step 2300, loss = 3.141695, learning_rate = 0.008100 (2572.0 examples/sec)
=> 2021-11-10 10:30:03.369791: step 2400, loss = 2.990987, learning_rate = 0.007290 (2570.2 examples/sec)
=> 2021-11-10 10:30:24.405545: step 2500, loss = 2.957595, learning_rate = 0.007290 (2583.4 examples/sec)
=> 2021-11-10 10:30:44.485988: step 2600, loss = 2.671274, learning_rate = 0.007290 (2570.9 examples/sec)
=> 2021-11-10 10:31:04.571199: step 2700, loss = 2.324539, learning_rate = 0.007290 (2569.8 examples/sec)
=> 2021-11-10 10:31:24.656088: step 2800, loss = 2.360450, learning_rate = 0.007290 (2570.7 examples/sec)
=> 2021-11-10 10:31:45.552884: step 2900, loss = 2.544581, learning_rate = 0.007290 (2585.7 examples/sec)
=> 2021-11-10 10:32:05.680655: step 3000, loss = 2.148554, learning_rate = 0.007290 (2565.1 examples/sec)
=> Model saved to file: ./logs_res/model-3000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.567646, best accuracy 0.301806
=> Model saved to file: ./logs_res/model-3000.pdparams
=> patience = 100
=> 2021-11-10 10:32:38.183466: step 3100, loss = 2.170141, learning_rate = 0.007290 (2575.6 examples/sec)
=> 2021-11-10 10:32:58.233822: step 3200, loss = 2.361304, learning_rate = 0.006561 (2574.8 examples/sec)
=> 2021-11-10 10:33:18.443656: step 3300, loss = 2.092367, learning_rate = 0.006561 (2554.4 examples/sec)
=> 2021-11-10 10:33:39.387718: step 3400, loss = 1.861864, learning_rate = 0.006561 (2588.1 examples/sec)
=> 2021-11-10 10:33:59.452935: step 3500, loss = 1.991207, learning_rate = 0.006561 (2573.2 examples/sec)
=> 2021-11-10 10:34:19.515931: step 3600, loss = 1.793471, learning_rate = 0.006561 (2573.3 examples/sec)
=> 2021-11-10 10:34:39.596943: step 3700, loss = 1.886215, learning_rate = 0.006561 (2570.8 examples/sec)
=> 2021-11-10 10:35:00.767534: step 3800, loss = 1.937694, learning_rate = 0.006561 (2579.9 examples/sec)
=> 2021-11-10 10:35:20.849741: step 3900, loss = 1.699541, learning_rate = 0.006561 (2570.8 examples/sec)
=> 2021-11-10 10:35:40.926530: step 4000, loss = 1.658437, learning_rate = 0.005905 (2571.4 examples/sec)
=> Model saved to file: ./logs_res/model-4000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.652893, best accuracy 0.567646
=> Model saved to file: ./logs_res/model-4000.pdparams
=> patience = 100
=> 2021-11-10 10:36:13.373578: step 4100, loss = 1.614248, learning_rate = 0.005905 (2579.9 examples/sec)
=> 2021-11-10 10:36:34.232288: step 4200, loss = 1.724706, learning_rate = 0.005905 (2590.0 examples/sec)
=> 2021-11-10 10:36:54.266071: step 4300, loss = 1.361213, learning_rate = 0.005905 (2577.0 examples/sec)
=> 2021-11-10 10:37:14.307656: step 4400, loss = 1.483763, learning_rate = 0.005905 (2576.0 examples/sec)
=> 2021-11-10 10:37:34.381232: step 4500, loss = 1.695588, learning_rate = 0.005905 (2571.9 examples/sec)
=> 2021-11-10 10:37:55.376570: step 4600, loss = 1.538047, learning_rate = 0.005905 (2584.0 examples/sec)
=> 2021-11-10 10:38:15.468159: step 4700, loss = 1.474349, learning_rate = 0.005905 (2569.7 examples/sec)
=> 2021-11-10 10:38:35.584446: step 4800, loss = 1.466138, learning_rate = 0.005314 (2566.5 examples/sec)
=> 2021-11-10 10:38:55.652929: step 4900, loss = 1.294623, learning_rate = 0.005314 (2572.4 examples/sec)
=> 2021-11-10 10:39:16.559813: step 5000, loss = 1.252943, learning_rate = 0.005314 (2588.2 examples/sec)
=> Model saved to file: ./logs_res/model-5000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.767294, best accuracy 0.652893
=> Model saved to file: ./logs_res/model-5000.pdparams
=> patience = 100
=> 2021-11-10 10:39:48.840969: step 5100, loss = 1.405282, learning_rate = 0.005314 (2580.0 examples/sec)
=> 2021-11-10 10:40:08.872177: step 5200, loss = 1.386667, learning_rate = 0.005314 (2577.3 examples/sec)
=> 2021-11-10 10:40:28.908718: step 5300, loss = 1.185739, learning_rate = 0.005314 (2576.8 examples/sec)
=> 2021-11-10 10:40:49.841322: step 5400, loss = 1.441129, learning_rate = 0.005314 (2604.3 examples/sec)
=> 2021-11-10 10:41:09.915676: step 5500, loss = 1.212965, learning_rate = 0.005314 (2571.6 examples/sec)
=> 2021-11-10 10:41:29.994173: step 5600, loss = 1.294711, learning_rate = 0.004783 (2571.2 examples/sec)
=> 2021-11-10 10:41:50.061273: step 5700, loss = 1.252135, learning_rate = 0.004783 (2572.7 examples/sec)
=> 2021-11-10 10:42:11.044260: step 5800, loss = 1.314224, learning_rate = 0.004783 (2587.2 examples/sec)
=> 2021-11-10 10:42:31.099808: step 5900, loss = 1.431547, learning_rate = 0.004783 (2574.0 examples/sec)
=> 2021-11-10 10:42:51.149616: step 6000, loss = 1.158359, learning_rate = 0.004783 (2575.1 examples/sec)
=> Model saved to file: ./logs_res/model-6000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.778007, best accuracy 0.767294
=> Model saved to file: ./logs_res/model-6000.pdparams
=> patience = 100
=> 2021-11-10 10:43:23.235900: step 6100, loss = 1.065421, learning_rate = 0.004783 (2574.5 examples/sec)
=> 2021-11-10 10:43:43.271299: step 6200, loss = 1.049866, learning_rate = 0.004783 (2576.9 examples/sec)
=> 2021-11-10 10:44:04.180392: step 6300, loss = 1.098841, learning_rate = 0.004783 (2584.8 examples/sec)
=> 2021-11-10 10:44:24.242923: step 6400, loss = 1.276344, learning_rate = 0.004305 (2573.8 examples/sec)
=> 2021-11-10 10:44:44.337043: step 6500, loss = 1.032394, learning_rate = 0.004305 (2569.6 examples/sec)
=> 2021-11-10 10:45:04.430532: step 6600, loss = 1.140003, learning_rate = 0.004305 (2569.5 examples/sec)
=> 2021-11-10 10:45:25.332881: step 6700, loss = 1.089589, learning_rate = 0.004305 (2589.3 examples/sec)
=> 2021-11-10 10:45:45.377723: step 6800, loss = 1.168347, learning_rate = 0.004305 (2575.7 examples/sec)
=> 2021-11-10 10:46:05.465581: step 6900, loss = 1.119664, learning_rate = 0.004305 (2570.2 examples/sec)
=> 2021-11-10 10:46:25.525105: step 7000, loss = 0.961880, learning_rate = 0.004305 (2573.7 examples/sec)
=> Model saved to file: ./logs_res/model-7000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.815350, best accuracy 0.778007
=> Model saved to file: ./logs_res/model-7000.pdparams
=> patience = 100
=> 2021-11-10 10:46:58.848303: step 7100, loss = 1.217056, learning_rate = 0.004305 (2595.1 examples/sec)
=> 2021-11-10 10:47:18.898752: step 7200, loss = 1.142689, learning_rate = 0.003874 (2574.8 examples/sec)
=> 2021-11-10 10:47:38.946934: step 7300, loss = 1.092076, learning_rate = 0.003874 (2575.2 examples/sec)
=> 2021-11-10 10:47:58.985723: step 7400, loss = 1.191322, learning_rate = 0.003874 (2576.4 examples/sec)
=> 2021-11-10 10:48:19.871945: step 7500, loss = 1.058044, learning_rate = 0.003874 (2587.8 examples/sec)
=> 2021-11-10 10:48:39.923547: step 7600, loss = 0.779339, learning_rate = 0.003874 (2574.7 examples/sec)
=> 2021-11-10 10:48:59.967269: step 7700, loss = 0.926568, learning_rate = 0.003874 (2575.8 examples/sec)
=> 2021-11-10 10:49:20.003984: step 7800, loss = 0.894609, learning_rate = 0.003874 (2576.7 examples/sec)
=> 2021-11-10 10:49:40.852566: step 7900, loss = 0.970103, learning_rate = 0.003874 (2596.9 examples/sec)
=> 2021-11-10 10:50:00.899346: step 8000, loss = 0.978235, learning_rate = 0.003487 (2575.3 examples/sec)
=> Model saved to file: ./logs_res/model-8000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.838843, best accuracy 0.815350
=> Model saved to file: ./logs_res/model-8000.pdparams
=> patience = 100
=> 2021-11-10 10:50:33.247777: step 8100, loss = 0.978403, learning_rate = 0.003487 (2576.8 examples/sec)
=> 2021-11-10 10:50:53.274324: step 8200, loss = 0.973930, learning_rate = 0.003487 (2578.0 examples/sec)
=> 2021-11-10 10:51:14.351506: step 8300, loss = 1.123869, learning_rate = 0.003487 (2591.0 examples/sec)
=> 2021-11-10 10:51:34.386100: step 8400, loss = 0.922977, learning_rate = 0.003487 (2576.9 examples/sec)
=> 2021-11-10 10:51:54.475221: step 8500, loss = 0.875864, learning_rate = 0.003487 (2569.9 examples/sec)
=> 2021-11-10 10:52:14.537908: step 8600, loss = 0.834960, learning_rate = 0.003487 (2573.6 examples/sec)
=> 2021-11-10 10:52:35.405805: step 8700, loss = 1.112554, learning_rate = 0.003487 (2593.0 examples/sec)
=> 2021-11-10 10:52:55.474292: step 8800, loss = 0.779949, learning_rate = 0.003138 (2572.5 examples/sec)
=> 2021-11-10 10:53:15.517592: step 8900, loss = 0.824582, learning_rate = 0.003138 (2575.9 examples/sec)
=> 2021-11-10 10:53:35.582626: step 9000, loss = 0.857952, learning_rate = 0.003138 (2572.9 examples/sec)
=> Model saved to file: ./logs_res/model-9000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.861264, best accuracy 0.838843
=> Model saved to file: ./logs_res/model-9000.pdparams
=> patience = 100
=> 2021-11-10 10:54:07.772744: step 9100, loss = 0.868196, learning_rate = 0.003138 (2581.6 examples/sec)
=> 2021-11-10 10:54:28.635706: step 9200, loss = 1.000291, learning_rate = 0.003138 (2595.3 examples/sec)
=> 2021-11-10 10:54:48.703384: step 9300, loss = 0.803108, learning_rate = 0.003138 (2572.5 examples/sec)
=> 2021-11-10 10:55:08.732409: step 9400, loss = 0.920233, learning_rate = 0.003138 (2577.6 examples/sec)
=> 2021-11-10 10:55:28.806220: step 9500, loss = 1.081248, learning_rate = 0.003138 (2572.1 examples/sec)
=> 2021-11-10 10:55:49.758491: step 9600, loss = 0.998289, learning_rate = 0.002824 (2587.8 examples/sec)
=> 2021-11-10 10:56:09.838141: step 9700, loss = 0.704685, learning_rate = 0.002824 (2571.2 examples/sec)
=> 2021-11-10 10:56:29.905682: step 9800, loss = 0.694799, learning_rate = 0.002824 (2573.1 examples/sec)
=> 2021-11-10 10:56:49.957381: step 9900, loss = 0.741035, learning_rate = 0.002824 (2574.8 examples/sec)
=> 2021-11-10 10:57:10.835878: step 10000, loss = 0.871504, learning_rate = 0.002824 (2589.5 examples/sec)
=> Model saved to file: ./logs_res/model-10000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.863407, best accuracy 0.861264
=> Model saved to file: ./logs_res/model-10000.pdparams
=> patience = 100
=> 2021-11-10 10:57:43.393649: step 10100, loss = 0.862913, learning_rate = 0.002824 (2577.3 examples/sec)
=> 2021-11-10 10:58:03.440671: step 10200, loss = 0.786061, learning_rate = 0.002824 (2575.6 examples/sec)
=> 2021-11-10 10:58:23.474186: step 10300, loss = 0.799725, learning_rate = 0.002824 (2577.1 examples/sec)
=> 2021-11-10 10:58:44.519560: step 10400, loss = 0.923802, learning_rate = 0.002542 (2584.0 examples/sec)
=> 2021-11-10 10:59:04.554200: step 10500, loss = 0.729589, learning_rate = 0.002542 (2576.8 examples/sec)
=> 2021-11-10 10:59:24.584124: step 10600, loss = 0.851086, learning_rate = 0.002542 (2577.4 examples/sec)
=> 2021-11-10 10:59:44.679575: step 10700, loss = 0.693824, learning_rate = 0.002542 (2569.0 examples/sec)
=> 2021-11-10 11:00:05.539993: step 10800, loss = 0.792153, learning_rate = 0.002542 (2591.2 examples/sec)
=> 2021-11-10 11:00:25.573236: step 10900, loss = 0.851453, learning_rate = 0.002542 (2577.0 examples/sec)
=> 2021-11-10 11:00:45.637722: step 11000, loss = 0.781806, learning_rate = 0.002542 (2573.0 examples/sec)
=> Model saved to file: ./logs_res/model-11000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.867156, best accuracy 0.863407
=> Model saved to file: ./logs_res/model-11000.pdparams
=> patience = 100
=> 2021-11-10 11:01:17.810183: step 11100, loss = 0.688582, learning_rate = 0.002542 (2578.8 examples/sec)
=> 2021-11-10 11:01:38.659352: step 11200, loss = 0.717491, learning_rate = 0.002288 (2593.5 examples/sec)
=> 2021-11-10 11:01:58.688987: step 11300, loss = 0.818573, learning_rate = 0.002288 (2577.6 examples/sec)
=> 2021-11-10 11:02:18.722153: step 11400, loss = 0.655201, learning_rate = 0.002288 (2577.2 examples/sec)
=> 2021-11-10 11:02:38.760522: step 11500, loss = 0.770442, learning_rate = 0.002288 (2576.6 examples/sec)
=> 2021-11-10 11:02:59.605819: step 11600, loss = 0.690204, learning_rate = 0.002288 (2592.7 examples/sec)
=> 2021-11-10 11:03:19.669985: step 11700, loss = 0.776562, learning_rate = 0.002288 (2573.3 examples/sec)
=> 2021-11-10 11:03:39.758557: step 11800, loss = 0.707553, learning_rate = 0.002288 (2570.1 examples/sec)
=> 2021-11-10 11:03:59.837960: step 11900, loss = 0.661400, learning_rate = 0.002288 (2571.4 examples/sec)
=> 2021-11-10 11:04:19.907730: step 12000, loss = 0.573708, learning_rate = 0.002059 (2573.2 examples/sec)
=> Model saved to file: ./logs_res/model-12000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.879936, best accuracy 0.867156
=> Model saved to file: ./logs_res/model-12000.pdparams
=> patience = 100
=> 2021-11-10 11:04:53.244872: step 12100, loss = 0.757211, learning_rate = 0.002059 (2593.6 examples/sec)
=> 2021-11-10 11:05:13.262710: step 12200, loss = 0.660970, learning_rate = 0.002059 (2579.0 examples/sec)
=> 2021-11-10 11:05:33.311094: step 12300, loss = 0.768649, learning_rate = 0.002059 (2575.1 examples/sec)
=> 2021-11-10 11:05:53.342308: step 12400, loss = 0.669656, learning_rate = 0.002059 (2577.3 examples/sec)
=> 2021-11-10 11:06:14.264530: step 12500, loss = 0.666336, learning_rate = 0.002059 (2590.4 examples/sec)
=> 2021-11-10 11:06:34.316763: step 12600, loss = 0.813518, learning_rate = 0.002059 (2574.6 examples/sec)
=> 2021-11-10 11:06:54.349772: step 12700, loss = 0.642213, learning_rate = 0.002059 (2577.0 examples/sec)
=> 2021-11-10 11:07:14.387065: step 12800, loss = 0.722233, learning_rate = 0.001853 (2576.6 examples/sec)
=> 2021-11-10 11:07:35.267550: step 12900, loss = 0.812447, learning_rate = 0.001853 (2589.9 examples/sec)
=> 2021-11-10 11:07:55.299180: step 13000, loss = 0.691279, learning_rate = 0.001853 (2577.3 examples/sec)
=> Model saved to file: ./logs_res/model-13000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.886364, best accuracy 0.879936
=> Model saved to file: ./logs_res/model-13000.pdparams
=> patience = 100
=> 2021-11-10 11:08:27.869354: step 13100, loss = 0.726235, learning_rate = 0.001853 (2576.0 examples/sec)
=> 2021-11-10 11:08:47.913978: step 13200, loss = 0.638028, learning_rate = 0.001853 (2576.0 examples/sec)
=> 2021-11-10 11:09:08.786322: step 13300, loss = 0.826968, learning_rate = 0.001853 (2591.0 examples/sec)
=> 2021-11-10 11:09:28.812843: step 13400, loss = 0.805185, learning_rate = 0.001853 (2577.5 examples/sec)
=> 2021-11-10 11:09:48.855534: step 13500, loss = 0.633026, learning_rate = 0.001853 (2575.7 examples/sec)
=> 2021-11-10 11:10:08.917505: step 13600, loss = 0.737754, learning_rate = 0.001668 (2573.3 examples/sec)
=> 2021-11-10 11:10:29.787610: step 13700, loss = 0.645611, learning_rate = 0.001668 (2592.9 examples/sec)
=> 2021-11-10 11:10:49.832101: step 13800, loss = 0.619538, learning_rate = 0.001668 (2575.7 examples/sec)
=> 2021-11-10 11:11:09.893118: step 13900, loss = 0.702913, learning_rate = 0.001668 (2573.4 examples/sec)
=> 2021-11-10 11:11:29.926905: step 14000, loss = 0.649599, learning_rate = 0.001668 (2577.0 examples/sec)
=> Model saved to file: ./logs_res/model-14000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.891720, best accuracy 0.886364
=> Model saved to file: ./logs_res/model-14000.pdparams
=> patience = 100
=> 2021-11-10 11:12:03.246414: step 14100, loss = 0.706168, learning_rate = 0.001668 (2597.1 examples/sec)
=> 2021-11-10 11:12:23.268479: step 14200, loss = 0.711776, learning_rate = 0.001668 (2578.7 examples/sec)
=> 2021-11-10 11:12:43.314580: step 14300, loss = 0.579168, learning_rate = 0.001668 (2575.5 examples/sec)
=> 2021-11-10 11:13:03.357087: step 14400, loss = 0.639374, learning_rate = 0.001501 (2575.9 examples/sec)
=> 2021-11-10 11:13:24.303665: step 14500, loss = 0.638643, learning_rate = 0.001501 (2592.3 examples/sec)
=> 2021-11-10 11:13:44.330319: step 14600, loss = 0.679347, learning_rate = 0.001501 (2577.9 examples/sec)
=> 2021-11-10 11:14:04.380799: step 14700, loss = 0.682845, learning_rate = 0.001501 (2574.8 examples/sec)
=> 2021-11-10 11:14:24.429364: step 14800, loss = 0.866130, learning_rate = 0.001501 (2575.1 examples/sec)
=> 2021-11-10 11:14:44.461218: step 14900, loss = 0.681200, learning_rate = 0.001501 (2577.6 examples/sec)
=> 2021-11-10 11:15:05.354024: step 15000, loss = 0.753320, learning_rate = 0.001501 (2590.0 examples/sec)
=> Model saved to file: ./logs_res/model-15000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.894169, best accuracy 0.891720
=> Model saved to file: ./logs_res/model-15000.pdparams
=> patience = 100
=> 2021-11-10 11:15:37.671173: step 15100, loss = 0.704482, learning_rate = 0.001501 (2581.7 examples/sec)
=> 2021-11-10 11:15:57.692492: step 15200, loss = 0.581486, learning_rate = 0.001351 (2578.6 examples/sec)
=> 2021-11-10 11:16:17.725153: step 15300, loss = 0.770299, learning_rate = 0.001351 (2577.2 examples/sec)
=> 2021-11-10 11:16:38.778827: step 15400, loss = 0.712015, learning_rate = 0.001351 (2593.1 examples/sec)
=> 2021-11-10 11:16:58.804783: step 15500, loss = 0.655312, learning_rate = 0.001351 (2578.1 examples/sec)
=> 2021-11-10 11:17:18.821044: step 15600, loss = 0.635680, learning_rate = 0.001351 (2579.0 examples/sec)
=> 2021-11-10 11:17:38.860878: step 15700, loss = 0.564330, learning_rate = 0.001351 (2576.3 examples/sec)
=> 2021-11-10 11:17:59.696912: step 15800, loss = 0.551582, learning_rate = 0.001351 (2594.3 examples/sec)
=> 2021-11-10 11:18:19.727076: step 15900, loss = 0.495007, learning_rate = 0.001351 (2578.1 examples/sec)
=> 2021-11-10 11:18:39.779233: step 16000, loss = 0.697457, learning_rate = 0.001216 (2576.3 examples/sec)
=> Model saved to file: ./logs_res/model-16000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.901209, best accuracy 0.894169
=> Model saved to file: ./logs_res/model-16000.pdparams
=> patience = 100
=> 2021-11-10 11:19:12.141966: step 16100, loss = 0.641683, learning_rate = 0.001216 (2579.1 examples/sec)
=> 2021-11-10 11:19:33.006645: step 16200, loss = 0.636705, learning_rate = 0.001216 (2595.1 examples/sec)
=> 2021-11-10 11:19:53.019990: step 16300, loss = 0.585608, learning_rate = 0.001216 (2579.8 examples/sec)
=> 2021-11-10 11:20:13.058806: step 16400, loss = 0.400568, learning_rate = 0.001216 (2576.3 examples/sec)
=> 2021-11-10 11:20:33.098098: step 16500, loss = 0.807550, learning_rate = 0.001216 (2576.6 examples/sec)
=> 2021-11-10 11:20:54.015783: step 16600, loss = 0.556724, learning_rate = 0.001216 (2583.2 examples/sec)
=> 2021-11-10 11:21:14.055475: step 16700, loss = 0.625477, learning_rate = 0.001216 (2576.3 examples/sec)
=> 2021-11-10 11:21:34.123233: step 16800, loss = 0.580586, learning_rate = 0.001094 (2572.5 examples/sec)
=> 2021-11-10 11:21:54.172655: step 16900, loss = 0.402799, learning_rate = 0.001094 (2575.1 examples/sec)
=> 2021-11-10 11:22:15.088852: step 17000, loss = 0.606579, learning_rate = 0.001094 (2591.1 examples/sec)
=> Model saved to file: ./logs_res/model-17000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.908555, best accuracy 0.901209
=> Model saved to file: ./logs_res/model-17000.pdparams
=> patience = 100
=> 2021-11-10 11:22:47.286807: step 17100, loss = 0.630967, learning_rate = 0.001094 (2581.2 examples/sec)
=> 2021-11-10 11:23:07.304660: step 17200, loss = 0.572548, learning_rate = 0.001094 (2579.3 examples/sec)
=> 2021-11-10 11:23:27.308700: step 17300, loss = 0.610234, learning_rate = 0.001094 (2580.9 examples/sec)
=> 2021-11-10 11:23:48.211444: step 17400, loss = 0.597570, learning_rate = 0.001094 (2590.7 examples/sec)
=> 2021-11-10 11:24:08.250969: step 17500, loss = 0.641636, learning_rate = 0.001094 (2576.4 examples/sec)
=> 2021-11-10 11:24:28.287324: step 17600, loss = 0.713252, learning_rate = 0.000985 (2576.8 examples/sec)
=> 2021-11-10 11:24:48.319451: step 17700, loss = 0.440078, learning_rate = 0.000985 (2577.2 examples/sec)
=> 2021-11-10 11:25:08.423018: step 17800, loss = 0.439468, learning_rate = 0.000985 (2568.6 examples/sec)
=> 2021-11-10 11:25:29.324552: step 17900, loss = 0.669940, learning_rate = 0.000985 (2589.3 examples/sec)
=> 2021-11-10 11:25:49.390504: step 18000, loss = 0.634777, learning_rate = 0.000985 (2572.8 examples/sec)
=> Model saved to file: ./logs_res/model-18000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.910162, best accuracy 0.908555
=> Model saved to file: ./logs_res/model-18000.pdparams
=> patience = 100
=> 2021-11-10 11:26:21.780865: step 18100, loss = 0.547994, learning_rate = 0.000985 (2578.0 examples/sec)
=> 2021-11-10 11:26:41.845386: step 18200, loss = 0.556570, learning_rate = 0.000985 (2573.2 examples/sec)
=> 2021-11-10 11:27:02.783650: step 18300, loss = 0.540489, learning_rate = 0.000985 (2582.3 examples/sec)
=> 2021-11-10 11:27:22.840148: step 18400, loss = 0.645828, learning_rate = 0.000886 (2574.3 examples/sec)
=> 2021-11-10 11:27:42.893514: step 18500, loss = 0.464579, learning_rate = 0.000886 (2574.6 examples/sec)
=> 2021-11-10 11:28:02.964085: step 18600, loss = 0.494783, learning_rate = 0.000886 (2572.9 examples/sec)
=> 2021-11-10 11:28:23.873359: step 18700, loss = 0.586077, learning_rate = 0.000886 (2588.6 examples/sec)
=> 2021-11-10 11:28:43.918805: step 18800, loss = 0.678277, learning_rate = 0.000886 (2575.5 examples/sec)
=> 2021-11-10 11:29:03.973926: step 18900, loss = 0.507562, learning_rate = 0.000886 (2574.5 examples/sec)
=> 2021-11-10 11:29:24.036975: step 19000, loss = 0.460637, learning_rate = 0.000886 (2573.5 examples/sec)
=> Model saved to file: ./logs_res/model-19000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.909933, best accuracy 0.910162
=> patience = 99
=> 2021-11-10 11:29:56.442830: step 19100, loss = 0.532112, learning_rate = 0.000886 (2600.2 examples/sec)
=> 2021-11-10 11:30:16.454930: step 19200, loss = 0.422991, learning_rate = 0.000798 (2579.9 examples/sec)
=> 2021-11-10 11:30:36.489998: step 19300, loss = 0.468822, learning_rate = 0.000798 (2576.8 examples/sec)
=> 2021-11-10 11:30:56.513650: step 19400, loss = 0.655338, learning_rate = 0.000798 (2578.5 examples/sec)
=> 2021-11-10 11:31:17.364223: step 19500, loss = 0.475684, learning_rate = 0.000798 (2593.5 examples/sec)
=> 2021-11-10 11:31:37.405917: step 19600, loss = 0.458001, learning_rate = 0.000798 (2576.0 examples/sec)
=> 2021-11-10 11:31:57.456517: step 19700, loss = 0.550461, learning_rate = 0.000798 (2575.1 examples/sec)
=> 2021-11-10 11:32:17.493085: step 19800, loss = 0.467019, learning_rate = 0.000798 (2576.6 examples/sec)
=> 2021-11-10 11:32:38.351811: step 19900, loss = 0.450962, learning_rate = 0.000798 (2592.6 examples/sec)
=> 2021-11-10 11:32:58.381704: step 20000, loss = 0.545577, learning_rate = 0.000718 (2577.7 examples/sec)
=> Model saved to file: ./logs_res/model-20000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.911004, best accuracy 0.910162
=> Model saved to file: ./logs_res/model-20000.pdparams
=> patience = 100
=> 2021-11-10 11:33:30.615796: step 20100, loss = 0.604552, learning_rate = 0.000718 (2581.4 examples/sec)
=> 2021-11-10 11:33:50.631698: step 20200, loss = 0.537062, learning_rate = 0.000718 (2579.4 examples/sec)
=> 2021-11-10 11:34:11.711667: step 20300, loss = 0.479913, learning_rate = 0.000718 (2590.9 examples/sec)
=> 2021-11-10 11:34:31.743006: step 20400, loss = 0.420775, learning_rate = 0.000718 (2577.4 examples/sec)
=> 2021-11-10 11:34:51.793794: step 20500, loss = 0.594774, learning_rate = 0.000718 (2574.6 examples/sec)
=> 2021-11-10 11:35:11.814081: step 20600, loss = 0.623641, learning_rate = 0.000718 (2578.8 examples/sec)
=> 2021-11-10 11:35:31.842054: step 20700, loss = 0.643461, learning_rate = 0.000718 (2578.3 examples/sec)
=> 2021-11-10 11:35:52.831038: step 20800, loss = 0.521653, learning_rate = 0.000646 (2575.1 examples/sec)
=> 2021-11-10 11:36:12.853758: step 20900, loss = 0.535576, learning_rate = 0.000646 (2578.5 examples/sec)
=> 2021-11-10 11:36:32.899678: step 21000, loss = 0.478432, learning_rate = 0.000646 (2575.3 examples/sec)
=> Model saved to file: ./logs_res/model-21000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.915978, best accuracy 0.911004
=> Model saved to file: ./logs_res/model-21000.pdparams
=> patience = 100
=> 2021-11-10 11:37:05.111442: step 21100, loss = 0.608379, learning_rate = 0.000646 (2580.9 examples/sec)
=> 2021-11-10 11:37:25.940998: step 21200, loss = 0.579338, learning_rate = 0.000646 (2595.7 examples/sec)
=> 2021-11-10 11:37:45.956091: step 21300, loss = 0.465045, learning_rate = 0.000646 (2579.4 examples/sec)
=> 2021-11-10 11:38:05.971135: step 21400, loss = 0.498818, learning_rate = 0.000646 (2579.5 examples/sec)
=> 2021-11-10 11:38:26.001589: step 21500, loss = 0.545390, learning_rate = 0.000646 (2577.4 examples/sec)
=> 2021-11-10 11:38:46.867562: step 21600, loss = 0.498599, learning_rate = 0.000581 (2605.8 examples/sec)
=> 2021-11-10 11:39:06.931676: step 21700, loss = 0.501724, learning_rate = 0.000581 (2573.1 examples/sec)
=> 2021-11-10 11:39:26.972004: step 21800, loss = 0.447841, learning_rate = 0.000581 (2576.5 examples/sec)
=> 2021-11-10 11:39:47.009976: step 21900, loss = 0.542858, learning_rate = 0.000581 (2576.5 examples/sec)
=> 2021-11-10 11:40:07.876167: step 22000, loss = 0.561214, learning_rate = 0.000581 (2592.2 examples/sec)
=> Model saved to file: ./logs_res/model-22000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.912228, best accuracy 0.915978
=> patience = 99
=> 2021-11-10 11:40:39.527848: step 22100, loss = 0.536041, learning_rate = 0.000581 (2580.7 examples/sec)
=> 2021-11-10 11:40:59.539098: step 22200, loss = 0.389008, learning_rate = 0.000581 (2580.0 examples/sec)
=> 2021-11-10 11:41:19.554159: step 22300, loss = 0.714976, learning_rate = 0.000581 (2579.3 examples/sec)
=> 2021-11-10 11:41:40.644822: step 22400, loss = 0.493958, learning_rate = 0.000523 (2590.9 examples/sec)
=> 2021-11-10 11:42:00.673553: step 22500, loss = 0.484022, learning_rate = 0.000523 (2577.9 examples/sec)
=> 2021-11-10 11:42:20.694052: step 22600, loss = 0.444002, learning_rate = 0.000523 (2578.7 examples/sec)
=> 2021-11-10 11:42:40.728612: step 22700, loss = 0.511344, learning_rate = 0.000523 (2577.1 examples/sec)
=> 2021-11-10 11:43:01.745613: step 22800, loss = 0.433701, learning_rate = 0.000523 (2590.4 examples/sec)
=> 2021-11-10 11:43:21.777975: step 22900, loss = 0.528450, learning_rate = 0.000523 (2577.3 examples/sec)
=> 2021-11-10 11:43:41.821264: step 23000, loss = 0.357935, learning_rate = 0.000523 (2575.7 examples/sec)
=> Model saved to file: ./logs_res/model-23000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.916054, best accuracy 0.915978
=> Model saved to file: ./logs_res/model-23000.pdparams
=> patience = 100
=> 2021-11-10 11:44:13.956645: step 23100, loss = 0.495477, learning_rate = 0.000523 (2582.7 examples/sec)
=> 2021-11-10 11:44:34.772508: step 23200, loss = 0.598215, learning_rate = 0.000471 (2596.9 examples/sec)
=> 2021-11-10 11:44:54.793558: step 23300, loss = 0.523903, learning_rate = 0.000471 (2578.6 examples/sec)
=> 2021-11-10 11:45:14.840476: step 23400, loss = 0.676102, learning_rate = 0.000471 (2575.4 examples/sec)
=> 2021-11-10 11:45:34.849075: step 23500, loss = 0.574074, learning_rate = 0.000471 (2580.2 examples/sec)
=> 2021-11-10 11:45:55.774282: step 23600, loss = 0.622480, learning_rate = 0.000471 (2594.4 examples/sec)
=> 2021-11-10 11:46:15.889659: step 23700, loss = 0.414895, learning_rate = 0.000471 (2566.6 examples/sec)
=> 2021-11-10 11:46:35.918034: step 23800, loss = 0.429071, learning_rate = 0.000471 (2577.8 examples/sec)
=> 2021-11-10 11:46:55.931790: step 23900, loss = 0.537142, learning_rate = 0.000471 (2579.5 examples/sec)
=> 2021-11-10 11:47:15.977762: step 24000, loss = 0.450310, learning_rate = 0.000424 (2575.4 examples/sec)
=> Model saved to file: ./logs_res/model-24000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.920875, best accuracy 0.916054
=> Model saved to file: ./logs_res/model-24000.pdparams
=> patience = 100
=> 2021-11-10 11:47:49.097761: step 24100, loss = 0.388220, learning_rate = 0.000424 (2596.9 examples/sec)
=> 2021-11-10 11:48:09.100129: step 24200, loss = 0.499978, learning_rate = 0.000424 (2581.0 examples/sec)
=> 2021-11-10 11:48:29.175048: step 24300, loss = 0.606752, learning_rate = 0.000424 (2571.7 examples/sec)
=> 2021-11-10 11:48:49.191769: step 24400, loss = 0.408664, learning_rate = 0.000424 (2579.1 examples/sec)
=> 2021-11-10 11:49:10.154381: step 24500, loss = 0.429091, learning_rate = 0.000424 (2595.9 examples/sec)
=> 2021-11-10 11:49:30.171967: step 24600, loss = 0.427976, learning_rate = 0.000424 (2579.5 examples/sec)
=> 2021-11-10 11:49:50.207190: step 24700, loss = 0.493594, learning_rate = 0.000424 (2576.8 examples/sec)
=> 2021-11-10 11:50:10.220150: step 24800, loss = 0.460974, learning_rate = 0.000382 (2579.6 examples/sec)
=> 2021-11-10 11:50:31.152493: step 24900, loss = 0.561167, learning_rate = 0.000382 (2593.7 examples/sec)
=> 2021-11-10 11:50:51.205340: step 25000, loss = 0.575326, learning_rate = 0.000382 (2574.6 examples/sec)
=> Model saved to file: ./logs_res/model-25000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.920187, best accuracy 0.920875
=> patience = 99
=> 2021-11-10 11:51:23.004478: step 25100, loss = 0.422595, learning_rate = 0.000382 (2582.2 examples/sec)
=> 2021-11-10 11:51:43.008765: step 25200, loss = 0.408081, learning_rate = 0.000382 (2580.8 examples/sec)
=> 2021-11-10 11:52:03.853185: step 25300, loss = 0.496415, learning_rate = 0.000382 (2606.6 examples/sec)
=> 2021-11-10 11:52:23.872534: step 25400, loss = 0.601997, learning_rate = 0.000382 (2579.1 examples/sec)
=> 2021-11-10 11:52:43.903299: step 25500, loss = 0.394069, learning_rate = 0.000382 (2577.6 examples/sec)
=> 2021-11-10 11:53:03.933699: step 25600, loss = 0.376966, learning_rate = 0.000343 (2577.4 examples/sec)
=> 2021-11-10 11:53:24.763228: step 25700, loss = 0.446974, learning_rate = 0.000343 (2595.5 examples/sec)
=> 2021-11-10 11:53:44.789475: step 25800, loss = 0.493818, learning_rate = 0.000343 (2578.1 examples/sec)
=> 2021-11-10 11:54:04.802351: step 25900, loss = 0.595797, learning_rate = 0.000343 (2579.6 examples/sec)
=> 2021-11-10 11:54:24.838053: step 26000, loss = 0.590591, learning_rate = 0.000343 (2576.7 examples/sec)
=> Model saved to file: ./logs_res/model-26000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.924089, best accuracy 0.920875
=> Model saved to file: ./logs_res/model-26000.pdparams
=> patience = 100
=> 2021-11-10 11:54:58.149426: step 26100, loss = 0.405885, learning_rate = 0.000343 (2604.4 examples/sec)
=> 2021-11-10 11:55:18.133237: step 26200, loss = 0.453358, learning_rate = 0.000343 (2583.5 examples/sec)
=> 2021-11-10 11:55:38.133499: step 26300, loss = 0.482030, learning_rate = 0.000343 (2581.3 examples/sec)
=> 2021-11-10 11:55:58.155449: step 26400, loss = 0.409141, learning_rate = 0.000309 (2578.6 examples/sec)
=> 2021-11-10 11:56:19.003341: step 26500, loss = 0.425467, learning_rate = 0.000309 (2594.1 examples/sec)
=> 2021-11-10 11:56:39.036108: step 26600, loss = 0.410148, learning_rate = 0.000309 (2577.4 examples/sec)
=> 2021-11-10 11:56:59.112606: step 26700, loss = 0.465379, learning_rate = 0.000309 (2571.4 examples/sec)
=> 2021-11-10 11:57:19.169282: step 26800, loss = 0.412319, learning_rate = 0.000309 (2574.0 examples/sec)
=> 2021-11-10 11:57:39.240279: step 26900, loss = 0.477268, learning_rate = 0.000309 (2572.3 examples/sec)
=> 2021-11-10 11:58:00.099914: step 27000, loss = 0.443258, learning_rate = 0.000309 (2592.4 examples/sec)
=> Model saved to file: ./logs_res/model-27000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.924931, best accuracy 0.924089
=> Model saved to file: ./logs_res/model-27000.pdparams
=> patience = 100
=> 2021-11-10 11:58:32.187462: step 27100, loss = 0.420396, learning_rate = 0.000309 (2579.6 examples/sec)
=> 2021-11-10 11:58:52.187088: step 27200, loss = 0.388185, learning_rate = 0.000278 (2581.4 examples/sec)
=> 2021-11-10 11:59:12.223322: step 27300, loss = 0.560009, learning_rate = 0.000278 (2576.7 examples/sec)
=> 2021-11-10 11:59:33.162137: step 27400, loss = 0.446584, learning_rate = 0.000278 (2596.7 examples/sec)
=> 2021-11-10 11:59:53.198323: step 27500, loss = 0.364916, learning_rate = 0.000278 (2576.7 examples/sec)
=> 2021-11-10 12:00:13.249737: step 27600, loss = 0.601541, learning_rate = 0.000278 (2574.8 examples/sec)
=> 2021-11-10 12:00:33.300367: step 27700, loss = 0.500910, learning_rate = 0.000278 (2574.8 examples/sec)
=> 2021-11-10 12:00:54.226814: step 27800, loss = 0.401743, learning_rate = 0.000278 (2592.5 examples/sec)
=> 2021-11-10 12:01:14.282811: step 27900, loss = 0.526835, learning_rate = 0.000278 (2574.2 examples/sec)
=> 2021-11-10 12:01:34.331043: step 28000, loss = 0.280550, learning_rate = 0.000250 (2575.1 examples/sec)
=> Model saved to file: ./logs_res/model-28000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.925390, best accuracy 0.924931
=> Model saved to file: ./logs_res/model-28000.pdparams
=> patience = 100
=> 2021-11-10 12:02:06.697590: step 28100, loss = 0.552712, learning_rate = 0.000250 (2583.6 examples/sec)
=> 2021-11-10 12:02:27.548563: step 28200, loss = 0.404735, learning_rate = 0.000250 (2594.2 examples/sec)
=> 2021-11-10 12:02:47.557845: step 28300, loss = 0.427640, learning_rate = 0.000250 (2580.3 examples/sec)
=> 2021-11-10 12:03:07.589895: step 28400, loss = 0.469354, learning_rate = 0.000250 (2577.3 examples/sec)
=> 2021-11-10 12:03:27.614286: step 28500, loss = 0.427227, learning_rate = 0.000250 (2578.4 examples/sec)
=> 2021-11-10 12:03:48.584696: step 28600, loss = 0.552475, learning_rate = 0.000250 (2594.4 examples/sec)
=> 2021-11-10 12:04:08.613145: step 28700, loss = 0.370337, learning_rate = 0.000250 (2578.1 examples/sec)
=> 2021-11-10 12:04:28.644610: step 28800, loss = 0.477109, learning_rate = 0.000225 (2577.2 examples/sec)
=> 2021-11-10 12:04:48.664164: step 28900, loss = 0.428178, learning_rate = 0.000225 (2578.6 examples/sec)
=> 2021-11-10 12:05:09.547420: step 29000, loss = 0.391809, learning_rate = 0.000225 (2590.2 examples/sec)
=> Model saved to file: ./logs_res/model-29000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.925008, best accuracy 0.925390
=> patience = 99
=> 2021-11-10 12:05:41.611722: step 29100, loss = 0.383371, learning_rate = 0.000225 (2581.9 examples/sec)
=> 2021-11-10 12:06:01.626719: step 29200, loss = 0.458539, learning_rate = 0.000225 (2579.5 examples/sec)
=> 2021-11-10 12:06:21.691806: step 29300, loss = 0.448848, learning_rate = 0.000225 (2573.0 examples/sec)
=> 2021-11-10 12:06:42.504053: step 29400, loss = 0.330700, learning_rate = 0.000225 (2596.7 examples/sec)
=> 2021-11-10 12:07:02.539512: step 29500, loss = 0.396744, learning_rate = 0.000225 (2576.7 examples/sec)
=> 2021-11-10 12:07:22.560825: step 29600, loss = 0.387686, learning_rate = 0.000203 (2578.6 examples/sec)
=> 2021-11-10 12:07:42.585063: step 29700, loss = 0.543835, learning_rate = 0.000203 (2578.2 examples/sec)
=> 2021-11-10 12:08:02.619646: step 29800, loss = 0.467378, learning_rate = 0.000203 (2577.8 examples/sec)
=> 2021-11-10 12:08:23.480102: step 29900, loss = 0.340387, learning_rate = 0.000203 (2593.9 examples/sec)
=> 2021-11-10 12:08:43.501825: step 30000, loss = 0.472397, learning_rate = 0.000203 (2578.6 examples/sec)
=> Model saved to file: ./logs_res/model-30000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.928910, best accuracy 0.925390
=> Model saved to file: ./logs_res/model-30000.pdparams
=> patience = 100
=> 2021-11-10 12:09:15.877714: step 30100, loss = 0.360200, learning_rate = 0.000203 (2583.4 examples/sec)
=> 2021-11-10 12:09:35.882264: step 30200, loss = 0.350827, learning_rate = 0.000203 (2580.7 examples/sec)
=> 2021-11-10 12:09:56.750174: step 30300, loss = 0.336813, learning_rate = 0.000203 (2597.6 examples/sec)
=> 2021-11-10 12:10:16.768763: step 30400, loss = 0.448778, learning_rate = 0.000182 (2578.9 examples/sec)
=> 2021-11-10 12:10:36.805279: step 30500, loss = 0.410402, learning_rate = 0.000182 (2577.1 examples/sec)
=> 2021-11-10 12:10:56.836555: step 30600, loss = 0.542130, learning_rate = 0.000182 (2577.2 examples/sec)
=> 2021-11-10 12:11:17.683635: step 30700, loss = 0.273472, learning_rate = 0.000182 (2594.3 examples/sec)
=> 2021-11-10 12:11:37.817708: step 30800, loss = 0.372132, learning_rate = 0.000182 (2564.3 examples/sec)
=> 2021-11-10 12:11:57.868636: step 30900, loss = 0.357819, learning_rate = 0.000182 (2574.8 examples/sec)
=> 2021-11-10 12:12:17.907368: step 31000, loss = 0.366356, learning_rate = 0.000182 (2576.6 examples/sec)
=> Model saved to file: ./logs_res/model-31000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.927686, best accuracy 0.928910
=> patience = 99
=> 2021-11-10 12:12:50.710785: step 31100, loss = 0.381312, learning_rate = 0.000182 (2594.6 examples/sec)
=> 2021-11-10 12:13:10.724847: step 31200, loss = 0.345159, learning_rate = 0.000164 (2579.7 examples/sec)
=> 2021-11-10 12:13:30.778185: step 31300, loss = 0.497810, learning_rate = 0.000164 (2574.5 examples/sec)
=> 2021-11-10 12:13:50.825104: step 31400, loss = 0.411492, learning_rate = 0.000164 (2575.6 examples/sec)
=> 2021-11-10 12:14:11.705609: step 31500, loss = 0.412318, learning_rate = 0.000164 (2592.7 examples/sec)
=> 2021-11-10 12:14:31.756951: step 31600, loss = 0.347960, learning_rate = 0.000164 (2575.9 examples/sec)
=> 2021-11-10 12:14:51.796618: step 31700, loss = 0.580983, learning_rate = 0.000164 (2576.2 examples/sec)
=> 2021-11-10 12:15:11.804189: step 31800, loss = 0.451718, learning_rate = 0.000164 (2580.5 examples/sec)
=> 2021-11-10 12:15:32.650696: step 31900, loss = 0.319638, learning_rate = 0.000164 (2594.3 examples/sec)
=> 2021-11-10 12:15:52.743559: step 32000, loss = 0.335211, learning_rate = 0.000148 (2569.6 examples/sec)
=> Model saved to file: ./logs_res/model-32000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.927533, best accuracy 0.928910
=> patience = 99
=> 2021-11-10 12:16:24.720659: step 32100, loss = 0.291974, learning_rate = 0.000148 (2582.1 examples/sec)
=> 2021-11-10 12:16:44.721406: step 32200, loss = 0.408310, learning_rate = 0.000148 (2581.1 examples/sec)
=> 2021-11-10 12:17:05.667073: step 32300, loss = 0.376418, learning_rate = 0.000148 (2594.9 examples/sec)
=> 2021-11-10 12:17:25.665959: step 32400, loss = 0.521474, learning_rate = 0.000148 (2581.4 examples/sec)
=> 2021-11-10 12:17:45.671472: step 32500, loss = 0.323929, learning_rate = 0.000148 (2580.5 examples/sec)
=> 2021-11-10 12:18:05.694676: step 32600, loss = 0.287057, learning_rate = 0.000148 (2578.5 examples/sec)
=> 2021-11-10 12:18:25.720271: step 32700, loss = 0.464433, learning_rate = 0.000148 (2578.8 examples/sec)
=> 2021-11-10 12:18:46.787427: step 32800, loss = 0.393150, learning_rate = 0.000133 (2590.0 examples/sec)
=> 2021-11-10 12:19:06.831395: step 32900, loss = 0.388607, learning_rate = 0.000133 (2575.9 examples/sec)
=> 2021-11-10 12:19:26.867505: step 33000, loss = 0.328110, learning_rate = 0.000133 (2577.1 examples/sec)
=> Model saved to file: ./logs_res/model-33000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.929752, best accuracy 0.928910
=> Model saved to file: ./logs_res/model-33000.pdparams
=> patience = 100
=> 2021-11-10 12:19:59.290781: step 33100, loss = 0.424733, learning_rate = 0.000133 (2583.7 examples/sec)
=> 2021-11-10 12:20:20.107806: step 33200, loss = 0.443115, learning_rate = 0.000133 (2596.8 examples/sec)
=> 2021-11-10 12:20:40.113057: step 33300, loss = 0.323201, learning_rate = 0.000133 (2581.0 examples/sec)
=> 2021-11-10 12:21:00.107094: step 33400, loss = 0.398916, learning_rate = 0.000133 (2582.3 examples/sec)
=> 2021-11-10 12:21:20.119733: step 33500, loss = 0.305670, learning_rate = 0.000133 (2580.1 examples/sec)
=> 2021-11-10 12:21:40.950302: step 33600, loss = 0.453626, learning_rate = 0.000120 (2595.4 examples/sec)
=> 2021-11-10 12:22:00.975518: step 33700, loss = 0.354403, learning_rate = 0.000120 (2578.2 examples/sec)
=> 2021-11-10 12:22:21.027053: step 33800, loss = 0.431097, learning_rate = 0.000120 (2574.9 examples/sec)
=> 2021-11-10 12:22:41.069337: step 33900, loss = 0.406637, learning_rate = 0.000120 (2576.0 examples/sec)
=> 2021-11-10 12:23:02.156342: step 34000, loss = 0.459987, learning_rate = 0.000120 (2591.2 examples/sec)
=> Model saved to file: ./logs_res/model-34000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.931665, best accuracy 0.929752
=> Model saved to file: ./logs_res/model-34000.pdparams
=> patience = 100
=> 2021-11-10 12:23:34.787086: step 34100, loss = 0.313618, learning_rate = 0.000120 (2583.7 examples/sec)
=> 2021-11-10 12:23:54.775070: step 34200, loss = 0.369919, learning_rate = 0.000120 (2583.5 examples/sec)
=> 2021-11-10 12:24:14.781292: step 34300, loss = 0.356774, learning_rate = 0.000120 (2581.1 examples/sec)
=> 2021-11-10 12:24:35.669035: step 34400, loss = 0.391167, learning_rate = 0.000108 (2599.7 examples/sec)
=> 2021-11-10 12:24:55.684856: step 34500, loss = 0.368332, learning_rate = 0.000108 (2579.2 examples/sec)
=> 2021-11-10 12:25:15.695474: step 34600, loss = 0.391922, learning_rate = 0.000108 (2580.0 examples/sec)
=> 2021-11-10 12:25:35.730013: step 34700, loss = 0.423741, learning_rate = 0.000108 (2577.2 examples/sec)
=> 2021-11-10 12:25:56.562601: step 34800, loss = 0.361417, learning_rate = 0.000108 (2597.6 examples/sec)
=> 2021-11-10 12:26:16.585799: step 34900, loss = 0.304009, learning_rate = 0.000108 (2578.4 examples/sec)
=> 2021-11-10 12:26:36.625779: step 35000, loss = 0.410184, learning_rate = 0.000108 (2576.3 examples/sec)
=> Model saved to file: ./logs_res/model-35000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.927762, best accuracy 0.931665
=> patience = 99
=> 2021-11-10 12:27:08.396000: step 35100, loss = 0.380492, learning_rate = 0.000108 (2585.5 examples/sec)
=> 2021-11-10 12:27:29.364436: step 35200, loss = 0.307864, learning_rate = 0.000097 (2598.3 examples/sec)
=> 2021-11-10 12:27:49.387665: step 35300, loss = 0.345432, learning_rate = 0.000097 (2578.6 examples/sec)
=> 2021-11-10 12:28:09.422895: step 35400, loss = 0.422965, learning_rate = 0.000097 (2576.9 examples/sec)
=> 2021-11-10 12:28:29.439182: step 35500, loss = 0.430404, learning_rate = 0.000097 (2579.5 examples/sec)
=> 2021-11-10 12:28:49.465479: step 35600, loss = 0.333348, learning_rate = 0.000097 (2578.9 examples/sec)
=> 2021-11-10 12:29:10.337359: step 35700, loss = 0.372240, learning_rate = 0.000097 (2590.9 examples/sec)
=> 2021-11-10 12:29:30.380137: step 35800, loss = 0.376508, learning_rate = 0.000097 (2575.9 examples/sec)
=> 2021-11-10 12:29:50.421551: step 35900, loss = 0.380099, learning_rate = 0.000097 (2576.2 examples/sec)
=> 2021-11-10 12:30:10.469726: step 36000, loss = 0.434525, learning_rate = 0.000087 (2575.3 examples/sec)
=> Model saved to file: ./logs_res/model-36000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.931053, best accuracy 0.931665
=> patience = 99
=> 2021-11-10 12:30:42.992719: step 36100, loss = 0.254370, learning_rate = 0.000087 (2596.4 examples/sec)
=> 2021-11-10 12:31:02.983664: step 36200, loss = 0.376704, learning_rate = 0.000087 (2582.7 examples/sec)
=> 2021-11-10 12:31:22.998879: step 36300, loss = 0.355700, learning_rate = 0.000087 (2579.6 examples/sec)
=> 2021-11-10 12:31:43.016660: step 36400, loss = 0.256406, learning_rate = 0.000087 (2579.3 examples/sec)
=> 2021-11-10 12:32:04.002112: step 36500, loss = 0.445988, learning_rate = 0.000087 (2577.0 examples/sec)
=> 2021-11-10 12:32:24.012931: step 36600, loss = 0.424886, learning_rate = 0.000087 (2580.1 examples/sec)
=> 2021-11-10 12:32:44.023571: step 36700, loss = 0.336905, learning_rate = 0.000087 (2580.0 examples/sec)
=> 2021-11-10 12:33:04.115734: step 36800, loss = 0.438252, learning_rate = 0.000079 (2569.7 examples/sec)
=> 2021-11-10 12:33:24.958391: step 36900, loss = 0.356159, learning_rate = 0.000079 (2596.1 examples/sec)
=> 2021-11-10 12:33:45.003514: step 37000, loss = 0.378123, learning_rate = 0.000079 (2575.8 examples/sec)
=> Model saved to file: ./logs_res/model-37000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.931206, best accuracy 0.931665
=> patience = 99
=> 2021-11-10 12:34:16.750508: step 37100, loss = 0.390844, learning_rate = 0.000079 (2581.5 examples/sec)
=> 2021-11-10 12:34:36.772435: step 37200, loss = 0.459968, learning_rate = 0.000079 (2578.7 examples/sec)
=> 2021-11-10 12:34:57.647610: step 37300, loss = 0.317044, learning_rate = 0.000079 (2588.9 examples/sec)
=> 2021-11-10 12:35:17.682917: step 37400, loss = 0.457526, learning_rate = 0.000079 (2577.0 examples/sec)
=> 2021-11-10 12:35:37.724427: step 37500, loss = 0.316665, learning_rate = 0.000079 (2576.3 examples/sec)
=> 2021-11-10 12:35:57.766587: step 37600, loss = 0.416729, learning_rate = 0.000071 (2576.4 examples/sec)
=> 2021-11-10 12:36:18.606776: step 37700, loss = 0.310015, learning_rate = 0.000071 (2593.7 examples/sec)
=> 2021-11-10 12:36:38.616993: step 37800, loss = 0.309327, learning_rate = 0.000071 (2580.2 examples/sec)
=> 2021-11-10 12:36:58.624495: step 37900, loss = 0.240855, learning_rate = 0.000071 (2580.5 examples/sec)
=> 2021-11-10 12:37:18.654723: step 38000, loss = 0.356333, learning_rate = 0.000071 (2577.4 examples/sec)
=> Model saved to file: ./logs_res/model-38000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.932277, best accuracy 0.931665
=> Model saved to file: ./logs_res/model-38000.pdparams
=> patience = 100
=> 2021-11-10 12:37:51.700442: step 38100, loss = 0.336624, learning_rate = 0.000071 (2596.9 examples/sec)
=> 2021-11-10 12:38:11.694240: step 38200, loss = 0.266766, learning_rate = 0.000071 (2582.3 examples/sec)
=> 2021-11-10 12:38:31.691340: step 38300, loss = 0.435804, learning_rate = 0.000071 (2581.6 examples/sec)
=> 2021-11-10 12:38:51.691363: step 38400, loss = 0.498815, learning_rate = 0.000064 (2581.5 examples/sec)
=> 2021-11-10 12:39:11.710980: step 38500, loss = 0.293208, learning_rate = 0.000064 (2579.5 examples/sec)
=> 2021-11-10 12:39:32.647314: step 38600, loss = 0.324713, learning_rate = 0.000064 (2592.7 examples/sec)
=> 2021-11-10 12:39:52.649262: step 38700, loss = 0.379981, learning_rate = 0.000064 (2581.3 examples/sec)
=> 2021-11-10 12:40:12.672492: step 38800, loss = 0.277036, learning_rate = 0.000064 (2578.4 examples/sec)
=> 2021-11-10 12:40:32.685480: step 38900, loss = 0.333279, learning_rate = 0.000064 (2579.2 examples/sec)
=> 2021-11-10 12:40:53.499696: step 39000, loss = 0.508601, learning_rate = 0.000064 (2601.7 examples/sec)
=> Model saved to file: ./logs_res/model-39000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.934037, best accuracy 0.932277
=> Model saved to file: ./logs_res/model-39000.pdparams
=> patience = 100
=> 2021-11-10 12:41:25.792446: step 39100, loss = 0.362701, learning_rate = 0.000064 (2583.8 examples/sec)
=> 2021-11-10 12:41:45.798201: step 39200, loss = 0.353337, learning_rate = 0.000057 (2580.7 examples/sec)
=> 2021-11-10 12:42:05.821142: step 39300, loss = 0.332428, learning_rate = 0.000057 (2578.6 examples/sec)
=> 2021-11-10 12:42:26.679301: step 39400, loss = 0.408211, learning_rate = 0.000057 (2594.3 examples/sec)
=> 2021-11-10 12:42:46.704737: step 39500, loss = 0.394323, learning_rate = 0.000057 (2578.2 examples/sec)
=> 2021-11-10 12:43:06.751868: step 39600, loss = 0.309175, learning_rate = 0.000057 (2575.3 examples/sec)
=> 2021-11-10 12:43:26.801642: step 39700, loss = 0.325003, learning_rate = 0.000057 (2575.2 examples/sec)
=> 2021-11-10 12:43:47.665536: step 39800, loss = 0.366855, learning_rate = 0.000057 (2609.4 examples/sec)
=> 2021-11-10 12:44:07.695865: step 39900, loss = 0.400405, learning_rate = 0.000057 (2577.8 examples/sec)
=> 2021-11-10 12:44:27.725873: step 40000, loss = 0.254230, learning_rate = 0.000052 (2577.7 examples/sec)
=> Model saved to file: ./logs_res/model-40000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.933349, best accuracy 0.934037
=> patience = 99
=> 2021-11-10 12:44:59.772303: step 40100, loss = 0.406751, learning_rate = 0.000052 (2581.2 examples/sec)
=> 2021-11-10 12:45:20.650639: step 40200, loss = 0.340608, learning_rate = 0.000052 (2593.9 examples/sec)
=> 2021-11-10 12:45:40.743297: step 40300, loss = 0.352742, learning_rate = 0.000052 (2569.6 examples/sec)
=> 2021-11-10 12:46:00.764374: step 40400, loss = 0.420471, learning_rate = 0.000052 (2578.7 examples/sec)
=> 2021-11-10 12:46:20.789949: step 40500, loss = 0.442517, learning_rate = 0.000052 (2578.3 examples/sec)
=> 2021-11-10 12:46:41.819294: step 40600, loss = 0.390974, learning_rate = 0.000052 (2589.1 examples/sec)
=> 2021-11-10 12:47:01.840206: step 40700, loss = 0.356985, learning_rate = 0.000052 (2579.0 examples/sec)
=> 2021-11-10 12:47:21.880129: step 40800, loss = 0.349663, learning_rate = 0.000046 (2576.4 examples/sec)
=> 2021-11-10 12:47:41.917632: step 40900, loss = 0.347350, learning_rate = 0.000046 (2576.6 examples/sec)
=> 2021-11-10 12:48:02.844006: step 41000, loss = 0.315517, learning_rate = 0.000046 (2591.2 examples/sec)
=> Model saved to file: ./logs_res/model-41000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.933884, best accuracy 0.934037
=> patience = 99
=> 2021-11-10 12:48:34.883567: step 41100, loss = 0.262080, learning_rate = 0.000046 (2579.8 examples/sec)
=> 2021-11-10 12:48:54.896181: step 41200, loss = 0.391991, learning_rate = 0.000046 (2580.0 examples/sec)
=> 2021-11-10 12:49:14.896539: step 41300, loss = 0.310846, learning_rate = 0.000046 (2581.5 examples/sec)
=> 2021-11-10 12:49:34.928051: step 41400, loss = 0.420653, learning_rate = 0.000046 (2577.8 examples/sec)
=> 2021-11-10 12:49:55.985907: step 41500, loss = 0.252568, learning_rate = 0.000046 (2576.6 examples/sec)
=> 2021-11-10 12:50:16.007023: step 41600, loss = 0.294253, learning_rate = 0.000042 (2578.7 examples/sec)
=> 2021-11-10 12:50:36.034437: step 41700, loss = 0.307467, learning_rate = 0.000042 (2578.0 examples/sec)
=> 2021-11-10 12:50:56.058810: step 41800, loss = 0.284937, learning_rate = 0.000042 (2578.3 examples/sec)
=> 2021-11-10 12:51:16.879052: step 41900, loss = 0.343210, learning_rate = 0.000042 (2596.1 examples/sec)
=> 2021-11-10 12:51:36.926181: step 42000, loss = 0.267260, learning_rate = 0.000042 (2575.4 examples/sec)
=> Model saved to file: ./logs_res/model-42000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.935185, best accuracy 0.934037
=> Model saved to file: ./logs_res/model-42000.pdparams
=> patience = 100
=> 2021-11-10 12:52:09.372114: step 42100, loss = 0.301065, learning_rate = 0.000042 (2584.1 examples/sec)
=> 2021-11-10 12:52:29.370894: step 42200, loss = 0.396550, learning_rate = 0.000042 (2581.3 examples/sec)
=> 2021-11-10 12:52:50.404160: step 42300, loss = 0.317214, learning_rate = 0.000042 (2594.6 examples/sec)
=> 2021-11-10 12:53:10.400713: step 42400, loss = 0.337524, learning_rate = 0.000038 (2581.9 examples/sec)
=> 2021-11-10 12:53:30.419994: step 42500, loss = 0.307085, learning_rate = 0.000038 (2579.1 examples/sec)
=> 2021-11-10 12:53:50.463698: step 42600, loss = 0.324562, learning_rate = 0.000038 (2575.7 examples/sec)
=> 2021-11-10 12:54:11.356635: step 42700, loss = 0.327067, learning_rate = 0.000038 (2592.8 examples/sec)
=> 2021-11-10 12:54:31.358660: step 42800, loss = 0.471126, learning_rate = 0.000038 (2581.1 examples/sec)
=> 2021-11-10 12:54:51.366438: step 42900, loss = 0.302822, learning_rate = 0.000038 (2580.5 examples/sec)
=> 2021-11-10 12:55:11.402628: step 43000, loss = 0.300823, learning_rate = 0.000038 (2576.7 examples/sec)
=> Model saved to file: ./logs_res/model-43000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.934956, best accuracy 0.935185
=> patience = 99
=> 2021-11-10 12:55:43.936260: step 43100, loss = 0.375137, learning_rate = 0.000038 (2597.8 examples/sec)
=> 2021-11-10 12:56:03.924059: step 43200, loss = 0.412711, learning_rate = 0.000034 (2583.0 examples/sec)
=> 2021-11-10 12:56:23.941088: step 43300, loss = 0.308180, learning_rate = 0.000034 (2579.3 examples/sec)
=> 2021-11-10 12:56:43.940358: step 43400, loss = 0.395993, learning_rate = 0.000034 (2581.3 examples/sec)
=> 2021-11-10 12:57:04.918910: step 43500, loss = 0.376958, learning_rate = 0.000034 (2591.8 examples/sec)
=> 2021-11-10 12:57:24.938688: step 43600, loss = 0.522477, learning_rate = 0.000034 (2578.8 examples/sec)
=> 2021-11-10 12:57:44.961857: step 43700, loss = 0.356687, learning_rate = 0.000034 (2578.2 examples/sec)
=> 2021-11-10 12:58:04.950852: step 43800, loss = 0.330532, learning_rate = 0.000034 (2582.7 examples/sec)
=> 2021-11-10 12:58:26.007934: step 43900, loss = 0.289046, learning_rate = 0.000034 (2592.6 examples/sec)
=> 2021-11-10 12:58:46.007882: step 44000, loss = 0.347513, learning_rate = 0.000030 (2581.4 examples/sec)
=> Model saved to file: ./logs_res/model-44000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.936180, best accuracy 0.935185
=> Model saved to file: ./logs_res/model-44000.pdparams
=> patience = 100
=> 2021-11-10 12:59:18.207154: step 44100, loss = 0.361301, learning_rate = 0.000030 (2586.0 examples/sec)
=> 2021-11-10 12:59:38.193750: step 44200, loss = 0.430671, learning_rate = 0.000030 (2583.0 examples/sec)
=> 2021-11-10 12:59:59.041802: step 44300, loss = 0.276386, learning_rate = 0.000030 (2595.7 examples/sec)
=> 2021-11-10 13:00:19.059142: step 44400, loss = 0.268409, learning_rate = 0.000030 (2579.1 examples/sec)
=> 2021-11-10 13:00:39.060942: step 44500, loss = 0.305378, learning_rate = 0.000030 (2581.3 examples/sec)
=> 2021-11-10 13:00:59.058806: step 44600, loss = 0.408897, learning_rate = 0.000030 (2581.4 examples/sec)
=> 2021-11-10 13:01:19.077314: step 44700, loss = 0.257803, learning_rate = 0.000030 (2579.1 examples/sec)
=> 2021-11-10 13:01:39.925781: step 44800, loss = 0.300055, learning_rate = 0.000027 (2592.6 examples/sec)
=> 2021-11-10 13:01:59.944227: step 44900, loss = 0.288438, learning_rate = 0.000027 (2579.0 examples/sec)
=> 2021-11-10 13:02:19.959527: step 45000, loss = 0.301150, learning_rate = 0.000027 (2579.7 examples/sec)
=> Model saved to file: ./logs_res/model-45000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.935109, best accuracy 0.936180
=> patience = 99
=> 2021-11-10 13:02:51.719206: step 45100, loss = 0.356211, learning_rate = 0.000027 (2584.1 examples/sec)
=> 2021-11-10 13:03:12.537229: step 45200, loss = 0.278863, learning_rate = 0.000027 (2597.2 examples/sec)
=> 2021-11-10 13:03:32.537439: step 45300, loss = 0.348382, learning_rate = 0.000027 (2581.4 examples/sec)
=> 2021-11-10 13:03:52.548395: step 45400, loss = 0.308495, learning_rate = 0.000027 (2579.9 examples/sec)
=> 2021-11-10 13:04:12.557338: step 45500, loss = 0.248444, learning_rate = 0.000027 (2580.4 examples/sec)
=> 2021-11-10 13:04:33.422425: step 45600, loss = 0.252065, learning_rate = 0.000025 (2595.2 examples/sec)
=> 2021-11-10 13:04:53.437386: step 45700, loss = 0.372112, learning_rate = 0.000025 (2579.4 examples/sec)
=> 2021-11-10 13:05:13.438353: step 45800, loss = 0.372580, learning_rate = 0.000025 (2581.2 examples/sec)
=> 2021-11-10 13:05:33.433484: step 45900, loss = 0.313105, learning_rate = 0.000025 (2582.0 examples/sec)
=> 2021-11-10 13:05:54.346984: step 46000, loss = 0.385633, learning_rate = 0.000025 (2593.0 examples/sec)
=> Model saved to file: ./logs_res/model-46000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937175, best accuracy 0.936180
=> Model saved to file: ./logs_res/model-46000.pdparams
=> patience = 100
=> 2021-11-10 13:06:26.859577: step 46100, loss = 0.294959, learning_rate = 0.000025 (2583.1 examples/sec)
=> 2021-11-10 13:06:46.857289: step 46200, loss = 0.244465, learning_rate = 0.000025 (2581.7 examples/sec)
=> 2021-11-10 13:07:06.852198: step 46300, loss = 0.355688, learning_rate = 0.000025 (2582.0 examples/sec)
=> 2021-11-10 13:07:27.707111: step 46400, loss = 0.320035, learning_rate = 0.000022 (2594.3 examples/sec)
=> 2021-11-10 13:07:47.717817: step 46500, loss = 0.249756, learning_rate = 0.000022 (2579.9 examples/sec)
=> 2021-11-10 13:08:07.728831: step 46600, loss = 0.263808, learning_rate = 0.000022 (2580.3 examples/sec)
=> 2021-11-10 13:08:27.735324: step 46700, loss = 0.283735, learning_rate = 0.000022 (2580.6 examples/sec)
=> 2021-11-10 13:08:48.605500: step 46800, loss = 0.253966, learning_rate = 0.000022 (2592.7 examples/sec)
=> 2021-11-10 13:09:08.608082: step 46900, loss = 0.346602, learning_rate = 0.000022 (2581.1 examples/sec)
=> 2021-11-10 13:09:28.618209: step 47000, loss = 0.256821, learning_rate = 0.000022 (2580.0 examples/sec)
=> Model saved to file: ./logs_res/model-47000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939394, best accuracy 0.937175
=> Model saved to file: ./logs_res/model-47000.pdparams
=> patience = 100
=> 2021-11-10 13:10:00.767557: step 47100, loss = 0.390500, learning_rate = 0.000022 (2580.0 examples/sec)
=> 2021-11-10 13:10:21.602116: step 47200, loss = 0.270809, learning_rate = 0.000020 (2595.9 examples/sec)
=> 2021-11-10 13:10:41.600581: step 47300, loss = 0.383586, learning_rate = 0.000020 (2582.1 examples/sec)
=> 2021-11-10 13:11:01.618291: step 47400, loss = 0.226984, learning_rate = 0.000020 (2579.3 examples/sec)
=> 2021-11-10 13:11:21.632606: step 47500, loss = 0.268508, learning_rate = 0.000020 (2579.5 examples/sec)
=> 2021-11-10 13:11:41.649199: step 47600, loss = 0.401116, learning_rate = 0.000020 (2579.1 examples/sec)
=> 2021-11-10 13:12:02.503413: step 47700, loss = 0.461184, learning_rate = 0.000020 (2596.7 examples/sec)
=> 2021-11-10 13:12:22.513954: step 47800, loss = 0.418531, learning_rate = 0.000020 (2580.1 examples/sec)
=> 2021-11-10 13:12:42.523264: step 47900, loss = 0.254169, learning_rate = 0.000020 (2580.3 examples/sec)
=> 2021-11-10 13:13:02.529950: step 48000, loss = 0.304983, learning_rate = 0.000018 (2580.5 examples/sec)
=> Model saved to file: ./logs_res/model-48000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937940, best accuracy 0.939394
=> patience = 99
=> 2021-11-10 13:13:35.145508: step 48100, loss = 0.349478, learning_rate = 0.000018 (2602.2 examples/sec)
=> 2021-11-10 13:13:55.174716: step 48200, loss = 0.372862, learning_rate = 0.000018 (2577.7 examples/sec)
=> 2021-11-10 13:14:15.195939: step 48300, loss = 0.317175, learning_rate = 0.000018 (2578.6 examples/sec)
=> 2021-11-10 13:14:35.210722: step 48400, loss = 0.335750, learning_rate = 0.000018 (2579.7 examples/sec)
=> 2021-11-10 13:14:56.265541: step 48500, loss = 0.245185, learning_rate = 0.000018 (2592.7 examples/sec)
=> 2021-11-10 13:15:16.295927: step 48600, loss = 0.431603, learning_rate = 0.000018 (2577.6 examples/sec)
=> 2021-11-10 13:15:36.343147: step 48700, loss = 0.355737, learning_rate = 0.000018 (2575.6 examples/sec)
=> 2021-11-10 13:15:56.381453: step 48800, loss = 0.363101, learning_rate = 0.000016 (2576.4 examples/sec)
=> 2021-11-10 13:16:17.249817: step 48900, loss = 0.252152, learning_rate = 0.000016 (2592.7 examples/sec)
=> 2021-11-10 13:16:37.294635: step 49000, loss = 0.317606, learning_rate = 0.000016 (2575.7 examples/sec)
=> Model saved to file: ./logs_res/model-49000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939088, best accuracy 0.939394
=> patience = 99
=> 2021-11-10 13:17:09.291311: step 49100, loss = 0.242675, learning_rate = 0.000016 (2582.3 examples/sec)
=> 2021-11-10 13:17:29.285780: step 49200, loss = 0.337784, learning_rate = 0.000016 (2582.4 examples/sec)
=> 2021-11-10 13:17:50.140111: step 49300, loss = 0.233244, learning_rate = 0.000016 (2597.4 examples/sec)
=> 2021-11-10 13:18:10.140515: step 49400, loss = 0.230313, learning_rate = 0.000016 (2581.4 examples/sec)
=> 2021-11-10 13:18:30.151355: step 49500, loss = 0.291964, learning_rate = 0.000016 (2580.0 examples/sec)
=> 2021-11-10 13:18:50.156633: step 49600, loss = 0.316904, learning_rate = 0.000015 (2580.6 examples/sec)
=> 2021-11-10 13:19:11.050697: step 49700, loss = 0.464950, learning_rate = 0.000015 (2597.0 examples/sec)
=> 2021-11-10 13:19:31.071939: step 49800, loss = 0.268996, learning_rate = 0.000015 (2578.6 examples/sec)
=> 2021-11-10 13:19:51.093640: step 49900, loss = 0.271625, learning_rate = 0.000015 (2578.6 examples/sec)
=> 2021-11-10 13:20:11.099437: step 50000, loss = 0.232748, learning_rate = 0.000015 (2580.5 examples/sec)
=> Model saved to file: ./logs_res/model-50000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.938935, best accuracy 0.939394
=> patience = 99
=> 2021-11-10 13:20:43.802884: step 50100, loss = 0.264728, learning_rate = 0.000015 (2597.0 examples/sec)
=> 2021-11-10 13:21:03.807722: step 50200, loss = 0.266135, learning_rate = 0.000015 (2580.8 examples/sec)
=> 2021-11-10 13:21:23.822938: step 50300, loss = 0.281407, learning_rate = 0.000015 (2579.6 examples/sec)
=> 2021-11-10 13:21:43.854023: step 50400, loss = 0.302325, learning_rate = 0.000013 (2577.8 examples/sec)
=> 2021-11-10 13:22:03.889583: step 50500, loss = 0.271704, learning_rate = 0.000013 (2577.5 examples/sec)
=> 2021-11-10 13:22:24.759898: step 50600, loss = 0.247255, learning_rate = 0.000013 (2594.2 examples/sec)
=> 2021-11-10 13:22:44.781493: step 50700, loss = 0.378489, learning_rate = 0.000013 (2578.5 examples/sec)
=> 2021-11-10 13:23:04.796572: step 50800, loss = 0.298123, learning_rate = 0.000013 (2579.6 examples/sec)
=> 2021-11-10 13:23:24.804284: step 50900, loss = 0.351383, learning_rate = 0.000013 (2580.5 examples/sec)
=> 2021-11-10 13:23:45.668762: step 51000, loss = 0.355743, learning_rate = 0.000013 (2610.8 examples/sec)
=> Model saved to file: ./logs_res/model-51000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.940618, best accuracy 0.939394
=> Model saved to file: ./logs_res/model-51000.pdparams
=> patience = 100
=> 2021-11-10 13:24:18.042115: step 51100, loss = 0.294744, learning_rate = 0.000013 (2583.8 examples/sec)
=> 2021-11-10 13:24:38.024211: step 51200, loss = 0.217295, learning_rate = 0.000012 (2583.4 examples/sec)
=> 2021-11-10 13:24:58.029294: step 51300, loss = 0.363059, learning_rate = 0.000012 (2580.7 examples/sec)
=> 2021-11-10 13:25:18.840188: step 51400, loss = 0.297010, learning_rate = 0.000012 (2598.6 examples/sec)
=> 2021-11-10 13:25:38.842401: step 51500, loss = 0.232700, learning_rate = 0.000012 (2581.3 examples/sec)
=> 2021-11-10 13:25:58.878220: step 51600, loss = 0.227679, learning_rate = 0.000012 (2576.9 examples/sec)
=> 2021-11-10 13:26:18.889757: step 51700, loss = 0.368296, learning_rate = 0.000012 (2579.9 examples/sec)
=> 2021-11-10 13:26:39.793855: step 51800, loss = 0.297858, learning_rate = 0.000012 (2593.9 examples/sec)
=> 2021-11-10 13:26:59.824313: step 51900, loss = 0.281273, learning_rate = 0.000012 (2577.5 examples/sec)
=> 2021-11-10 13:27:19.870774: step 52000, loss = 0.347184, learning_rate = 0.000011 (2575.5 examples/sec)
=> Model saved to file: ./logs_res/model-52000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939164, best accuracy 0.940618
=> patience = 99
=> 2021-11-10 13:27:51.557924: step 52100, loss = 0.285116, learning_rate = 0.000011 (2580.8 examples/sec)
=> 2021-11-10 13:28:12.367543: step 52200, loss = 0.256223, learning_rate = 0.000011 (2597.7 examples/sec)
=> 2021-11-10 13:28:32.394547: step 52300, loss = 0.303872, learning_rate = 0.000011 (2577.9 examples/sec)
=> 2021-11-10 13:28:52.415546: step 52400, loss = 0.222217, learning_rate = 0.000011 (2578.6 examples/sec)
=> 2021-11-10 13:29:12.449665: step 52500, loss = 0.316398, learning_rate = 0.000011 (2577.2 examples/sec)
=> 2021-11-10 13:29:33.308182: step 52600, loss = 0.297086, learning_rate = 0.000011 (2594.7 examples/sec)
=> 2021-11-10 13:29:53.343718: step 52700, loss = 0.281188, learning_rate = 0.000011 (2577.1 examples/sec)
=> 2021-11-10 13:30:13.358367: step 52800, loss = 0.285458, learning_rate = 0.000010 (2579.7 examples/sec)
=> 2021-11-10 13:30:33.375731: step 52900, loss = 0.400426, learning_rate = 0.000010 (2579.2 examples/sec)
=> 2021-11-10 13:30:54.240554: step 53000, loss = 0.251577, learning_rate = 0.000010 (2592.2 examples/sec)
=> Model saved to file: ./logs_res/model-53000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.938782, best accuracy 0.940618
=> patience = 99
=> 2021-11-10 13:31:25.947968: step 53100, loss = 0.244071, learning_rate = 0.000010 (2580.4 examples/sec)
=> 2021-11-10 13:31:45.937113: step 53200, loss = 0.211123, learning_rate = 0.000010 (2582.8 examples/sec)
=> 2021-11-10 13:32:05.928090: step 53300, loss = 0.310437, learning_rate = 0.000010 (2582.6 examples/sec)
=> 2021-11-10 13:32:25.932588: step 53400, loss = 0.241389, learning_rate = 0.000010 (2581.5 examples/sec)
=> 2021-11-10 13:32:46.753928: step 53500, loss = 0.333937, learning_rate = 0.000010 (2597.0 examples/sec)
=> 2021-11-10 13:33:06.775039: step 53600, loss = 0.339452, learning_rate = 0.000009 (2578.9 examples/sec)
=> 2021-11-10 13:33:26.783527: step 53700, loss = 0.381253, learning_rate = 0.000009 (2580.6 examples/sec)
=> 2021-11-10 13:33:46.789876: step 53800, loss = 0.277819, learning_rate = 0.000009 (2580.6 examples/sec)
=> 2021-11-10 13:34:07.650300: step 53900, loss = 0.290005, learning_rate = 0.000009 (2594.9 examples/sec)
=> 2021-11-10 13:34:27.666652: step 54000, loss = 0.178910, learning_rate = 0.000009 (2579.5 examples/sec)
=> Model saved to file: ./logs_res/model-54000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.938782, best accuracy 0.940618
=> patience = 99
=> 2021-11-10 13:34:59.532593: step 54100, loss = 0.348375, learning_rate = 0.000009 (2585.2 examples/sec)
=> 2021-11-10 13:35:19.531241: step 54200, loss = 0.301410, learning_rate = 0.000009 (2581.5 examples/sec)
=> 2021-11-10 13:35:40.449744: step 54300, loss = 0.315612, learning_rate = 0.000009 (2607.6 examples/sec)
=> 2021-11-10 13:36:00.447315: step 54400, loss = 0.230201, learning_rate = 0.000008 (2582.0 examples/sec)
=> 2021-11-10 13:36:20.454738: step 54500, loss = 0.327541, learning_rate = 0.000008 (2580.6 examples/sec)
=> 2021-11-10 13:36:40.460798: step 54600, loss = 0.291379, learning_rate = 0.000008 (2580.7 examples/sec)
=> 2021-11-10 13:37:01.453052: step 54700, loss = 0.275958, learning_rate = 0.000008 (2591.8 examples/sec)
=> 2021-11-10 13:37:21.454655: step 54800, loss = 0.343693, learning_rate = 0.000008 (2581.1 examples/sec)
=> 2021-11-10 13:37:41.481215: step 54900, loss = 0.367552, learning_rate = 0.000008 (2578.2 examples/sec)
=> 2021-11-10 13:38:01.485615: step 55000, loss = 0.289839, learning_rate = 0.000008 (2580.8 examples/sec)
=> Model saved to file: ./logs_res/model-55000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.940389, best accuracy 0.940618
=> patience = 99
=> 2021-11-10 13:38:33.933792: step 55100, loss = 0.250270, learning_rate = 0.000008 (2597.6 examples/sec)
=> 2021-11-10 13:38:53.926343: step 55200, loss = 0.253529, learning_rate = 0.000007 (2582.4 examples/sec)
=> 2021-11-10 13:39:13.920214: step 55300, loss = 0.206477, learning_rate = 0.000007 (2582.1 examples/sec)
=> 2021-11-10 13:39:33.915877: step 55400, loss = 0.224085, learning_rate = 0.000007 (2582.1 examples/sec)
=> 2021-11-10 13:39:54.902788: step 55500, loss = 0.306167, learning_rate = 0.000007 (2591.8 examples/sec)
=> 2021-11-10 13:40:14.910968: step 55600, loss = 0.254718, learning_rate = 0.000007 (2581.1 examples/sec)
=> 2021-11-10 13:40:34.937998: step 55700, loss = 0.210834, learning_rate = 0.000007 (2578.1 examples/sec)
=> 2021-11-10 13:40:54.967612: step 55800, loss = 0.331036, learning_rate = 0.000007 (2577.8 examples/sec)
=> 2021-11-10 13:41:16.003755: step 55900, loss = 0.208046, learning_rate = 0.000007 (2595.2 examples/sec)
=> 2021-11-10 13:41:36.004243: step 56000, loss = 0.224130, learning_rate = 0.000006 (2581.4 examples/sec)
=> Model saved to file: ./logs_res/model-56000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939853, best accuracy 0.940618
=> patience = 99
=> 2021-11-10 13:42:07.792848: step 56100, loss = 0.232445, learning_rate = 0.000006 (2584.3 examples/sec)
=> 2021-11-10 13:42:27.776640: step 56200, loss = 0.281324, learning_rate = 0.000006 (2583.4 examples/sec)
=> 2021-11-10 13:42:47.759598: step 56300, loss = 0.326441, learning_rate = 0.000006 (2583.9 examples/sec)
=> 2021-11-10 13:43:08.619716: step 56400, loss = 0.257204, learning_rate = 0.000006 (2592.8 examples/sec)
=> 2021-11-10 13:43:28.615789: step 56500, loss = 0.296347, learning_rate = 0.000006 (2581.9 examples/sec)
=> 2021-11-10 13:43:48.621284: step 56600, loss = 0.227080, learning_rate = 0.000006 (2580.8 examples/sec)
=> 2021-11-10 13:44:08.618501: step 56700, loss = 0.234499, learning_rate = 0.000006 (2581.9 examples/sec)
=> 2021-11-10 13:44:29.452951: step 56800, loss = 0.359062, learning_rate = 0.000006 (2597.8 examples/sec)
=> 2021-11-10 13:44:49.471324: step 56900, loss = 0.327362, learning_rate = 0.000006 (2581.2 examples/sec)
=> 2021-11-10 13:45:09.495347: step 57000, loss = 0.291174, learning_rate = 0.000006 (2580.0 examples/sec)
=> Model saved to file: ./logs_res/model-57000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.943067, best accuracy 0.940618
=> Model saved to file: ./logs_res/model-57000.pdparams
=> patience = 100
=> 2021-11-10 13:45:41.894182: step 57100, loss = 0.239217, learning_rate = 0.000006 (2586.8 examples/sec)
=> 2021-11-10 13:46:02.695505: step 57200, loss = 0.199700, learning_rate = 0.000006 (2603.8 examples/sec)
=> 2021-11-10 13:46:22.742297: step 57300, loss = 0.263584, learning_rate = 0.000006 (2575.9 examples/sec)
=> 2021-11-10 13:46:42.755947: step 57400, loss = 0.208603, learning_rate = 0.000006 (2579.7 examples/sec)
=> 2021-11-10 13:47:02.777238: step 57500, loss = 0.319461, learning_rate = 0.000006 (2578.8 examples/sec)
=> 2021-11-10 13:47:23.652173: step 57600, loss = 0.355586, learning_rate = 0.000005 (2593.5 examples/sec)
=> 2021-11-10 13:47:43.675590: step 57700, loss = 0.272119, learning_rate = 0.000005 (2578.9 examples/sec)
=> 2021-11-10 13:48:03.693494: step 57800, loss = 0.349174, learning_rate = 0.000005 (2579.4 examples/sec)
=> 2021-11-10 13:48:23.733045: step 57900, loss = 0.231308, learning_rate = 0.000005 (2576.6 examples/sec)
=> 2021-11-10 13:48:44.610280: step 58000, loss = 0.244963, learning_rate = 0.000005 (2600.6 examples/sec)
=> Model saved to file: ./logs_res/model-58000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.940924, best accuracy 0.943067
=> patience = 99
=> 2021-11-10 13:49:16.271317: step 58100, loss = 0.215108, learning_rate = 0.000005 (2585.1 examples/sec)
=> 2021-11-10 13:49:36.256583: step 58200, loss = 0.397947, learning_rate = 0.000005 (2583.4 examples/sec)
=> 2021-11-10 13:49:56.255563: step 58300, loss = 0.335007, learning_rate = 0.000005 (2581.7 examples/sec)
=> 2021-11-10 13:50:17.064043: step 58400, loss = 0.259802, learning_rate = 0.000005 (2600.3 examples/sec)
=> 2021-11-10 13:50:37.083170: step 58500, loss = 0.169603, learning_rate = 0.000005 (2579.2 examples/sec)
=> 2021-11-10 13:50:57.087667: step 58600, loss = 0.337274, learning_rate = 0.000005 (2580.9 examples/sec)
=> 2021-11-10 13:51:17.086179: step 58700, loss = 0.306552, learning_rate = 0.000005 (2581.7 examples/sec)
=> 2021-11-10 13:51:38.249021: step 58800, loss = 0.255509, learning_rate = 0.000005 (2581.9 examples/sec)
=> 2021-11-10 13:51:58.284504: step 58900, loss = 0.281717, learning_rate = 0.000005 (2577.1 examples/sec)
=> 2021-11-10 13:52:18.324311: step 59000, loss = 0.268196, learning_rate = 0.000005 (2576.3 examples/sec)
=> Model saved to file: ./logs_res/model-59000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.942225, best accuracy 0.943067
=> patience = 99
=> 2021-11-10 13:52:50.240247: step 59100, loss = 0.170254, learning_rate = 0.000005 (2583.6 examples/sec)
=> 2021-11-10 13:53:10.222764: step 59200, loss = 0.249161, learning_rate = 0.000004 (2584.2 examples/sec)
=> 2021-11-10 13:53:31.043954: step 59300, loss = 0.242293, learning_rate = 0.000004 (2597.0 examples/sec)
=> 2021-11-10 13:53:51.038144: step 59400, loss = 0.261560, learning_rate = 0.000004 (2582.1 examples/sec)
=> 2021-11-10 13:54:11.039442: step 59500, loss = 0.325933, learning_rate = 0.000004 (2581.1 examples/sec)
=> 2021-11-10 13:54:31.051994: step 59600, loss = 0.347095, learning_rate = 0.000004 (2579.9 examples/sec)
=> 2021-11-10 13:54:51.967802: step 59700, loss = 0.272626, learning_rate = 0.000004 (2595.0 examples/sec)
=> 2021-11-10 13:55:12.009210: step 59800, loss = 0.333319, learning_rate = 0.000004 (2576.0 examples/sec)
=> 2021-11-10 13:55:32.025152: step 59900, loss = 0.432445, learning_rate = 0.000004 (2579.4 examples/sec)
=> 2021-11-10 13:55:52.034175: step 60000, loss = 0.235675, learning_rate = 0.000004 (2580.3 examples/sec)
=> Model saved to file: ./logs_res/model-60000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.942072, best accuracy 0.943067
=> patience = 99
=> 2021-11-10 13:56:24.711161: step 60100, loss = 0.366450, learning_rate = 0.000004 (2598.4 examples/sec)
=> 2021-11-10 13:56:44.802505: step 60200, loss = 0.345272, learning_rate = 0.000004 (2569.8 examples/sec)
=> 2021-11-10 13:57:04.790247: step 60300, loss = 0.322309, learning_rate = 0.000004 (2583.1 examples/sec)
=> 2021-11-10 13:57:24.768578: step 60400, loss = 0.386043, learning_rate = 0.000004 (2584.3 examples/sec)
=> 2021-11-10 13:57:45.614093: step 60500, loss = 0.234064, learning_rate = 0.000004 (2595.7 examples/sec)
=> 2021-11-10 13:58:05.609908: step 60600, loss = 0.239437, learning_rate = 0.000004 (2582.0 examples/sec)
=> 2021-11-10 13:58:25.651260: step 60700, loss = 0.250091, learning_rate = 0.000004 (2576.1 examples/sec)
=> 2021-11-10 13:58:45.649488: step 60800, loss = 0.219401, learning_rate = 0.000003 (2581.5 examples/sec)
=> 2021-11-10 13:59:06.497817: step 60900, loss = 0.339338, learning_rate = 0.000003 (2594.8 examples/sec)
=> 2021-11-10 13:59:26.517052: step 61000, loss = 0.216912, learning_rate = 0.000003 (2579.1 examples/sec)
=> Model saved to file: ./logs_res/model-61000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.943679, best accuracy 0.943067
=> Model saved to file: ./logs_res/model-61000.pdparams
=> patience = 100
=> 2021-11-10 13:59:58.798861: step 61100, loss = 0.235409, learning_rate = 0.000003 (2585.8 examples/sec)
=> 2021-11-10 14:00:18.766885: step 61200, loss = 0.203856, learning_rate = 0.000003 (2585.5 examples/sec)
=> 2021-11-10 14:00:39.662023: step 61300, loss = 0.220094, learning_rate = 0.000003 (2599.1 examples/sec)
=> 2021-11-10 14:00:59.641973: step 61400, loss = 0.208045, learning_rate = 0.000003 (2584.5 examples/sec)
=> 2021-11-10 14:01:19.640515: step 61500, loss = 0.285281, learning_rate = 0.000003 (2581.4 examples/sec)
=> 2021-11-10 14:01:39.650523: step 61600, loss = 0.251128, learning_rate = 0.000003 (2580.1 examples/sec)
=> 2021-11-10 14:02:00.478254: step 61700, loss = 0.389954, learning_rate = 0.000003 (2596.6 examples/sec)
=> 2021-11-10 14:02:20.552504: step 61800, loss = 0.219345, learning_rate = 0.000003 (2571.9 examples/sec)
=> 2021-11-10 14:02:40.551498: step 61900, loss = 0.209066, learning_rate = 0.000003 (2581.5 examples/sec)
=> 2021-11-10 14:03:00.551519: step 62000, loss = 0.182009, learning_rate = 0.000003 (2581.2 examples/sec)
=> Model saved to file: ./logs_res/model-62000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941919, best accuracy 0.943679
=> patience = 99
=> 2021-11-10 14:03:32.581140: step 62100, loss = 0.246415, learning_rate = 0.000003 (2586.7 examples/sec)
=> 2021-11-10 14:03:53.527379: step 62200, loss = 0.248178, learning_rate = 0.000003 (2580.0 examples/sec)
=> 2021-11-10 14:04:13.558962: step 62300, loss = 0.301110, learning_rate = 0.000003 (2577.3 examples/sec)
=> 2021-11-10 14:04:33.545936: step 62400, loss = 0.167327, learning_rate = 0.000003 (2582.9 examples/sec)
=> 2021-11-10 14:04:53.550859: step 62500, loss = 0.326816, learning_rate = 0.000003 (2580.8 examples/sec)
=> 2021-11-10 14:05:14.356040: step 62600, loss = 0.179752, learning_rate = 0.000003 (2600.5 examples/sec)
=> 2021-11-10 14:05:34.356432: step 62700, loss = 0.213055, learning_rate = 0.000003 (2581.4 examples/sec)
=> 2021-11-10 14:05:54.346070: step 62800, loss = 0.205718, learning_rate = 0.000003 (2582.8 examples/sec)
=> 2021-11-10 14:06:14.358224: step 62900, loss = 0.196047, learning_rate = 0.000003 (2579.8 examples/sec)
=> 2021-11-10 14:06:35.209649: step 63000, loss = 0.294202, learning_rate = 0.000003 (2595.9 examples/sec)
=> Model saved to file: ./logs_res/model-63000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945286, best accuracy 0.943679
=> Model saved to file: ./logs_res/model-63000.pdparams
=> patience = 100
=> 2021-11-10 14:07:07.651735: step 63100, loss = 0.291131, learning_rate = 0.000003 (2582.3 examples/sec)
=> 2021-11-10 14:07:27.677695: step 63200, loss = 0.262511, learning_rate = 0.000002 (2578.2 examples/sec)
=> 2021-11-10 14:07:47.677837: step 63300, loss = 0.236456, learning_rate = 0.000002 (2581.6 examples/sec)
=> 2021-11-10 14:08:08.532239: step 63400, loss = 0.288272, learning_rate = 0.000002 (2594.2 examples/sec)
=> 2021-11-10 14:08:28.556833: step 63500, loss = 0.130098, learning_rate = 0.000002 (2578.3 examples/sec)
=> 2021-11-10 14:08:48.564684: step 63600, loss = 0.274416, learning_rate = 0.000002 (2580.6 examples/sec)
=> 2021-11-10 14:09:08.602365: step 63700, loss = 0.234704, learning_rate = 0.000002 (2576.6 examples/sec)
=> 2021-11-10 14:09:29.581156: step 63800, loss = 0.253975, learning_rate = 0.000002 (2596.5 examples/sec)
=> 2021-11-10 14:09:49.632087: step 63900, loss = 0.326518, learning_rate = 0.000002 (2574.8 examples/sec)
=> 2021-11-10 14:10:09.655482: step 64000, loss = 0.266029, learning_rate = 0.000002 (2577.8 examples/sec)
=> Model saved to file: ./logs_res/model-64000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944062, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:10:41.450531: step 64100, loss = 0.201370, learning_rate = 0.000002 (2582.7 examples/sec)
=> 2021-11-10 14:11:02.308883: step 64200, loss = 0.225680, learning_rate = 0.000002 (2596.6 examples/sec)
=> 2021-11-10 14:11:22.330711: step 64300, loss = 0.267186, learning_rate = 0.000002 (2578.9 examples/sec)
=> 2021-11-10 14:11:42.368287: step 64400, loss = 0.268392, learning_rate = 0.000002 (2576.8 examples/sec)
=> 2021-11-10 14:12:02.386983: step 64500, loss = 0.266839, learning_rate = 0.000002 (2579.4 examples/sec)
=> 2021-11-10 14:12:23.238107: step 64600, loss = 0.195230, learning_rate = 0.000002 (2596.2 examples/sec)
=> 2021-11-10 14:12:43.256825: step 64700, loss = 0.366424, learning_rate = 0.000002 (2579.0 examples/sec)
=> 2021-11-10 14:13:03.289810: step 64800, loss = 0.266226, learning_rate = 0.000002 (2577.6 examples/sec)
=> 2021-11-10 14:13:23.312025: step 64900, loss = 0.259216, learning_rate = 0.000002 (2578.6 examples/sec)
=> 2021-11-10 14:13:44.203051: step 65000, loss = 0.273824, learning_rate = 0.000002 (2593.8 examples/sec)
=> Model saved to file: ./logs_res/model-65000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944827, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:14:16.235369: step 65100, loss = 0.245192, learning_rate = 0.000002 (2585.9 examples/sec)
=> 2021-11-10 14:14:36.210994: step 65200, loss = 0.237364, learning_rate = 0.000002 (2584.7 examples/sec)
=> 2021-11-10 14:14:56.207224: step 65300, loss = 0.330870, learning_rate = 0.000002 (2582.1 examples/sec)
=> 2021-11-10 14:15:16.200593: step 65400, loss = 0.268708, learning_rate = 0.000002 (2582.4 examples/sec)
=> 2021-11-10 14:15:37.033709: step 65500, loss = 0.192790, learning_rate = 0.000002 (2597.7 examples/sec)
=> 2021-11-10 14:15:57.101146: step 65600, loss = 0.277243, learning_rate = 0.000002 (2572.7 examples/sec)
=> 2021-11-10 14:16:17.099722: step 65700, loss = 0.257222, learning_rate = 0.000002 (2581.6 examples/sec)
=> 2021-11-10 14:16:37.098470: step 65800, loss = 0.308888, learning_rate = 0.000002 (2581.6 examples/sec)
=> 2021-11-10 14:16:57.955571: step 65900, loss = 0.155783, learning_rate = 0.000002 (2594.1 examples/sec)
=> 2021-11-10 14:17:17.945623: step 66000, loss = 0.276832, learning_rate = 0.000002 (2582.9 examples/sec)
=> Model saved to file: ./logs_res/model-66000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944751, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:17:49.768077: step 66100, loss = 0.196851, learning_rate = 0.000002 (2587.0 examples/sec)
=> 2021-11-10 14:18:09.756632: step 66200, loss = 0.192984, learning_rate = 0.000002 (2582.8 examples/sec)
=> 2021-11-10 14:18:30.597969: step 66300, loss = 0.275876, learning_rate = 0.000002 (2596.4 examples/sec)
=> 2021-11-10 14:18:50.582170: step 66400, loss = 0.346838, learning_rate = 0.000002 (2583.5 examples/sec)
=> 2021-11-10 14:19:10.579277: step 66500, loss = 0.225250, learning_rate = 0.000002 (2582.1 examples/sec)
=> 2021-11-10 14:19:30.564347: step 66600, loss = 0.329439, learning_rate = 0.000002 (2583.5 examples/sec)
=> 2021-11-10 14:19:51.399501: step 66700, loss = 0.287080, learning_rate = 0.000002 (2595.3 examples/sec)
=> 2021-11-10 14:20:11.407375: step 66800, loss = 0.178711, learning_rate = 0.000002 (2580.4 examples/sec)
=> 2021-11-10 14:20:31.421137: step 66900, loss = 0.177369, learning_rate = 0.000002 (2580.0 examples/sec)
=> 2021-11-10 14:20:51.418739: step 67000, loss = 0.202156, learning_rate = 0.000002 (2581.6 examples/sec)
=> Model saved to file: ./logs_res/model-67000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944521, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:21:24.028108: step 67100, loss = 0.218565, learning_rate = 0.000002 (2599.3 examples/sec)
=> 2021-11-10 14:21:44.009975: step 67200, loss = 0.209514, learning_rate = 0.000001 (2583.8 examples/sec)
=> 2021-11-10 14:22:04.003522: step 67300, loss = 0.196319, learning_rate = 0.000001 (2582.3 examples/sec)
=> 2021-11-10 14:22:23.992823: step 67400, loss = 0.275562, learning_rate = 0.000001 (2582.8 examples/sec)
=> 2021-11-10 14:22:44.959027: step 67500, loss = 0.225425, learning_rate = 0.000001 (2596.6 examples/sec)
=> 2021-11-10 14:23:04.971970: step 67600, loss = 0.118955, learning_rate = 0.000001 (2579.7 examples/sec)
=> 2021-11-10 14:23:24.981869: step 67700, loss = 0.352484, learning_rate = 0.000001 (2580.2 examples/sec)
=> 2021-11-10 14:23:45.001835: step 67800, loss = 0.204795, learning_rate = 0.000001 (2578.9 examples/sec)
=> 2021-11-10 14:24:05.866862: step 67900, loss = 0.149410, learning_rate = 0.000001 (2594.3 examples/sec)
=> 2021-11-10 14:24:25.908109: step 68000, loss = 0.348722, learning_rate = 0.000001 (2576.4 examples/sec)
=> Model saved to file: ./logs_res/model-68000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944368, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:24:57.930318: step 68100, loss = 0.196532, learning_rate = 0.000001 (2586.1 examples/sec)
=> 2021-11-10 14:25:17.900581: step 68200, loss = 0.260866, learning_rate = 0.000001 (2585.3 examples/sec)
=> 2021-11-10 14:25:37.893264: step 68300, loss = 0.207771, learning_rate = 0.000001 (2582.5 examples/sec)
=> 2021-11-10 14:25:58.729307: step 68400, loss = 0.238089, learning_rate = 0.000001 (2594.9 examples/sec)
=> 2021-11-10 14:26:18.736428: step 68500, loss = 0.208147, learning_rate = 0.000001 (2580.6 examples/sec)
=> 2021-11-10 14:26:38.735862: step 68600, loss = 0.218153, learning_rate = 0.000001 (2581.6 examples/sec)
=> 2021-11-10 14:26:58.721349: step 68700, loss = 0.192108, learning_rate = 0.000001 (2583.3 examples/sec)
=> 2021-11-10 14:27:19.748150: step 68800, loss = 0.235034, learning_rate = 0.000001 (2595.1 examples/sec)
=> 2021-11-10 14:27:39.771740: step 68900, loss = 0.310701, learning_rate = 0.000001 (2578.4 examples/sec)
=> 2021-11-10 14:27:59.778788: step 69000, loss = 0.197020, learning_rate = 0.000001 (2580.7 examples/sec)
=> Model saved to file: ./logs_res/model-69000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945286, best accuracy 0.945286
=> patience = 99
=> 2021-11-10 14:28:31.574971: step 69100, loss = 0.170346, learning_rate = 0.000001 (2583.8 examples/sec)
=> 2021-11-10 14:28:52.448007: step 69200, loss = 0.226890, learning_rate = 0.000001 (2595.8 examples/sec)
=> 2021-11-10 14:29:12.452507: step 69300, loss = 0.227926, learning_rate = 0.000001 (2580.8 examples/sec)
=> 2021-11-10 14:29:32.448127: step 69400, loss = 0.209909, learning_rate = 0.000001 (2582.1 examples/sec)
=> 2021-11-10 14:29:52.447849: step 69500, loss = 0.215501, learning_rate = 0.000001 (2581.7 examples/sec)
=> 2021-11-10 14:30:13.268606: step 69600, loss = 0.130057, learning_rate = 0.000001 (2598.3 examples/sec)
=> 2021-11-10 14:30:33.276926: step 69700, loss = 0.202076, learning_rate = 0.000001 (2580.3 examples/sec)
=> 2021-11-10 14:30:53.337877: step 69800, loss = 0.283280, learning_rate = 0.000001 (2573.9 examples/sec)
=> 2021-11-10 14:31:13.343196: step 69900, loss = 0.226965, learning_rate = 0.000001 (2580.8 examples/sec)
=> 2021-11-10 14:31:34.148055: step 70000, loss = 0.309913, learning_rate = 0.000001 (2598.5 examples/sec)
=> Model saved to file: ./logs_res/model-70000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946281, best accuracy 0.945286
=> Model saved to file: ./logs_res/model-70000.pdparams
=> patience = 100
=> 2021-11-10 14:32:06.674446: step 70100, loss = 0.238351, learning_rate = 0.000001 (2585.1 examples/sec)
=> 2021-11-10 14:32:26.658477: step 70200, loss = 0.224777, learning_rate = 0.000001 (2583.6 examples/sec)
=> 2021-11-10 14:32:46.649847: step 70300, loss = 0.218467, learning_rate = 0.000001 (2582.6 examples/sec)
=> 2021-11-10 14:33:07.540925: step 70400, loss = 0.342342, learning_rate = 0.000001 (2596.5 examples/sec)
=> 2021-11-10 14:33:27.550534: step 70500, loss = 0.229608, learning_rate = 0.000001 (2580.3 examples/sec)
=> 2021-11-10 14:33:47.556513: step 70600, loss = 0.257675, learning_rate = 0.000001 (2580.7 examples/sec)
=> 2021-11-10 14:34:07.554289: step 70700, loss = 0.243744, learning_rate = 0.000001 (2581.8 examples/sec)
=> 2021-11-10 14:34:28.367345: step 70800, loss = 0.229863, learning_rate = 0.000001 (2599.3 examples/sec)
=> 2021-11-10 14:34:48.349730: step 70900, loss = 0.184713, learning_rate = 0.000001 (2583.8 examples/sec)
=> 2021-11-10 14:35:08.353850: step 71000, loss = 0.157607, learning_rate = 0.000001 (2581.1 examples/sec)
=> Model saved to file: ./logs_res/model-71000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944980, best accuracy 0.946281
=> patience = 99
=> 2021-11-10 14:35:40.149656: step 71100, loss = 0.211925, learning_rate = 0.000001 (2586.1 examples/sec)
=> 2021-11-10 14:36:00.114985: step 71200, loss = 0.249754, learning_rate = 0.000001 (2586.5 examples/sec)
=> 2021-11-10 14:36:20.929353: step 71300, loss = 0.173075, learning_rate = 0.000001 (2597.2 examples/sec)
=> 2021-11-10 14:36:40.924523: step 71400, loss = 0.218060, learning_rate = 0.000001 (2582.0 examples/sec)
=> 2021-11-10 14:37:00.916237: step 71500, loss = 0.209504, learning_rate = 0.000001 (2582.3 examples/sec)
=> 2021-11-10 14:37:20.913618: step 71600, loss = 0.274041, learning_rate = 0.000001 (2581.7 examples/sec)
=> 2021-11-10 14:37:41.776680: step 71700, loss = 0.217585, learning_rate = 0.000001 (2598.0 examples/sec)
=> 2021-11-10 14:38:01.779796: step 71800, loss = 0.233531, learning_rate = 0.000001 (2581.3 examples/sec)
=> 2021-11-10 14:38:21.794462: step 71900, loss = 0.215106, learning_rate = 0.000001 (2579.8 examples/sec)
=> 2021-11-10 14:38:41.818206: step 72000, loss = 0.275294, learning_rate = 0.000001 (2578.5 examples/sec)
=> Model saved to file: ./logs_res/model-72000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946587, best accuracy 0.946281
=> Model saved to file: ./logs_res/model-72000.pdparams
=> patience = 100
=> 2021-11-10 14:39:15.143112: step 72100, loss = 0.290004, learning_rate = 0.000001 (2601.8 examples/sec)
=> 2021-11-10 14:39:35.140099: step 72200, loss = 0.186195, learning_rate = 0.000001 (2582.0 examples/sec)
=> 2021-11-10 14:39:55.124160: step 72300, loss = 0.217199, learning_rate = 0.000001 (2583.3 examples/sec)
=> 2021-11-10 14:40:15.111296: step 72400, loss = 0.299627, learning_rate = 0.000001 (2583.1 examples/sec)
=> 2021-11-10 14:40:35.937277: step 72500, loss = 0.139950, learning_rate = 0.000001 (2597.7 examples/sec)
=> 2021-11-10 14:40:55.926240: step 72600, loss = 0.328950, learning_rate = 0.000001 (2582.8 examples/sec)
=> 2021-11-10 14:41:15.930040: step 72700, loss = 0.187376, learning_rate = 0.000001 (2580.9 examples/sec)
=> 2021-11-10 14:41:35.921909: step 72800, loss = 0.172779, learning_rate = 0.000001 (2582.5 examples/sec)
=> 2021-11-10 14:41:56.747133: step 72900, loss = 0.364552, learning_rate = 0.000001 (2616.3 examples/sec)
=> 2021-11-10 14:42:16.762652: step 73000, loss = 0.209035, learning_rate = 0.000001 (2579.6 examples/sec)
=> Model saved to file: ./logs_res/model-73000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946970, best accuracy 0.946587
=> Model saved to file: ./logs_res/model-73000.pdparams
=> patience = 100
=> 2021-11-10 14:42:48.967232: step 73100, loss = 0.239588, learning_rate = 0.000001 (2585.0 examples/sec)
=> 2021-11-10 14:43:08.950437: step 73200, loss = 0.267193, learning_rate = 0.000001 (2583.7 examples/sec)
=> 2021-11-10 14:43:29.748944: step 73300, loss = 0.172150, learning_rate = 0.000001 (2599.6 examples/sec)
=> 2021-11-10 14:43:49.729529: step 73400, loss = 0.240907, learning_rate = 0.000001 (2584.0 examples/sec)
=> 2021-11-10 14:44:09.717277: step 73500, loss = 0.256078, learning_rate = 0.000001 (2583.0 examples/sec)
=> 2021-11-10 14:44:29.706927: step 73600, loss = 0.297949, learning_rate = 0.000001 (2582.8 examples/sec)
=> 2021-11-10 14:44:50.539956: step 73700, loss = 0.120961, learning_rate = 0.000001 (2596.0 examples/sec)
=> 2021-11-10 14:45:10.536647: step 73800, loss = 0.157271, learning_rate = 0.000001 (2581.8 examples/sec)
=> 2021-11-10 14:45:30.537921: step 73900, loss = 0.185758, learning_rate = 0.000001 (2581.1 examples/sec)
=> 2021-11-10 14:45:50.535347: step 74000, loss = 0.287979, learning_rate = 0.000001 (2582.0 examples/sec)
=> Model saved to file: ./logs_res/model-74000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947658, best accuracy 0.946970
=> Model saved to file: ./logs_res/model-74000.pdparams
=> patience = 100
=> 2021-11-10 14:46:22.880826: step 74100, loss = 0.235742, learning_rate = 0.000001 (2585.9 examples/sec)
=> 2021-11-10 14:46:43.800983: step 74200, loss = 0.250983, learning_rate = 0.000001 (2598.4 examples/sec)
=> 2021-11-10 14:47:03.800299: step 74300, loss = 0.139446, learning_rate = 0.000001 (2581.5 examples/sec)
=> 2021-11-10 14:47:23.788888: step 74400, loss = 0.172507, learning_rate = 0.000001 (2582.8 examples/sec)
=> 2021-11-10 14:47:43.779879: step 74500, loss = 0.210762, learning_rate = 0.000001 (2582.7 examples/sec)
=> 2021-11-10 14:48:04.613623: step 74600, loss = 0.229239, learning_rate = 0.000001 (2596.4 examples/sec)
=> 2021-11-10 14:48:24.613305: step 74700, loss = 0.170760, learning_rate = 0.000001 (2581.6 examples/sec)
=> 2021-11-10 14:48:44.618287: step 74800, loss = 0.246827, learning_rate = 0.000001 (2580.9 examples/sec)
=> 2021-11-10 14:49:04.620237: step 74900, loss = 0.238824, learning_rate = 0.000001 (2581.4 examples/sec)
=> 2021-11-10 14:49:25.439076: step 75000, loss = 0.257684, learning_rate = 0.000001 (2600.4 examples/sec)
=> Model saved to file: ./logs_res/model-75000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946970, best accuracy 0.947658
=> patience = 99
=> 2021-11-10 14:49:57.041753: step 75100, loss = 0.267827, learning_rate = 0.000001 (2584.7 examples/sec)
=> 2021-11-10 14:50:17.018445: step 75200, loss = 0.227334, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-10 14:50:37.002728: step 75300, loss = 0.339412, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 14:50:57.842073: step 75400, loss = 0.171306, learning_rate = 0.000000 (2597.0 examples/sec)
=> 2021-11-10 14:51:17.834118: step 75500, loss = 0.147121, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 14:51:37.825141: step 75600, loss = 0.176391, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-10 14:51:57.820689: step 75700, loss = 0.196393, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 14:52:18.652075: step 75800, loss = 0.201614, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-10 14:52:38.656962: step 75900, loss = 0.193719, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 14:52:58.667597: step 76000, loss = 0.165761, learning_rate = 0.000000 (2580.1 examples/sec)
=> Model saved to file: ./logs_res/model-76000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946204, best accuracy 0.947658
=> patience = 99
=> 2021-11-10 14:53:30.429989: step 76100, loss = 0.222428, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-10 14:53:51.208967: step 76200, loss = 0.163775, learning_rate = 0.000000 (2601.6 examples/sec)
=> 2021-11-10 14:54:11.204008: step 76300, loss = 0.143434, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-10 14:54:31.186108: step 76400, loss = 0.227912, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 14:54:51.182979: step 76500, loss = 0.194479, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-10 14:55:12.042705: step 76600, loss = 0.195282, learning_rate = 0.000000 (2596.0 examples/sec)
=> 2021-11-10 14:55:32.097480: step 76700, loss = 0.167534, learning_rate = 0.000000 (2574.7 examples/sec)
=> 2021-11-10 14:55:52.127368: step 76800, loss = 0.141099, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-10 14:56:12.148294: step 76900, loss = 0.162479, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-10 14:56:32.176964: step 77000, loss = 0.169588, learning_rate = 0.000000 (2578.6 examples/sec)
=> Model saved to file: ./logs_res/model-77000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945898, best accuracy 0.947658
=> patience = 99
=> 2021-11-10 14:57:04.905388: step 77100, loss = 0.169550, learning_rate = 0.000000 (2597.9 examples/sec)
=> 2021-11-10 14:57:24.877515: step 77200, loss = 0.149357, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 14:57:44.859121: step 77300, loss = 0.278264, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 14:58:04.847158: step 77400, loss = 0.156771, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-10 14:58:25.789856: step 77500, loss = 0.181673, learning_rate = 0.000000 (2599.0 examples/sec)
=> 2021-11-10 14:58:45.769180: step 77600, loss = 0.160151, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-10 14:59:05.754822: step 77700, loss = 0.273301, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 14:59:25.748131: step 77800, loss = 0.175372, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 14:59:46.565621: step 77900, loss = 0.196507, learning_rate = 0.000000 (2599.2 examples/sec)
=> 2021-11-10 15:00:06.557025: step 78000, loss = 0.226221, learning_rate = 0.000000 (2582.4 examples/sec)
=> Model saved to file: ./logs_res/model-78000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946051, best accuracy 0.947658
=> patience = 99
=> 2021-11-10 15:00:38.599875: step 78100, loss = 0.220200, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-10 15:00:58.596052: step 78200, loss = 0.153995, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 15:01:19.486137: step 78300, loss = 0.199828, learning_rate = 0.000000 (2597.3 examples/sec)
=> 2021-11-10 15:01:39.464135: step 78400, loss = 0.313863, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 15:01:59.464905: step 78500, loss = 0.202280, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-10 15:02:19.461633: step 78600, loss = 0.250648, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 15:02:40.299456: step 78700, loss = 0.226664, learning_rate = 0.000000 (2595.8 examples/sec)
=> 2021-11-10 15:03:00.340547: step 78800, loss = 0.213633, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-10 15:03:20.378047: step 78900, loss = 0.250101, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-10 15:03:40.426822: step 79000, loss = 0.134464, learning_rate = 0.000000 (2575.6 examples/sec)
=> Model saved to file: ./logs_res/model-79000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948118, best accuracy 0.947658
=> Model saved to file: ./logs_res/model-79000.pdparams
=> patience = 100
=> 2021-11-10 15:04:15.146779: step 79100, loss = 0.199377, learning_rate = 0.000000 (2653.1 examples/sec)
=> 2021-11-10 15:04:35.113861: step 79200, loss = 0.248940, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 15:04:59.369819: step 79300, loss = 0.187805, learning_rate = 0.000000 (2764.7 examples/sec)
=> 2021-11-10 15:05:19.496024: step 79400, loss = 0.160910, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-10 15:05:40.304714: step 79500, loss = 0.230410, learning_rate = 0.000000 (2598.3 examples/sec)
=> 2021-11-10 15:06:00.311397: step 79600, loss = 0.213212, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-10 15:06:20.418660: step 79700, loss = 0.184771, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-10 15:06:40.425418: step 79800, loss = 0.136738, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-10 15:07:00.426432: step 79900, loss = 0.208894, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 15:07:21.236777: step 80000, loss = 0.138252, learning_rate = 0.000000 (2615.2 examples/sec)
=> Model saved to file: ./logs_res/model-80000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947429, best accuracy 0.948118
=> patience = 99
=> 2021-11-10 15:07:53.314784: step 80100, loss = 0.255583, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 15:08:13.310195: step 80200, loss = 0.199420, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 15:08:33.310324: step 80300, loss = 0.170080, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-10 15:08:54.206601: step 80400, loss = 0.165991, learning_rate = 0.000000 (2596.4 examples/sec)
=> 2021-11-10 15:09:14.206653: step 80500, loss = 0.168759, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-10 15:09:34.225888: step 80600, loss = 0.168052, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-10 15:09:54.230719: step 80700, loss = 0.247498, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 15:10:15.066067: step 80800, loss = 0.197773, learning_rate = 0.000000 (2597.2 examples/sec)
=> 2021-11-10 15:10:35.087786: step 80900, loss = 0.124441, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-10 15:10:55.110087: step 81000, loss = 0.159203, learning_rate = 0.000000 (2578.7 examples/sec)
=> Model saved to file: ./logs_res/model-81000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947123, best accuracy 0.948118
=> patience = 99
=> 2021-11-10 15:11:26.615219: step 81100, loss = 0.185611, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-10 15:11:47.436431: step 81200, loss = 0.181584, learning_rate = 0.000000 (2599.4 examples/sec)
=> 2021-11-10 15:12:07.417775: step 81300, loss = 0.212867, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-10 15:12:27.436375: step 81400, loss = 0.255538, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-10 15:12:47.430820: step 81500, loss = 0.228416, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 15:13:08.228865: step 81600, loss = 0.162832, learning_rate = 0.000000 (2600.2 examples/sec)
=> 2021-11-10 15:13:28.229678: step 81700, loss = 0.171901, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-10 15:13:48.240876: step 81800, loss = 0.160901, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-10 15:14:08.249177: step 81900, loss = 0.191475, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-10 15:14:32.698737: step 82000, loss = 0.200829, learning_rate = 0.000000 (2715.0 examples/sec)
=> Model saved to file: ./logs_res/model-82000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946281, best accuracy 0.948118
=> patience = 99
=> 2021-11-10 15:15:09.184793: step 82100, loss = 0.252880, learning_rate = 0.000000 (2811.8 examples/sec)
=> 2021-11-10 15:15:29.142097: step 82200, loss = 0.266270, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 15:15:49.131863: step 82300, loss = 0.280667, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 15:16:16.604595: step 82400, loss = 0.190476, learning_rate = 0.000000 (3051.3 examples/sec)
=> 2021-11-10 15:16:37.434442: step 82500, loss = 0.192304, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-10 15:16:57.424074: step 82600, loss = 0.252689, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-10 15:17:25.972840: step 82700, loss = 0.171337, learning_rate = 0.000000 (3049.7 examples/sec)
=> 2021-11-10 15:17:52.963557: step 82800, loss = 0.169549, learning_rate = 0.000000 (3049.3 examples/sec)
=> 2021-11-10 15:18:22.563281: step 82900, loss = 0.195227, learning_rate = 0.000000 (3052.9 examples/sec)
=> 2021-11-10 15:18:46.501226: step 83000, loss = 0.198492, learning_rate = 0.000000 (2804.8 examples/sec)
=> Model saved to file: ./logs_res/model-83000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949112, best accuracy 0.948118
=> Model saved to file: ./logs_res/model-83000.pdparams
=> patience = 100
=> 2021-11-10 15:19:21.323856: step 83100, loss = 0.204679, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-10 15:19:41.273475: step 83200, loss = 0.226503, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 15:20:02.183034: step 83300, loss = 0.203731, learning_rate = 0.000000 (2600.2 examples/sec)
=> 2021-11-10 15:20:22.155106: step 83400, loss = 0.208148, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 15:20:42.177300: step 83500, loss = 0.189692, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-10 15:21:02.213168: step 83600, loss = 0.197878, learning_rate = 0.000000 (2577.0 examples/sec)
=> 2021-11-10 15:21:23.082221: step 83700, loss = 0.218454, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-10 15:21:43.112799: step 83800, loss = 0.169657, learning_rate = 0.000000 (2577.8 examples/sec)
=> 2021-11-10 15:22:03.134847: step 83900, loss = 0.187954, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-10 15:22:23.185342: step 84000, loss = 0.206886, learning_rate = 0.000000 (2584.6 examples/sec)
=> Model saved to file: ./logs_res/model-84000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948806, best accuracy 0.949112
=> patience = 99
=> 2021-11-10 15:22:56.209066: step 84100, loss = 0.121463, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-10 15:23:16.189818: step 84200, loss = 0.152543, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-10 15:23:36.154178: step 84300, loss = 0.209345, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 15:23:56.130149: step 84400, loss = 0.287556, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 15:24:16.992661: step 84500, loss = 0.163719, learning_rate = 0.000000 (2600.3 examples/sec)
=> 2021-11-10 15:24:36.976910: step 84600, loss = 0.237453, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 15:24:56.970490: step 84700, loss = 0.167182, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 15:25:16.955998: step 84800, loss = 0.181947, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 15:25:37.768328: step 84900, loss = 0.206353, learning_rate = 0.000000 (2598.9 examples/sec)
=> 2021-11-10 15:25:57.766507: step 85000, loss = 0.182126, learning_rate = 0.000000 (2581.7 examples/sec)
=> Model saved to file: ./logs_res/model-85000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947658, best accuracy 0.949112
=> patience = 99
=> 2021-11-10 15:26:29.513379: step 85100, loss = 0.187572, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 15:26:49.509964: step 85200, loss = 0.219745, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 15:27:10.363313: step 85300, loss = 0.260339, learning_rate = 0.000000 (2598.6 examples/sec)
=> 2021-11-10 15:27:30.408001: step 85400, loss = 0.259403, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-10 15:27:50.414092: step 85500, loss = 0.229604, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-10 15:28:10.436514: step 85600, loss = 0.117122, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-10 15:28:31.440177: step 85700, loss = 0.191552, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-10 15:28:51.423971: step 85800, loss = 0.129348, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 15:29:11.410839: step 85900, loss = 0.210681, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 15:29:31.409469: step 86000, loss = 0.191445, learning_rate = 0.000000 (2582.2 examples/sec)
=> Model saved to file: ./logs_res/model-86000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.949112
=> Model saved to file: ./logs_res/model-86000.pdparams
=> patience = 100
=> 2021-11-10 15:30:04.049958: step 86100, loss = 0.109535, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 15:30:24.831519: step 86200, loss = 0.188003, learning_rate = 0.000000 (2601.3 examples/sec)
=> 2021-11-10 15:30:44.810233: step 86300, loss = 0.264719, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 15:31:04.785256: step 86400, loss = 0.188626, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 15:31:24.770219: step 86500, loss = 0.171187, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 15:31:45.611034: step 86600, loss = 0.130091, learning_rate = 0.000000 (2596.8 examples/sec)
=> 2021-11-10 15:32:05.631690: step 86700, loss = 0.269894, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-10 15:32:25.647794: step 86800, loss = 0.134000, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-10 15:32:45.659463: step 86900, loss = 0.282093, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-10 15:33:06.613090: step 87000, loss = 0.147254, learning_rate = 0.000000 (2582.9 examples/sec)
=> Model saved to file: ./logs_res/model-87000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947811, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:33:38.170027: step 87100, loss = 0.225741, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 15:33:58.169271: step 87200, loss = 0.170129, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-10 15:34:18.168358: step 87300, loss = 0.225155, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-10 15:34:39.009578: step 87400, loss = 0.253604, learning_rate = 0.000000 (2597.2 examples/sec)
=> 2021-11-10 15:34:59.020898: step 87500, loss = 0.122089, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-10 15:35:19.048893: step 87600, loss = 0.186585, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-10 15:35:39.056061: step 87700, loss = 0.193448, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-10 15:36:00.046033: step 87800, loss = 0.183070, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 15:36:20.069596: step 87900, loss = 0.191576, learning_rate = 0.000000 (2578.9 examples/sec)
=> 2021-11-10 15:36:40.048126: step 88000, loss = 0.207191, learning_rate = 0.000000 (2584.3 examples/sec)
=> Model saved to file: ./logs_res/model-88000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:37:12.697416: step 88100, loss = 0.207974, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 15:37:33.497618: step 88200, loss = 0.165152, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-10 15:37:53.464183: step 88300, loss = 0.224085, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 15:38:13.442367: step 88400, loss = 0.110622, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 15:38:33.407600: step 88500, loss = 0.119611, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 15:38:54.242467: step 88600, loss = 0.118913, learning_rate = 0.000000 (2598.8 examples/sec)
=> 2021-11-10 15:39:14.252297: step 88700, loss = 0.359179, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-10 15:39:34.268152: step 88800, loss = 0.160050, learning_rate = 0.000000 (2579.5 examples/sec)
=> 2021-11-10 15:39:54.281255: step 88900, loss = 0.189975, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-10 15:40:14.304610: step 89000, loss = 0.161732, learning_rate = 0.000000 (2579.0 examples/sec)
=> Model saved to file: ./logs_res/model-89000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948883, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:40:47.595562: step 89100, loss = 0.155399, learning_rate = 0.000000 (2595.4 examples/sec)
=> 2021-11-10 15:41:07.590895: step 89200, loss = 0.219511, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 15:41:27.627215: step 89300, loss = 0.166988, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-10 15:41:47.651003: step 89400, loss = 0.167569, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-10 15:42:08.541143: step 89500, loss = 0.158845, learning_rate = 0.000000 (2598.1 examples/sec)
=> 2021-11-10 15:42:28.561471: step 89600, loss = 0.230651, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-10 15:42:48.588697: step 89700, loss = 0.178685, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-10 15:43:08.612556: step 89800, loss = 0.215921, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-10 15:43:29.544114: step 89900, loss = 0.157317, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 15:43:49.537546: step 90000, loss = 0.152622, learning_rate = 0.000000 (2582.7 examples/sec)
=> Model saved to file: ./logs_res/model-90000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949495, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:44:21.919344: step 90100, loss = 0.180372, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 15:44:41.912727: step 90200, loss = 0.190019, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 15:45:02.838215: step 90300, loss = 0.168405, learning_rate = 0.000000 (2598.3 examples/sec)
=> 2021-11-10 15:45:22.833433: step 90400, loss = 0.117244, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-10 15:45:42.828824: step 90500, loss = 0.195300, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-10 15:46:02.826780: step 90600, loss = 0.196565, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-10 15:46:23.713662: step 90700, loss = 0.178905, learning_rate = 0.000000 (2593.5 examples/sec)
=> 2021-11-10 15:46:43.760918: step 90800, loss = 0.224109, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-10 15:47:03.824241: step 90900, loss = 0.150611, learning_rate = 0.000000 (2573.7 examples/sec)
=> 2021-11-10 15:47:23.855550: step 91000, loss = 0.121962, learning_rate = 0.000000 (2577.9 examples/sec)
=> Model saved to file: ./logs_res/model-91000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948653, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:47:56.858867: step 91100, loss = 0.192034, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 15:48:16.832997: step 91200, loss = 0.260961, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 15:48:36.851682: step 91300, loss = 0.204775, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-10 15:48:56.888859: step 91400, loss = 0.176706, learning_rate = 0.000000 (2577.1 examples/sec)
=> 2021-11-10 15:49:17.756924: step 91500, loss = 0.168218, learning_rate = 0.000000 (2597.6 examples/sec)
=> 2021-11-10 15:49:37.759920: step 91600, loss = 0.185664, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-10 15:49:57.802488: step 91700, loss = 0.243277, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-10 15:50:17.806695: step 91800, loss = 0.247458, learning_rate = 0.000000 (2581.3 examples/sec)
=> 2021-11-10 15:50:37.794947: step 91900, loss = 0.172958, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 15:50:58.854222: step 92000, loss = 0.229797, learning_rate = 0.000000 (2597.0 examples/sec)
=> Model saved to file: ./logs_res/model-92000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948194, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:51:30.863673: step 92100, loss = 0.130885, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 15:51:50.890414: step 92200, loss = 0.149603, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-10 15:52:10.903222: step 92300, loss = 0.182339, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-10 15:52:31.749548: step 92400, loss = 0.221743, learning_rate = 0.000000 (2599.0 examples/sec)
=> 2021-11-10 15:52:51.735797: step 92500, loss = 0.150964, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 15:53:11.738675: step 92600, loss = 0.211407, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-10 15:53:31.738997: step 92700, loss = 0.245781, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 15:53:52.650754: step 92800, loss = 0.158758, learning_rate = 0.000000 (2598.7 examples/sec)
=> 2021-11-10 15:54:12.688550: step 92900, loss = 0.147330, learning_rate = 0.000000 (2577.0 examples/sec)
=> 2021-11-10 15:54:32.694710: step 93000, loss = 0.112679, learning_rate = 0.000000 (2581.2 examples/sec)
=> Model saved to file: ./logs_res/model-93000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948959, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:55:04.575419: step 93100, loss = 0.135595, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 15:55:25.593053: step 93200, loss = 0.164189, learning_rate = 0.000000 (2594.7 examples/sec)
=> 2021-11-10 15:55:45.555952: step 93300, loss = 0.153513, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 15:56:05.542637: step 93400, loss = 0.163043, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 15:56:25.591698: step 93500, loss = 0.173004, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-10 15:56:46.441566: step 93600, loss = 0.145842, learning_rate = 0.000000 (2598.4 examples/sec)
=> 2021-11-10 15:57:06.426892: step 93700, loss = 0.171931, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 15:57:26.445873: step 93800, loss = 0.168314, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-10 15:57:46.463395: step 93900, loss = 0.155888, learning_rate = 0.000000 (2579.5 examples/sec)
=> 2021-11-10 15:58:07.344125: step 94000, loss = 0.210176, learning_rate = 0.000000 (2594.4 examples/sec)
=> Model saved to file: ./logs_res/model-94000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949265, best accuracy 0.950184
=> patience = 99
=> 2021-11-10 15:58:39.405519: step 94100, loss = 0.127928, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-10 15:58:59.438534: step 94200, loss = 0.162139, learning_rate = 0.000000 (2578.3 examples/sec)
=> 2021-11-10 15:59:19.408357: step 94300, loss = 0.131504, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 15:59:40.241630: step 94400, loss = 0.145753, learning_rate = 0.000000 (2600.3 examples/sec)
=> 2021-11-10 16:00:00.207965: step 94500, loss = 0.193137, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 16:00:20.180914: step 94600, loss = 0.155690, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 16:00:40.165670: step 94700, loss = 0.203012, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 16:01:00.132810: step 94800, loss = 0.153545, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 16:01:21.005045: step 94900, loss = 0.173301, learning_rate = 0.000000 (2598.2 examples/sec)
=> 2021-11-10 16:01:41.069498: step 95000, loss = 0.207834, learning_rate = 0.000000 (2574.5 examples/sec)
=> Model saved to file: ./logs_res/model-95000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950872, best accuracy 0.950184
=> Model saved to file: ./logs_res/model-95000.pdparams
=> patience = 100
=> 2021-11-10 16:02:13.483737: step 95100, loss = 0.146710, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 16:02:33.431334: step 95200, loss = 0.149529, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 16:02:54.412697: step 95300, loss = 0.143233, learning_rate = 0.000000 (2593.7 examples/sec)
=> 2021-11-10 16:03:14.371547: step 95400, loss = 0.179989, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 16:03:34.349022: step 95500, loss = 0.229050, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 16:03:54.336297: step 95600, loss = 0.114300, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 16:04:15.134179: step 95700, loss = 0.221871, learning_rate = 0.000000 (2602.0 examples/sec)
=> 2021-11-10 16:04:35.109355: step 95800, loss = 0.137586, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 16:04:55.103195: step 95900, loss = 0.125062, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 16:05:15.085276: step 96000, loss = 0.277820, learning_rate = 0.000000 (2583.9 examples/sec)
=> Model saved to file: ./logs_res/model-96000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950413, best accuracy 0.950872
=> patience = 99
=> 2021-11-10 16:05:47.716796: step 96100, loss = 0.253489, learning_rate = 0.000000 (2599.3 examples/sec)
=> 2021-11-10 16:06:07.666689: step 96200, loss = 0.213453, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 16:06:27.630215: step 96300, loss = 0.163729, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 16:06:47.611963: step 96400, loss = 0.188967, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 16:07:08.435284: step 96500, loss = 0.213288, learning_rate = 0.000000 (2598.7 examples/sec)
=> 2021-11-10 16:07:28.402667: step 96600, loss = 0.164628, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 16:07:48.387597: step 96700, loss = 0.200947, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 16:08:08.384448: step 96800, loss = 0.143196, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-10 16:08:29.295498: step 96900, loss = 0.103839, learning_rate = 0.000000 (2598.9 examples/sec)
=> 2021-11-10 16:08:49.277925: step 97000, loss = 0.184851, learning_rate = 0.000000 (2583.8 examples/sec)
=> Model saved to file: ./logs_res/model-97000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.950872
=> patience = 99
=> 2021-11-10 16:09:21.135556: step 97100, loss = 0.151544, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 16:09:41.093342: step 97200, loss = 0.125735, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 16:10:01.937711: step 97300, loss = 0.195738, learning_rate = 0.000000 (2599.2 examples/sec)
=> 2021-11-10 16:10:21.958013: step 97400, loss = 0.160017, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-10 16:10:41.990812: step 97500, loss = 0.133890, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-10 16:11:01.988716: step 97600, loss = 0.285448, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 16:11:21.987764: step 97700, loss = 0.117444, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 16:11:42.849928: step 97800, loss = 0.181208, learning_rate = 0.000000 (2593.7 examples/sec)
=> 2021-11-10 16:12:02.842582: step 97900, loss = 0.161699, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 16:12:22.839062: step 98000, loss = 0.147211, learning_rate = 0.000000 (2582.1 examples/sec)
=> Model saved to file: ./logs_res/model-98000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.950872
=> patience = 99
=> 2021-11-10 16:12:54.960788: step 98100, loss = 0.123203, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 16:13:15.790775: step 98200, loss = 0.131777, learning_rate = 0.000000 (2599.3 examples/sec)
=> 2021-11-10 16:13:35.791792: step 98300, loss = 0.121855, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-10 16:13:55.780754: step 98400, loss = 0.169288, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 16:14:15.766006: step 98500, loss = 0.157311, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 16:14:36.804886: step 98600, loss = 0.203759, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-10 16:14:56.799346: step 98700, loss = 0.140747, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 16:15:16.783968: step 98800, loss = 0.160589, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 16:15:36.791886: step 98900, loss = 0.190385, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-10 16:15:57.670500: step 99000, loss = 0.087227, learning_rate = 0.000000 (2597.9 examples/sec)
=> Model saved to file: ./logs_res/model-99000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.950872
=> patience = 99
=> 2021-11-10 16:16:29.730365: step 99100, loss = 0.087586, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 16:16:49.758665: step 99200, loss = 0.218804, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 16:17:09.768423: step 99300, loss = 0.144423, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-10 16:17:30.810359: step 99400, loss = 0.183349, learning_rate = 0.000000 (2591.8 examples/sec)
=> 2021-11-10 16:17:50.860310: step 99500, loss = 0.245434, learning_rate = 0.000000 (2575.7 examples/sec)
=> 2021-11-10 16:18:10.888582: step 99600, loss = 0.120462, learning_rate = 0.000000 (2578.4 examples/sec)
=> 2021-11-10 16:18:30.898739: step 99700, loss = 0.234426, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-10 16:18:51.738127: step 99800, loss = 0.148939, learning_rate = 0.000000 (2597.4 examples/sec)
=> 2021-11-10 16:19:11.743183: step 99900, loss = 0.150769, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-10 16:19:31.722558: step 100000, loss = 0.113885, learning_rate = 0.000000 (2584.2 examples/sec)
=> Model saved to file: ./logs_res/model-100000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.950872
=> Model saved to file: ./logs_res/model-100000.pdparams
=> patience = 100
=> 2021-11-10 16:20:04.193756: step 100100, loss = 0.127522, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 16:20:24.967744: step 100200, loss = 0.169349, learning_rate = 0.000000 (2606.3 examples/sec)
=> 2021-11-10 16:20:44.936673: step 100300, loss = 0.157218, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 16:21:04.929490: step 100400, loss = 0.213757, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-10 16:21:24.902836: step 100500, loss = 0.085394, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 16:21:44.892592: step 100600, loss = 0.215594, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 16:22:05.867404: step 100700, loss = 0.199471, learning_rate = 0.000000 (2597.4 examples/sec)
=> 2021-11-10 16:22:25.882345: step 100800, loss = 0.135063, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-10 16:22:45.872794: step 100900, loss = 0.163353, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 16:23:05.870929: step 101000, loss = 0.156315, learning_rate = 0.000000 (2581.8 examples/sec)
=> Model saved to file: ./logs_res/model-101000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.950949
=> Model saved to file: ./logs_res/model-101000.pdparams
=> patience = 100
=> 2021-11-10 16:23:39.288126: step 101100, loss = 0.170207, learning_rate = 0.000000 (2599.9 examples/sec)
=> 2021-11-10 16:23:59.236813: step 101200, loss = 0.209772, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 16:24:19.197372: step 101300, loss = 0.218511, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 16:24:39.157427: step 101400, loss = 0.133173, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 16:24:59.949780: step 101500, loss = 0.152002, learning_rate = 0.000000 (2602.6 examples/sec)
=> 2021-11-10 16:25:19.918308: step 101600, loss = 0.126792, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 16:25:39.895882: step 101700, loss = 0.174943, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-10 16:25:59.872221: step 101800, loss = 0.175393, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-10 16:26:20.813444: step 101900, loss = 0.162664, learning_rate = 0.000000 (2597.8 examples/sec)
=> 2021-11-10 16:26:40.785196: step 102000, loss = 0.177567, learning_rate = 0.000000 (2585.1 examples/sec)
=> Model saved to file: ./logs_res/model-102000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948959, best accuracy 0.951025
=> patience = 99
=> 2021-11-10 16:27:12.568182: step 102100, loss = 0.185601, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 16:27:32.529228: step 102200, loss = 0.086570, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 16:27:53.325250: step 102300, loss = 0.193634, learning_rate = 0.000000 (2601.9 examples/sec)
=> 2021-11-10 16:28:13.301571: step 102400, loss = 0.281216, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-10 16:28:33.275123: step 102500, loss = 0.115924, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-10 16:28:53.250402: step 102600, loss = 0.142110, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 16:29:14.063975: step 102700, loss = 0.121223, learning_rate = 0.000000 (2603.6 examples/sec)
=> 2021-11-10 16:29:34.057401: step 102800, loss = 0.095394, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-10 16:29:54.025425: step 102900, loss = 0.152102, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 16:30:14.013923: step 103000, loss = 0.163366, learning_rate = 0.000000 (2582.9 examples/sec)
=> Model saved to file: ./logs_res/model-103000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.951025
=> patience = 99
=> 2021-11-10 16:30:46.801500: step 103100, loss = 0.208975, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-10 16:31:06.751319: step 103200, loss = 0.211142, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 16:31:26.713331: step 103300, loss = 0.187669, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 16:31:46.671452: step 103400, loss = 0.126784, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 16:32:06.635796: step 103500, loss = 0.197468, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 16:32:27.600120: step 103600, loss = 0.141290, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 16:32:47.563508: step 103700, loss = 0.169442, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 16:33:07.514748: step 103800, loss = 0.171816, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 16:33:27.468444: step 103900, loss = 0.100512, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 16:33:48.265555: step 104000, loss = 0.114766, learning_rate = 0.000000 (2602.3 examples/sec)
=> Model saved to file: ./logs_res/model-104000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.951025
=> patience = 99
=> 2021-11-10 16:34:19.925281: step 104100, loss = 0.159407, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 16:34:39.887994: step 104200, loss = 0.130531, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 16:34:59.872939: step 104300, loss = 0.154444, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 16:35:20.791993: step 104400, loss = 0.120893, learning_rate = 0.000000 (2596.7 examples/sec)
=> 2021-11-10 16:35:40.776975: step 104500, loss = 0.199602, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 16:36:00.770640: step 104600, loss = 0.155458, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-10 16:36:20.771930: step 104700, loss = 0.126310, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-10 16:36:41.669015: step 104800, loss = 0.144412, learning_rate = 0.000000 (2598.4 examples/sec)
=> 2021-11-10 16:37:01.650875: step 104900, loss = 0.122499, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 16:37:21.653787: step 105000, loss = 0.108391, learning_rate = 0.000000 (2581.5 examples/sec)
=> Model saved to file: ./logs_res/model-105000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.951025
=> Model saved to file: ./logs_res/model-105000.pdparams
=> patience = 100
=> 2021-11-10 16:37:54.949171: step 105100, loss = 0.112958, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-10 16:38:15.816204: step 105200, loss = 0.111858, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-10 16:38:35.753562: step 105300, loss = 0.155331, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 16:38:55.706743: step 105400, loss = 0.127598, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 16:39:15.666250: step 105500, loss = 0.165656, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 16:39:36.555599: step 105600, loss = 0.223035, learning_rate = 0.000000 (2601.2 examples/sec)
=> 2021-11-10 16:39:56.529329: step 105700, loss = 0.154879, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 16:40:16.498414: step 105800, loss = 0.127125, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 16:40:36.491931: step 105900, loss = 0.130213, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 16:40:57.654977: step 106000, loss = 0.184088, learning_rate = 0.000000 (2587.4 examples/sec)
=> Model saved to file: ./logs_res/model-106000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.951408
=> Model saved to file: ./logs_res/model-106000.pdparams
=> patience = 100
=> 2021-11-10 16:41:30.186461: step 106100, loss = 0.131710, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 16:41:50.146695: step 106200, loss = 0.201264, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 16:42:10.110226: step 106300, loss = 0.110400, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 16:42:31.067185: step 106400, loss = 0.103331, learning_rate = 0.000000 (2600.4 examples/sec)
=> 2021-11-10 16:42:51.045631: step 106500, loss = 0.146589, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 16:43:11.038856: step 106600, loss = 0.188275, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 16:43:31.049961: step 106700, loss = 0.164083, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-10 16:43:51.036272: step 106800, loss = 0.220043, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 16:44:12.045104: step 106900, loss = 0.140108, learning_rate = 0.000000 (2594.4 examples/sec)
=> 2021-11-10 16:44:32.082721: step 107000, loss = 0.156650, learning_rate = 0.000000 (2576.9 examples/sec)
=> Model saved to file: ./logs_res/model-107000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 16:45:03.981901: step 107100, loss = 0.142945, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 16:45:26.756956: step 107200, loss = 0.094982, learning_rate = 0.000000 (2656.2 examples/sec)
=> 2021-11-10 16:45:47.503128: step 107300, loss = 0.175526, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-10 16:46:07.442518: step 107400, loss = 0.273897, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 16:46:27.414664: step 107500, loss = 0.172767, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 16:46:47.376185: step 107600, loss = 0.141918, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 16:47:08.229823: step 107700, loss = 0.111327, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-10 16:47:28.198757: step 107800, loss = 0.120943, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 16:47:48.156627: step 107900, loss = 0.194209, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 16:48:08.124825: step 108000, loss = 0.282847, learning_rate = 0.000000 (2585.7 examples/sec)
=> Model saved to file: ./logs_res/model-108000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950107, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 16:48:41.227682: step 108100, loss = 0.114426, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-10 16:49:01.180199: step 108200, loss = 0.126887, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 16:49:21.122595: step 108300, loss = 0.128794, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 16:49:41.082461: step 108400, loss = 0.116336, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 16:50:01.930538: step 108500, loss = 0.134960, learning_rate = 0.000000 (2599.2 examples/sec)
=> 2021-11-10 16:50:21.896761: step 108600, loss = 0.089023, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 16:50:41.850092: step 108700, loss = 0.140520, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 16:51:01.812327: step 108800, loss = 0.158835, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 16:51:22.637923: step 108900, loss = 0.153637, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-10 16:51:42.596358: step 109000, loss = 0.086179, learning_rate = 0.000000 (2587.0 examples/sec)
=> Model saved to file: ./logs_res/model-109000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 16:52:14.536078: step 109100, loss = 0.148414, learning_rate = 0.000000 (2594.9 examples/sec)
=> 2021-11-10 16:52:34.465237: step 109200, loss = 0.093703, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-10 16:52:55.305214: step 109300, loss = 0.166725, learning_rate = 0.000000 (2601.0 examples/sec)
=> 2021-11-10 16:53:15.286249: step 109400, loss = 0.176966, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-10 16:53:35.235961: step 109500, loss = 0.104557, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 16:53:55.298581: step 109600, loss = 0.176233, learning_rate = 0.000000 (2605.2 examples/sec)
=> 2021-11-10 16:54:29.695068: step 109700, loss = 0.106577, learning_rate = 0.000000 (3057.6 examples/sec)
=> 2021-11-10 16:54:51.250980: step 109800, loss = 0.148216, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-10 16:55:11.268600: step 109900, loss = 0.084845, learning_rate = 0.000000 (2579.5 examples/sec)
=> 2021-11-10 16:55:31.227533: step 110000, loss = 0.186305, learning_rate = 0.000000 (2587.6 examples/sec)
=> Model saved to file: ./logs_res/model-110000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948424, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 16:56:03.170304: step 110100, loss = 0.171144, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 16:56:24.131753: step 110200, loss = 0.145720, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-10 16:56:44.133431: step 110300, loss = 0.145102, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-10 16:57:04.116150: step 110400, loss = 0.099771, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 16:57:24.179277: step 110500, loss = 0.103439, learning_rate = 0.000000 (2573.6 examples/sec)
=> 2021-11-10 16:57:50.134792: step 110600, loss = 0.164636, learning_rate = 0.000000 (2777.8 examples/sec)
=> 2021-11-10 16:58:10.114350: step 110700, loss = 0.174297, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 16:58:30.129813: step 110800, loss = 0.147777, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-10 16:58:50.122902: step 110900, loss = 0.270759, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-10 16:59:13.172862: step 111000, loss = 0.097758, learning_rate = 0.000000 (2637.6 examples/sec)
=> Model saved to file: ./logs_res/model-111000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 16:59:45.266240: step 111100, loss = 0.164205, learning_rate = 0.000000 (2595.3 examples/sec)
=> 2021-11-10 17:00:05.191069: step 111200, loss = 0.171415, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 17:00:25.233015: step 111300, loss = 0.132725, learning_rate = 0.000000 (2575.9 examples/sec)
=> 2021-11-10 17:00:46.023457: step 111400, loss = 0.126106, learning_rate = 0.000000 (2604.9 examples/sec)
=> 2021-11-10 17:01:07.315051: step 111500, loss = 0.173351, learning_rate = 0.000000 (2658.2 examples/sec)
=> 2021-11-10 17:01:27.306936: step 111600, loss = 0.134113, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 17:01:47.298362: step 111700, loss = 0.148835, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-10 17:02:08.251519: step 111800, loss = 0.041128, learning_rate = 0.000000 (2601.2 examples/sec)
=> 2021-11-10 17:02:28.239620: step 111900, loss = 0.139039, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 17:02:48.209900: step 112000, loss = 0.143779, learning_rate = 0.000000 (2586.1 examples/sec)
=> Model saved to file: ./logs_res/model-112000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.951867
=> patience = 99
=> 2021-11-10 17:03:20.359021: step 112100, loss = 0.111020, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 17:03:41.240785: step 112200, loss = 0.121860, learning_rate = 0.000000 (2608.7 examples/sec)
=> 2021-11-10 17:04:01.173771: step 112300, loss = 0.157941, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 17:04:21.859820: step 112400, loss = 0.228467, learning_rate = 0.000000 (2639.3 examples/sec)
=> 2021-11-10 17:04:41.789895: step 112500, loss = 0.214271, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 17:05:01.742403: step 112600, loss = 0.113112, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 17:05:22.526822: step 112700, loss = 0.127636, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-10 17:05:42.491911: step 112800, loss = 0.161640, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 17:06:02.460009: step 112900, loss = 0.148465, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 17:06:22.408443: step 113000, loss = 0.130642, learning_rate = 0.000000 (2588.3 examples/sec)
=> Model saved to file: ./logs_res/model-113000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.951867
=> Model saved to file: ./logs_res/model-113000.pdparams
=> patience = 100
=> 2021-11-10 17:06:56.021156: step 113100, loss = 0.116826, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-10 17:07:16.601991: step 113200, loss = 0.172982, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 17:07:36.575927: step 113300, loss = 0.122748, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 17:07:56.547578: step 113400, loss = 0.128423, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 17:08:17.429132: step 113500, loss = 0.159448, learning_rate = 0.000000 (2599.8 examples/sec)
=> 2021-11-10 17:08:37.408022: step 113600, loss = 0.162083, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 17:08:57.433016: step 113700, loss = 0.174570, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-10 17:09:17.398781: step 113800, loss = 0.101290, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-10 17:09:38.183706: step 113900, loss = 0.154149, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-10 17:09:58.141552: step 114000, loss = 0.107404, learning_rate = 0.000000 (2586.9 examples/sec)
=> Model saved to file: ./logs_res/model-114000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.952097
=> patience = 99
=> 2021-11-10 17:10:29.905087: step 114100, loss = 0.095897, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 17:10:49.826608: step 114200, loss = 0.149382, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-10 17:11:10.597567: step 114300, loss = 0.167073, learning_rate = 0.000000 (2608.3 examples/sec)
=> 2021-11-10 17:11:30.596694: step 114400, loss = 0.122375, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-10 17:11:50.551716: step 114500, loss = 0.097589, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 17:12:10.516738: step 114600, loss = 0.182757, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 17:12:31.434735: step 114700, loss = 0.138618, learning_rate = 0.000000 (2599.3 examples/sec)
=> 2021-11-10 17:12:51.402021: step 114800, loss = 0.172973, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 17:13:11.361811: step 114900, loss = 0.097073, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 17:13:31.353064: step 115000, loss = 0.123526, learning_rate = 0.000000 (2583.1 examples/sec)
=> Model saved to file: ./logs_res/model-115000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.952097
=> Model saved to file: ./logs_res/model-115000.pdparams
=> patience = 100
=> 2021-11-10 17:14:08.161447: step 115100, loss = 0.145703, learning_rate = 0.000000 (2751.8 examples/sec)
=> 2021-11-10 17:14:28.086147: step 115200, loss = 0.109116, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-10 17:14:48.026752: step 115300, loss = 0.125242, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 17:15:07.955860: step 115400, loss = 0.092031, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 17:15:27.910283: step 115500, loss = 0.120146, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 17:15:49.174156: step 115600, loss = 0.111588, learning_rate = 0.000000 (2601.6 examples/sec)
=> 2021-11-10 17:16:09.160178: step 115700, loss = 0.159049, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 17:16:29.132136: step 115800, loss = 0.118906, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-10 17:16:49.107476: step 115900, loss = 0.097454, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 17:17:10.009192: step 116000, loss = 0.121944, learning_rate = 0.000000 (2605.5 examples/sec)
=> Model saved to file: ./logs_res/model-116000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:17:41.844113: step 116100, loss = 0.162117, learning_rate = 0.000000 (2592.5 examples/sec)
=> 2021-11-10 17:18:01.780231: step 116200, loss = 0.127842, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 17:18:21.707820: step 116300, loss = 0.116292, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 17:18:42.491037: step 116400, loss = 0.134613, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-10 17:19:02.458055: step 116500, loss = 0.107277, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 17:19:22.452243: step 116600, loss = 0.159232, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 17:19:42.425140: step 116700, loss = 0.153877, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 17:20:03.399299: step 116800, loss = 0.109979, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 17:20:23.391526: step 116900, loss = 0.162781, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 17:20:43.354768: step 117000, loss = 0.089295, learning_rate = 0.000000 (2586.6 examples/sec)
=> Model saved to file: ./logs_res/model-117000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948959, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:21:15.193699: step 117100, loss = 0.129168, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 17:21:35.937267: step 117200, loss = 0.080661, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-10 17:21:55.896898: step 117300, loss = 0.125589, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 17:22:15.870325: step 117400, loss = 0.081955, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 17:22:35.832267: step 117500, loss = 0.192069, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 17:22:56.964315: step 117600, loss = 0.101246, learning_rate = 0.000000 (2608.1 examples/sec)
=> 2021-11-10 17:23:16.949688: step 117700, loss = 0.074621, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-10 17:23:36.927612: step 117800, loss = 0.086580, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 17:23:56.892700: step 117900, loss = 0.153444, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 17:24:17.838489: step 118000, loss = 0.103583, learning_rate = 0.000000 (2602.1 examples/sec)
=> Model saved to file: ./logs_res/model-118000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:24:50.087629: step 118100, loss = 0.107809, learning_rate = 0.000000 (2592.5 examples/sec)
=> 2021-11-10 17:25:10.010170: step 118200, loss = 0.135793, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 17:25:29.936086: step 118300, loss = 0.145222, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 17:25:49.883829: step 118400, loss = 0.115108, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 17:26:10.663604: step 118500, loss = 0.175237, learning_rate = 0.000000 (2603.6 examples/sec)
=> 2021-11-10 17:26:30.612884: step 118600, loss = 0.184174, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 17:26:50.597669: step 118700, loss = 0.107588, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 17:27:10.541410: step 118800, loss = 0.150954, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 17:27:31.908071: step 118900, loss = 0.107419, learning_rate = 0.000000 (2558.5 examples/sec)
=> 2021-11-10 17:27:51.900634: step 119000, loss = 0.110789, learning_rate = 0.000000 (2583.1 examples/sec)
=> Model saved to file: ./logs_res/model-119000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:28:27.139073: step 119100, loss = 0.107420, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-10 17:28:47.162668: step 119200, loss = 0.157295, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-10 17:29:08.102584: step 119300, loss = 0.084347, learning_rate = 0.000000 (2602.8 examples/sec)
=> 2021-11-10 17:29:28.284268: step 119400, loss = 0.139345, learning_rate = 0.000000 (2605.7 examples/sec)
=> 2021-11-10 17:29:50.451468: step 119500, loss = 0.124132, learning_rate = 0.000000 (2687.2 examples/sec)
=> 2021-11-10 17:30:10.395540: step 119600, loss = 0.088916, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 17:30:31.170292: step 119700, loss = 0.172599, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-10 17:30:51.111961: step 119800, loss = 0.139364, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 17:31:11.061905: step 119900, loss = 0.107932, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 17:31:30.996491: step 120000, loss = 0.067185, learning_rate = 0.000000 (2590.0 examples/sec)
=> Model saved to file: ./logs_res/model-120000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950260, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:32:03.720887: step 120100, loss = 0.166982, learning_rate = 0.000000 (2605.6 examples/sec)
=> 2021-11-10 17:32:23.649717: step 120200, loss = 0.085621, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 17:32:43.614703: step 120300, loss = 0.117331, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 17:33:03.588520: step 120400, loss = 0.140547, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-10 17:33:24.356532: step 120500, loss = 0.112281, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-10 17:33:45.306053: step 120600, loss = 0.146561, learning_rate = 0.000000 (2672.4 examples/sec)
=> 2021-11-10 17:34:05.244352: step 120700, loss = 0.129451, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-10 17:34:25.180682: step 120800, loss = 0.080205, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 17:34:45.951974: step 120900, loss = 0.104513, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-10 17:35:05.883031: step 121000, loss = 0.085474, learning_rate = 0.000000 (2590.6 examples/sec)
=> Model saved to file: ./logs_res/model-121000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:35:37.540847: step 121100, loss = 0.158690, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 17:35:57.459513: step 121200, loss = 0.183494, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 17:36:17.436036: step 121300, loss = 0.113217, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 17:36:38.283530: step 121400, loss = 0.082132, learning_rate = 0.000000 (2598.2 examples/sec)
=> 2021-11-10 17:36:58.261302: step 121500, loss = 0.159778, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-10 17:37:18.257966: step 121600, loss = 0.119533, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 17:37:41.968167: step 121700, loss = 0.112664, learning_rate = 0.000000 (2702.8 examples/sec)
=> 2021-11-10 17:38:03.497814: step 121800, loss = 0.080968, learning_rate = 0.000000 (2633.9 examples/sec)
=> 2021-11-10 17:38:23.452672: step 121900, loss = 0.104568, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 17:38:43.409888: step 122000, loss = 0.189976, learning_rate = 0.000000 (2587.6 examples/sec)
=> Model saved to file: ./logs_res/model-122000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.952632
=> patience = 99
=> 2021-11-10 17:39:20.006064: step 122100, loss = 0.167165, learning_rate = 0.000000 (2767.3 examples/sec)
=> 2021-11-10 17:39:40.846486: step 122200, loss = 0.130441, learning_rate = 0.000000 (2597.4 examples/sec)
=> 2021-11-10 17:40:00.816138: step 122300, loss = 0.194921, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 17:40:20.795282: step 122400, loss = 0.096784, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-10 17:40:40.787396: step 122500, loss = 0.137979, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 17:41:01.702587: step 122600, loss = 0.121522, learning_rate = 0.000000 (2602.9 examples/sec)
=> 2021-11-10 17:41:21.652128: step 122700, loss = 0.115094, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 17:41:41.645796: step 122800, loss = 0.145863, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 17:42:01.613864: step 122900, loss = 0.089478, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 17:42:22.415134: step 123000, loss = 0.123989, learning_rate = 0.000000 (2602.1 examples/sec)
=> Model saved to file: ./logs_res/model-123000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.952632
=> Model saved to file: ./logs_res/model-123000.pdparams
=> patience = 100
=> 2021-11-10 17:42:54.789304: step 123100, loss = 0.144475, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-10 17:43:14.698246: step 123200, loss = 0.071294, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-10 17:43:34.628098: step 123300, loss = 0.103745, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 17:43:55.429869: step 123400, loss = 0.134530, learning_rate = 0.000000 (2602.4 examples/sec)
=> 2021-11-10 17:44:15.361058: step 123500, loss = 0.098328, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 17:44:35.293834: step 123600, loss = 0.124824, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 17:44:55.226123: step 123700, loss = 0.097168, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 17:45:16.138450: step 123800, loss = 0.118147, learning_rate = 0.000000 (2606.9 examples/sec)
=> 2021-11-10 17:45:36.070473: step 123900, loss = 0.091925, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 17:45:56.021264: step 124000, loss = 0.086292, learning_rate = 0.000000 (2587.8 examples/sec)
=> Model saved to file: ./logs_res/model-124000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950490, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 17:46:27.620396: step 124100, loss = 0.099620, learning_rate = 0.000000 (2596.1 examples/sec)
=> 2021-11-10 17:46:47.543798: step 124200, loss = 0.092125, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-10 17:47:08.574017: step 124300, loss = 0.110713, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 17:47:28.509020: step 124400, loss = 0.114264, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 17:47:48.439830: step 124500, loss = 0.106555, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 17:48:08.362303: step 124600, loss = 0.101919, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 17:48:29.121468: step 124700, loss = 0.076899, learning_rate = 0.000000 (2609.3 examples/sec)
=> 2021-11-10 17:48:49.053555: step 124800, loss = 0.107312, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 17:49:08.999567: step 124900, loss = 0.113639, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-10 17:49:28.933913: step 125000, loss = 0.118428, learning_rate = 0.000000 (2590.2 examples/sec)
=> Model saved to file: ./logs_res/model-125000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 17:50:01.442539: step 125100, loss = 0.085408, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-10 17:50:21.377665: step 125200, loss = 0.118725, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 17:50:41.299681: step 125300, loss = 0.106300, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 17:51:01.234284: step 125400, loss = 0.107342, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 17:51:22.105041: step 125500, loss = 0.165532, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-10 17:51:42.315463: step 125600, loss = 0.189853, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-10 17:52:03.511137: step 125700, loss = 0.132514, learning_rate = 0.000000 (2673.9 examples/sec)
=> 2021-11-10 17:52:24.423649: step 125800, loss = 0.128897, learning_rate = 0.000000 (2637.8 examples/sec)
=> 2021-11-10 17:52:47.177999: step 125900, loss = 0.079860, learning_rate = 0.000000 (2720.5 examples/sec)
=> 2021-11-10 17:53:07.128185: step 126000, loss = 0.138834, learning_rate = 0.000000 (2588.3 examples/sec)
=> Model saved to file: ./logs_res/model-126000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 17:53:40.958442: step 126100, loss = 0.088858, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 17:54:00.915431: step 126200, loss = 0.117708, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 17:54:21.740314: step 126300, loss = 0.109134, learning_rate = 0.000000 (2614.1 examples/sec)
=> 2021-11-10 17:54:41.934144: step 126400, loss = 0.062030, learning_rate = 0.000000 (2557.3 examples/sec)
=> 2021-11-10 17:55:01.921222: step 126500, loss = 0.090108, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-10 17:55:21.894262: step 126600, loss = 0.110729, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 17:55:42.766090: step 126700, loss = 0.086329, learning_rate = 0.000000 (2601.3 examples/sec)
=> 2021-11-10 17:56:02.749645: step 126800, loss = 0.140636, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-10 17:56:22.744309: step 126900, loss = 0.138650, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-10 17:56:42.804419: step 127000, loss = 0.112412, learning_rate = 0.000000 (2573.8 examples/sec)
=> Model saved to file: ./logs_res/model-127000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 17:57:22.140283: step 127100, loss = 0.121514, learning_rate = 0.000000 (2608.3 examples/sec)
=> 2021-11-10 17:57:42.055957: step 127200, loss = 0.063193, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 17:58:01.983366: step 127300, loss = 0.111903, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 17:58:21.900145: step 127400, loss = 0.077411, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-10 17:58:41.838916: step 127500, loss = 0.104333, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 17:59:02.700426: step 127600, loss = 0.196923, learning_rate = 0.000000 (2605.2 examples/sec)
=> 2021-11-10 17:59:22.637093: step 127700, loss = 0.131280, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 17:59:42.580348: step 127800, loss = 0.119270, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 18:00:02.550677: step 127900, loss = 0.116619, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 18:00:23.340309: step 128000, loss = 0.111959, learning_rate = 0.000000 (2603.9 examples/sec)
=> Model saved to file: ./logs_res/model-128000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:00:55.164009: step 128100, loss = 0.121499, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-10 18:01:15.110194: step 128200, loss = 0.058241, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 18:01:35.063825: step 128300, loss = 0.195883, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 18:01:59.960460: step 128400, loss = 0.128872, learning_rate = 0.000000 (2723.3 examples/sec)
=> 2021-11-10 18:02:19.879012: step 128500, loss = 0.113113, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-10 18:02:39.813981: step 128600, loss = 0.096972, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 18:02:59.762362: step 128700, loss = 0.076622, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 18:03:20.735896: step 128800, loss = 0.166185, learning_rate = 0.000000 (2606.4 examples/sec)
=> 2021-11-10 18:03:47.534924: step 128900, loss = 0.078768, learning_rate = 0.000000 (3037.1 examples/sec)
=> 2021-11-10 18:04:08.602163: step 129000, loss = 0.144444, learning_rate = 0.000000 (2676.1 examples/sec)
=> Model saved to file: ./logs_res/model-129000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:04:40.259292: step 129100, loss = 0.094556, learning_rate = 0.000000 (2598.1 examples/sec)
=> 2021-11-10 18:05:01.140544: step 129200, loss = 0.116583, learning_rate = 0.000000 (2631.1 examples/sec)
=> 2021-11-10 18:05:21.074849: step 129300, loss = 0.086026, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 18:05:41.178003: step 129400, loss = 0.108430, learning_rate = 0.000000 (2606.2 examples/sec)
=> 2021-11-10 18:06:01.118523: step 129500, loss = 0.132058, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 18:06:22.640130: step 129600, loss = 0.105094, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-10 18:06:44.884107: step 129700, loss = 0.096517, learning_rate = 0.000000 (2709.0 examples/sec)
=> 2021-11-10 18:07:04.826760: step 129800, loss = 0.109543, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 18:07:24.766133: step 129900, loss = 0.096397, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 18:07:45.565755: step 130000, loss = 0.156261, learning_rate = 0.000000 (2607.1 examples/sec)
=> Model saved to file: ./logs_res/model-130000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:08:17.566535: step 130100, loss = 0.131568, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-10 18:08:37.486150: step 130200, loss = 0.084864, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 18:09:00.846630: step 130300, loss = 0.038185, learning_rate = 0.000000 (2766.8 examples/sec)
=> 2021-11-10 18:09:20.762392: step 130400, loss = 0.092703, learning_rate = 0.000000 (2592.6 examples/sec)
=> 2021-11-10 18:09:41.933253: step 130500, loss = 0.093727, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-10 18:10:01.883093: step 130600, loss = 0.134889, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 18:10:21.818341: step 130700, loss = 0.158920, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 18:10:41.787422: step 130800, loss = 0.096239, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 18:11:02.706665: step 130900, loss = 0.086008, learning_rate = 0.000000 (2599.4 examples/sec)
=> 2021-11-10 18:11:22.668261: step 131000, loss = 0.137068, learning_rate = 0.000000 (2586.7 examples/sec)
=> Model saved to file: ./logs_res/model-131000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:11:55.191943: step 131100, loss = 0.105320, learning_rate = 0.000000 (2591.8 examples/sec)
=> 2021-11-10 18:12:15.100824: step 131200, loss = 0.112564, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-10 18:12:35.919053: step 131300, loss = 0.090126, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-10 18:12:55.851654: step 131400, loss = 0.048673, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 18:13:15.791868: step 131500, loss = 0.096956, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 18:13:35.722438: step 131600, loss = 0.115574, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 18:13:56.576531: step 131700, loss = 0.106738, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-10 18:14:16.521246: step 131800, loss = 0.047014, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 18:14:36.457097: step 131900, loss = 0.127812, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 18:14:56.400509: step 132000, loss = 0.103211, learning_rate = 0.000000 (2589.2 examples/sec)
=> Model saved to file: ./logs_res/model-132000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948577, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:15:29.527383: step 132100, loss = 0.156531, learning_rate = 0.000000 (2609.4 examples/sec)
=> 2021-11-10 18:15:49.439881: step 132200, loss = 0.148008, learning_rate = 0.000000 (2592.9 examples/sec)
=> 2021-11-10 18:16:09.360977: step 132300, loss = 0.069938, learning_rate = 0.000000 (2591.9 examples/sec)
=> 2021-11-10 18:16:29.290495: step 132400, loss = 0.093985, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 18:16:51.533963: step 132500, loss = 0.102139, learning_rate = 0.000000 (2709.3 examples/sec)
=> 2021-11-10 18:17:16.836048: step 132600, loss = 0.070756, learning_rate = 0.000000 (2904.8 examples/sec)
=> 2021-11-10 18:17:37.359293: step 132700, loss = 0.182928, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-10 18:17:57.296438: step 132800, loss = 0.137381, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 18:18:23.139793: step 132900, loss = 0.080207, learning_rate = 0.000000 (2873.7 examples/sec)
=> 2021-11-10 18:18:45.787333: step 133000, loss = 0.073015, learning_rate = 0.000000 (2748.0 examples/sec)
=> Model saved to file: ./logs_res/model-133000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:19:17.414430: step 133100, loss = 0.146555, learning_rate = 0.000000 (2598.2 examples/sec)
=> 2021-11-10 18:19:37.321279: step 133200, loss = 0.096682, learning_rate = 0.000000 (2593.6 examples/sec)
=> 2021-11-10 18:19:57.228815: step 133300, loss = 0.119619, learning_rate = 0.000000 (2594.1 examples/sec)
=> 2021-11-10 18:20:17.991659: step 133400, loss = 0.091215, learning_rate = 0.000000 (2607.0 examples/sec)
=> 2021-11-10 18:20:37.931051: step 133500, loss = 0.108619, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-10 18:20:57.861457: step 133600, loss = 0.098733, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 18:21:17.801839: step 133700, loss = 0.124983, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 18:21:38.607045: step 133800, loss = 0.062898, learning_rate = 0.000000 (2607.3 examples/sec)
=> 2021-11-10 18:21:58.566748: step 133900, loss = 0.128641, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 18:22:18.525599: step 134000, loss = 0.087007, learning_rate = 0.000000 (2587.1 examples/sec)
=> Model saved to file: ./logs_res/model-134000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:22:55.203284: step 134100, loss = 0.135638, learning_rate = 0.000000 (2677.5 examples/sec)
=> 2021-11-10 18:23:16.139529: step 134200, loss = 0.157801, learning_rate = 0.000000 (2610.0 examples/sec)
=> 2021-11-10 18:23:36.046917: step 134300, loss = 0.090697, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-10 18:23:55.969936: step 134400, loss = 0.095712, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-10 18:24:15.880116: step 134500, loss = 0.117713, learning_rate = 0.000000 (2593.2 examples/sec)
=> 2021-11-10 18:24:36.631283: step 134600, loss = 0.152584, learning_rate = 0.000000 (2607.2 examples/sec)
=> 2021-11-10 18:24:56.604855: step 134700, loss = 0.085297, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 18:25:16.587160: step 134800, loss = 0.106604, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 18:25:36.541061: step 134900, loss = 0.114233, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 18:25:57.334911: step 135000, loss = 0.054127, learning_rate = 0.000000 (2613.7 examples/sec)
=> Model saved to file: ./logs_res/model-135000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:26:29.661562: step 135100, loss = 0.087426, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 18:26:49.605331: step 135200, loss = 0.081888, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 18:27:09.577589: step 135300, loss = 0.146253, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 18:27:30.540166: step 135400, loss = 0.086050, learning_rate = 0.000000 (2601.9 examples/sec)
=> 2021-11-10 18:27:50.509560: step 135500, loss = 0.100073, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 18:28:10.471310: step 135600, loss = 0.123218, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 18:28:30.433359: step 135700, loss = 0.118717, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 18:28:51.241645: step 135800, loss = 0.100339, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-10 18:29:11.207300: step 135900, loss = 0.106160, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 18:29:31.154131: step 136000, loss = 0.141366, learning_rate = 0.000000 (2588.7 examples/sec)
=> Model saved to file: ./logs_res/model-136000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.953245
=> patience = 99
=> 2021-11-10 18:30:03.115099: step 136100, loss = 0.103224, learning_rate = 0.000000 (2595.2 examples/sec)
=> 2021-11-10 18:30:23.054820: step 136200, loss = 0.068820, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 18:30:43.980347: step 136300, loss = 0.094016, learning_rate = 0.000000 (2600.3 examples/sec)
=> 2021-11-10 18:31:03.979522: step 136400, loss = 0.069959, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 18:31:23.999674: step 136500, loss = 0.090858, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-10 18:31:43.952103: step 136600, loss = 0.068924, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 18:32:04.810385: step 136700, loss = 0.121548, learning_rate = 0.000000 (2606.6 examples/sec)
=> 2021-11-10 18:32:24.747517: step 136800, loss = 0.085142, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 18:32:44.692076: step 136900, loss = 0.147517, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 18:33:04.641177: step 137000, loss = 0.070383, learning_rate = 0.000000 (2588.2 examples/sec)
=> Model saved to file: ./logs_res/model-137000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.953245
=> Model saved to file: ./logs_res/model-137000.pdparams
=> patience = 100
=> 2021-11-10 18:33:38.016676: step 137100, loss = 0.076447, learning_rate = 0.000000 (2603.3 examples/sec)
=> 2021-11-10 18:33:57.932718: step 137200, loss = 0.125209, learning_rate = 0.000000 (2592.8 examples/sec)
=> 2021-11-10 18:34:17.875984: step 137300, loss = 0.073107, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 18:34:37.846526: step 137400, loss = 0.111388, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 18:34:58.706659: step 137500, loss = 0.068197, learning_rate = 0.000000 (2599.5 examples/sec)
=> 2021-11-10 18:35:18.644990: step 137600, loss = 0.129217, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 18:35:38.583035: step 137700, loss = 0.106431, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 18:35:58.529467: step 137800, loss = 0.148255, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 18:36:19.392676: step 137900, loss = 0.106991, learning_rate = 0.000000 (2606.4 examples/sec)
=> 2021-11-10 18:36:39.334780: step 138000, loss = 0.098323, learning_rate = 0.000000 (2589.4 examples/sec)
=> Model saved to file: ./logs_res/model-138000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.953321
=> patience = 99
=> 2021-11-10 18:37:11.249551: step 138100, loss = 0.115016, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-10 18:37:31.171485: step 138200, loss = 0.093683, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 18:37:52.002926: step 138300, loss = 0.151349, learning_rate = 0.000000 (2596.5 examples/sec)
=> 2021-11-10 18:38:11.932634: step 138400, loss = 0.094406, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 18:38:31.872466: step 138500, loss = 0.078619, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 18:38:51.808756: step 138600, loss = 0.082923, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 18:39:12.735967: step 138700, loss = 0.113667, learning_rate = 0.000000 (2601.6 examples/sec)
=> 2021-11-10 18:39:32.689343: step 138800, loss = 0.068026, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 18:39:52.654103: step 138900, loss = 0.071180, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 18:40:12.611364: step 139000, loss = 0.123100, learning_rate = 0.000000 (2587.5 examples/sec)
=> Model saved to file: ./logs_res/model-139000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.953321
=> patience = 99
=> 2021-11-10 18:40:44.569093: step 139100, loss = 0.069556, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-10 18:41:05.466848: step 139200, loss = 0.074597, learning_rate = 0.000000 (2605.5 examples/sec)
=> 2021-11-10 18:41:25.393759: step 139300, loss = 0.092010, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 18:41:45.321927: step 139400, loss = 0.064358, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-10 18:42:05.269991: step 139500, loss = 0.097163, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-10 18:42:26.118835: step 139600, loss = 0.101308, learning_rate = 0.000000 (2603.3 examples/sec)
=> 2021-11-10 18:42:46.067823: step 139700, loss = 0.090478, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 18:43:06.021614: step 139800, loss = 0.141633, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 18:43:25.987916: step 139900, loss = 0.057755, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 18:43:46.966108: step 140000, loss = 0.093147, learning_rate = 0.000000 (2602.1 examples/sec)
=> Model saved to file: ./logs_res/model-140000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.953321
=> Model saved to file: ./logs_res/model-140000.pdparams
=> patience = 100
=> 2021-11-10 18:44:19.273807: step 140100, loss = 0.096130, learning_rate = 0.000000 (2594.2 examples/sec)
=> 2021-11-10 18:44:39.195577: step 140200, loss = 0.139124, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-10 18:44:59.124002: step 140300, loss = 0.089658, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 18:45:19.924294: step 140400, loss = 0.097982, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-10 18:45:39.901508: step 140500, loss = 0.102359, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-10 18:45:59.917931: step 140600, loss = 0.135481, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-10 18:46:19.907708: step 140700, loss = 0.076779, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 18:46:40.918306: step 140800, loss = 0.118227, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-10 18:47:00.861015: step 140900, loss = 0.081783, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 18:47:20.807071: step 141000, loss = 0.053166, learning_rate = 0.000000 (2588.8 examples/sec)
=> Model saved to file: ./logs_res/model-141000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.953627
=> patience = 99
=> 2021-11-10 18:47:52.729384: step 141100, loss = 0.087992, learning_rate = 0.000000 (2591.9 examples/sec)
=> 2021-11-10 18:48:13.524202: step 141200, loss = 0.084150, learning_rate = 0.000000 (2605.5 examples/sec)
=> 2021-11-10 18:48:33.457588: step 141300, loss = 0.122884, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 18:48:53.401887: step 141400, loss = 0.141762, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 18:49:13.342687: step 141500, loss = 0.157577, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 18:49:34.273872: step 141600, loss = 0.114051, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-10 18:49:54.238427: step 141700, loss = 0.102590, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 18:50:14.749639: step 141800, loss = 0.140712, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-10 18:50:34.692313: step 141900, loss = 0.109212, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 18:50:54.634116: step 142000, loss = 0.119246, learning_rate = 0.000000 (2589.6 examples/sec)
=> Model saved to file: ./logs_res/model-142000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.953627
=> patience = 99
=> 2021-11-10 18:51:27.985593: step 142100, loss = 0.085621, learning_rate = 0.000000 (2611.9 examples/sec)
=> 2021-11-10 18:51:59.140411: step 142200, loss = 0.073106, learning_rate = 0.000000 (2960.2 examples/sec)
=> 2021-11-10 18:52:21.444303: step 142300, loss = 0.071958, learning_rate = 0.000000 (2660.4 examples/sec)
=> 2021-11-10 18:52:41.351325: step 142400, loss = 0.088451, learning_rate = 0.000000 (2593.5 examples/sec)
=> 2021-11-10 18:53:02.211050: step 142500, loss = 0.101983, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-10 18:53:22.259292: step 142600, loss = 0.147944, learning_rate = 0.000000 (2575.8 examples/sec)
=> 2021-11-10 18:53:42.219867: step 142700, loss = 0.080136, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 18:54:02.207944: step 142800, loss = 0.107850, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 18:54:28.991227: step 142900, loss = 0.067207, learning_rate = 0.000000 (2762.0 examples/sec)
=> 2021-11-10 18:54:48.904832: step 143000, loss = 0.061749, learning_rate = 0.000000 (2593.0 examples/sec)
=> Model saved to file: ./logs_res/model-143000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.953627
=> Model saved to file: ./logs_res/model-143000.pdparams
=> patience = 100
=> 2021-11-10 18:55:22.251925: step 143100, loss = 0.100151, learning_rate = 0.000000 (2594.5 examples/sec)
=> 2021-11-10 18:55:42.164765: step 143200, loss = 0.074605, learning_rate = 0.000000 (2593.1 examples/sec)
=> 2021-11-10 18:56:02.975239: step 143300, loss = 0.066153, learning_rate = 0.000000 (2603.4 examples/sec)
=> 2021-11-10 18:56:22.902134: step 143400, loss = 0.060085, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 18:56:42.849508: step 143500, loss = 0.078842, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 18:57:02.781776: step 143600, loss = 0.128374, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 18:57:23.684484: step 143700, loss = 0.127646, learning_rate = 0.000000 (2598.7 examples/sec)
=> 2021-11-10 18:57:43.640554: step 143800, loss = 0.095794, learning_rate = 0.000000 (2587.2 examples/sec)
=> 2021-11-10 18:58:03.597135: step 143900, loss = 0.095010, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 18:58:23.545514: step 144000, loss = 0.105176, learning_rate = 0.000000 (2588.5 examples/sec)
=> Model saved to file: ./logs_res/model-144000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 18:58:56.824525: step 144100, loss = 0.097606, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-10 18:59:16.758548: step 144200, loss = 0.063646, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 18:59:36.707741: step 144300, loss = 0.157011, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 18:59:57.313950: step 144400, loss = 0.109042, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-10 19:00:18.063472: step 144500, loss = 0.095011, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-10 19:00:37.985987: step 144600, loss = 0.086530, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 19:00:57.927912: step 144700, loss = 0.124554, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 19:01:17.853500: step 144800, loss = 0.061627, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 19:01:37.784898: step 144900, loss = 0.053029, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 19:01:58.726447: step 145000, loss = 0.097803, learning_rate = 0.000000 (2588.0 examples/sec)
=> Model saved to file: ./logs_res/model-145000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:02:30.461479: step 145100, loss = 0.057996, learning_rate = 0.000000 (2596.1 examples/sec)
=> 2021-11-10 19:02:50.379104: step 145200, loss = 0.132798, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-10 19:03:10.314321: step 145300, loss = 0.096962, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 19:03:31.121462: step 145400, loss = 0.114841, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-10 19:03:51.062042: step 145500, loss = 0.060684, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-10 19:04:11.003717: step 145600, loss = 0.083557, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 19:04:30.949180: step 145700, loss = 0.084055, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-10 19:04:51.809969: step 145800, loss = 0.056087, learning_rate = 0.000000 (2603.5 examples/sec)
=> 2021-11-10 19:05:11.781043: step 145900, loss = 0.089509, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 19:05:31.785321: step 146000, loss = 0.098537, learning_rate = 0.000000 (2605.7 examples/sec)
=> Model saved to file: ./logs_res/model-146000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:06:12.981895: step 146100, loss = 0.122737, learning_rate = 0.000000 (2906.4 examples/sec)
=> 2021-11-10 19:06:33.693991: step 146200, loss = 0.070948, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-10 19:06:53.610118: step 146300, loss = 0.098983, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-10 19:07:13.531718: step 146400, loss = 0.092704, learning_rate = 0.000000 (2592.0 examples/sec)
=> 2021-11-10 19:07:33.460585: step 146500, loss = 0.118373, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 19:07:54.281110: step 146600, loss = 0.046452, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-10 19:08:14.232288: step 146700, loss = 0.155659, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 19:08:34.179110: step 146800, loss = 0.086410, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 19:08:54.125812: step 146900, loss = 0.143635, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 19:09:15.031649: step 147000, loss = 0.062938, learning_rate = 0.000000 (2608.4 examples/sec)
=> Model saved to file: ./logs_res/model-147000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:09:47.303965: step 147100, loss = 0.087929, learning_rate = 0.000000 (2593.8 examples/sec)
=> 2021-11-10 19:10:07.223412: step 147200, loss = 0.098048, learning_rate = 0.000000 (2592.6 examples/sec)
=> 2021-11-10 19:10:27.168023: step 147300, loss = 0.094679, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 19:10:47.967997: step 147400, loss = 0.061293, learning_rate = 0.000000 (2605.3 examples/sec)
=> 2021-11-10 19:11:07.930553: step 147500, loss = 0.082016, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 19:11:27.970215: step 147600, loss = 0.063545, learning_rate = 0.000000 (2576.7 examples/sec)
=> 2021-11-10 19:11:48.062864: step 147700, loss = 0.122594, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-10 19:12:08.904042: step 147800, loss = 0.110654, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-10 19:12:30.702704: step 147900, loss = 0.090687, learning_rate = 0.000000 (2648.4 examples/sec)
=> 2021-11-10 19:12:50.689999: step 148000, loss = 0.074604, learning_rate = 0.000000 (2583.8 examples/sec)
=> Model saved to file: ./logs_res/model-148000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:13:22.613475: step 148100, loss = 0.060470, learning_rate = 0.000000 (2595.1 examples/sec)
=> 2021-11-10 19:13:42.551691: step 148200, loss = 0.108104, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 19:14:03.483510: step 148300, loss = 0.120804, learning_rate = 0.000000 (2607.3 examples/sec)
=> 2021-11-10 19:14:23.419338: step 148400, loss = 0.082255, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 19:14:43.378922: step 148500, loss = 0.078395, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 19:15:03.319887: step 148600, loss = 0.113074, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 19:15:24.277446: step 148700, loss = 0.100988, learning_rate = 0.000000 (2600.5 examples/sec)
=> 2021-11-10 19:15:44.229177: step 148800, loss = 0.081086, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 19:16:04.186044: step 148900, loss = 0.064853, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 19:16:24.132297: step 149000, loss = 0.045098, learning_rate = 0.000000 (2589.2 examples/sec)
=> Model saved to file: ./logs_res/model-149000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:16:57.329708: step 149100, loss = 0.082170, learning_rate = 0.000000 (2605.5 examples/sec)
=> 2021-11-10 19:17:17.303103: step 149200, loss = 0.107607, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 19:17:37.277218: step 149300, loss = 0.070394, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 19:17:57.255874: step 149400, loss = 0.072280, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 19:18:18.204451: step 149500, loss = 0.092246, learning_rate = 0.000000 (2600.1 examples/sec)
=> 2021-11-10 19:18:38.167479: step 149600, loss = 0.089246, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 19:18:58.172291: step 149700, loss = 0.086812, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-10 19:19:18.159898: step 149800, loss = 0.049315, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 19:19:38.992464: step 149900, loss = 0.096037, learning_rate = 0.000000 (2599.6 examples/sec)
=> 2021-11-10 19:19:58.985950: step 150000, loss = 0.069900, learning_rate = 0.000000 (2582.8 examples/sec)
=> Model saved to file: ./logs_res/model-150000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:20:31.095009: step 150100, loss = 0.049400, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 19:20:51.056411: step 150200, loss = 0.054989, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 19:21:11.928900: step 150300, loss = 0.089660, learning_rate = 0.000000 (2599.1 examples/sec)
=> 2021-11-10 19:21:31.857459: step 150400, loss = 0.045221, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 19:21:51.781401: step 150500, loss = 0.085389, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-10 19:22:11.713613: step 150600, loss = 0.054905, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 19:22:32.570367: step 150700, loss = 0.060102, learning_rate = 0.000000 (2608.1 examples/sec)
=> 2021-11-10 19:22:52.509869: step 150800, loss = 0.118745, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 19:23:12.477804: step 150900, loss = 0.054999, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 19:23:32.451608: step 151000, loss = 0.067979, learning_rate = 0.000000 (2585.2 examples/sec)
=> Model saved to file: ./logs_res/model-151000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:24:04.672229: step 151100, loss = 0.067353, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 19:24:25.574478: step 151200, loss = 0.085116, learning_rate = 0.000000 (2607.3 examples/sec)
=> 2021-11-10 19:24:45.513505: step 151300, loss = 0.069483, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 19:25:05.440152: step 151400, loss = 0.096634, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 19:25:25.392352: step 151500, loss = 0.102553, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 19:25:46.194899: step 151600, loss = 0.067042, learning_rate = 0.000000 (2602.8 examples/sec)
=> 2021-11-10 19:26:06.129754: step 151700, loss = 0.149959, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 19:26:26.079400: step 151800, loss = 0.074496, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 19:26:46.013091: step 151900, loss = 0.080173, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 19:27:06.805678: step 152000, loss = 0.097386, learning_rate = 0.000000 (2607.9 examples/sec)
=> Model saved to file: ./logs_res/model-152000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:27:38.650934: step 152100, loss = 0.086536, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-10 19:27:58.573050: step 152200, loss = 0.097460, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-10 19:28:18.492752: step 152300, loss = 0.107647, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 19:28:39.328480: step 152400, loss = 0.085350, learning_rate = 0.000000 (2602.8 examples/sec)
=> 2021-11-10 19:28:59.289140: step 152500, loss = 0.065637, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 19:29:19.272437: step 152600, loss = 0.052045, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 19:29:39.234735: step 152700, loss = 0.057658, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 19:30:00.024605: step 152800, loss = 0.058714, learning_rate = 0.000000 (2605.9 examples/sec)
=> 2021-11-10 19:30:19.952848: step 152900, loss = 0.070847, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 19:30:39.873949: step 153000, loss = 0.075713, learning_rate = 0.000000 (2592.2 examples/sec)
=> Model saved to file: ./logs_res/model-153000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:31:11.733076: step 153100, loss = 0.107830, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-10 19:31:32.498367: step 153200, loss = 0.059188, learning_rate = 0.000000 (2608.2 examples/sec)
=> 2021-11-10 19:31:52.409126: step 153300, loss = 0.114264, learning_rate = 0.000000 (2593.9 examples/sec)
=> 2021-11-10 19:32:12.334955: step 153400, loss = 0.111365, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-10 19:32:32.287161: step 153500, loss = 0.082264, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 19:32:53.103433: step 153600, loss = 0.121618, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-10 19:33:13.028877: step 153700, loss = 0.042522, learning_rate = 0.000000 (2594.7 examples/sec)
=> 2021-11-10 19:33:32.963037: step 153800, loss = 0.053844, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 19:33:52.897796: step 153900, loss = 0.080156, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 19:34:12.829059: step 154000, loss = 0.114883, learning_rate = 0.000000 (2591.0 examples/sec)
=> Model saved to file: ./logs_res/model-154000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:34:45.462837: step 154100, loss = 0.100504, learning_rate = 0.000000 (2606.2 examples/sec)
=> 2021-11-10 19:35:05.403840: step 154200, loss = 0.053671, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-10 19:35:25.349985: step 154300, loss = 0.106823, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 19:35:45.311347: step 154400, loss = 0.073413, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 19:36:06.253583: step 154500, loss = 0.060803, learning_rate = 0.000000 (2603.6 examples/sec)
=> 2021-11-10 19:36:26.182529: step 154600, loss = 0.040620, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-10 19:36:46.125179: step 154700, loss = 0.161701, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 19:37:06.089790: step 154800, loss = 0.088277, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 19:37:26.935214: step 154900, loss = 0.062887, learning_rate = 0.000000 (2599.3 examples/sec)
=> 2021-11-10 19:37:46.907887: step 155000, loss = 0.063544, learning_rate = 0.000000 (2584.9 examples/sec)
=> Model saved to file: ./logs_res/model-155000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:38:18.893782: step 155100, loss = 0.058563, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 19:38:38.827322: step 155200, loss = 0.115323, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 19:38:59.623624: step 155300, loss = 0.071327, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-10 19:39:19.573455: step 155400, loss = 0.088745, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 19:39:39.531397: step 155500, loss = 0.063833, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 19:39:59.481150: step 155600, loss = 0.090940, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 19:40:20.285011: step 155700, loss = 0.095833, learning_rate = 0.000000 (2605.7 examples/sec)
=> 2021-11-10 19:40:40.240894: step 155800, loss = 0.066942, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-10 19:41:00.195967: step 155900, loss = 0.161006, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 19:41:20.146491: step 156000, loss = 0.083047, learning_rate = 0.000000 (2588.2 examples/sec)
=> Model saved to file: ./logs_res/model-156000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:41:53.191639: step 156100, loss = 0.083410, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-10 19:42:13.097801: step 156200, loss = 0.074228, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 19:42:33.006734: step 156300, loss = 0.077217, learning_rate = 0.000000 (2593.5 examples/sec)
=> 2021-11-10 19:42:52.950778: step 156400, loss = 0.113305, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 19:43:13.739564: step 156500, loss = 0.090894, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-10 19:43:33.650158: step 156600, loss = 0.057655, learning_rate = 0.000000 (2593.2 examples/sec)
=> 2021-11-10 19:43:53.575782: step 156700, loss = 0.103423, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 19:44:13.506826: step 156800, loss = 0.106597, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 19:44:33.439447: step 156900, loss = 0.063585, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 19:44:54.193520: step 157000, loss = 0.085224, learning_rate = 0.000000 (2614.2 examples/sec)
=> Model saved to file: ./logs_res/model-157000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:45:25.943437: step 157100, loss = 0.067519, learning_rate = 0.000000 (2593.4 examples/sec)
=> 2021-11-10 19:45:45.850361: step 157200, loss = 0.099043, learning_rate = 0.000000 (2594.7 examples/sec)
=> 2021-11-10 19:46:05.766059: step 157300, loss = 0.098122, learning_rate = 0.000000 (2593.8 examples/sec)
=> 2021-11-10 19:46:26.748634: step 157400, loss = 0.115762, learning_rate = 0.000000 (2608.1 examples/sec)
=> 2021-11-10 19:46:46.669435: step 157500, loss = 0.085978, learning_rate = 0.000000 (2591.8 examples/sec)
=> 2021-11-10 19:47:06.593735: step 157600, loss = 0.060076, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 19:47:26.508479: step 157700, loss = 0.055549, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-10 19:47:47.406052: step 157800, loss = 0.081448, learning_rate = 0.000000 (2604.3 examples/sec)
=> 2021-11-10 19:48:07.364505: step 157900, loss = 0.099381, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 19:48:29.091331: step 158000, loss = 0.051290, learning_rate = 0.000000 (2698.4 examples/sec)
=> Model saved to file: ./logs_res/model-158000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:49:01.214287: step 158100, loss = 0.049529, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-10 19:49:22.042852: step 158200, loss = 0.056756, learning_rate = 0.000000 (2601.8 examples/sec)
=> 2021-11-10 19:49:42.016594: step 158300, loss = 0.108379, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 19:50:01.958690: step 158400, loss = 0.053365, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 19:50:21.881476: step 158500, loss = 0.100490, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 19:50:42.709129: step 158600, loss = 0.058301, learning_rate = 0.000000 (2607.8 examples/sec)
=> 2021-11-10 19:51:02.639155: step 158700, loss = 0.050972, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 19:51:22.576532: step 158800, loss = 0.050500, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-10 19:51:42.511626: step 158900, loss = 0.048304, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 19:52:03.255381: step 159000, loss = 0.059972, learning_rate = 0.000000 (2608.2 examples/sec)
=> Model saved to file: ./logs_res/model-159000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:52:35.200639: step 159100, loss = 0.072281, learning_rate = 0.000000 (2595.5 examples/sec)
=> 2021-11-10 19:52:55.095490: step 159200, loss = 0.049672, learning_rate = 0.000000 (2595.1 examples/sec)
=> 2021-11-10 19:53:15.023716: step 159300, loss = 0.081888, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 19:53:35.757743: step 159400, loss = 0.102426, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-10 19:53:55.687474: step 159500, loss = 0.082586, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 19:54:15.611391: step 159600, loss = 0.081209, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-10 19:54:35.527609: step 159700, loss = 0.058674, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-10 19:54:55.440175: step 159800, loss = 0.073309, learning_rate = 0.000000 (2593.5 examples/sec)
=> 2021-11-10 19:55:16.192451: step 159900, loss = 0.086594, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-10 19:55:36.140590: step 160000, loss = 0.077825, learning_rate = 0.000000 (2588.6 examples/sec)
=> Model saved to file: ./logs_res/model-160000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:56:08.337239: step 160100, loss = 0.049488, learning_rate = 0.000000 (2598.5 examples/sec)
=> 2021-11-10 19:56:28.242261: step 160200, loss = 0.057116, learning_rate = 0.000000 (2593.9 examples/sec)
=> 2021-11-10 19:56:48.976204: step 160300, loss = 0.063650, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-10 19:57:08.897776: step 160400, loss = 0.045062, learning_rate = 0.000000 (2591.8 examples/sec)
=> 2021-11-10 19:57:28.827925: step 160500, loss = 0.071580, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 19:57:48.750726: step 160600, loss = 0.087927, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 19:58:09.710467: step 160700, loss = 0.063297, learning_rate = 0.000000 (2610.3 examples/sec)
=> 2021-11-10 19:58:29.627176: step 160800, loss = 0.069667, learning_rate = 0.000000 (2592.5 examples/sec)
=> 2021-11-10 19:58:49.556614: step 160900, loss = 0.098409, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 19:59:09.479825: step 161000, loss = 0.075859, learning_rate = 0.000000 (2591.7 examples/sec)
=> Model saved to file: ./logs_res/model-161000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950490, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 19:59:42.403711: step 161100, loss = 0.079579, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-10 20:00:02.310963: step 161200, loss = 0.128123, learning_rate = 0.000000 (2593.8 examples/sec)
=> 2021-11-10 20:00:22.229274: step 161300, loss = 0.064915, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-10 20:00:42.174852: step 161400, loss = 0.099970, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 20:01:02.975100: step 161500, loss = 0.053477, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-10 20:01:22.908930: step 161600, loss = 0.065600, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 20:01:42.854868: step 161700, loss = 0.110444, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 20:02:02.788785: step 161800, loss = 0.078210, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 20:02:23.594107: step 161900, loss = 0.111283, learning_rate = 0.000000 (2602.6 examples/sec)
=> 2021-11-10 20:02:43.538658: step 162000, loss = 0.109856, learning_rate = 0.000000 (2589.0 examples/sec)
=> Model saved to file: ./logs_res/model-162000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:03:15.373262: step 162100, loss = 0.088684, learning_rate = 0.000000 (2592.5 examples/sec)
=> 2021-11-10 20:03:35.326447: step 162200, loss = 0.122775, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 20:03:56.296706: step 162300, loss = 0.077111, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-10 20:04:16.215092: step 162400, loss = 0.064602, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:04:36.160541: step 162500, loss = 0.085048, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 20:04:56.099335: step 162600, loss = 0.075275, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 20:05:16.024044: step 162700, loss = 0.039323, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:05:36.900050: step 162800, loss = 0.080409, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-10 20:05:56.901229: step 162900, loss = 0.059905, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-10 20:06:16.835071: step 163000, loss = 0.070950, learning_rate = 0.000000 (2590.2 examples/sec)
=> Model saved to file: ./logs_res/model-163000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:06:48.719920: step 163100, loss = 0.083343, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 20:07:09.637906: step 163200, loss = 0.096418, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-10 20:07:29.587969: step 163300, loss = 0.082027, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 20:07:49.818431: step 163400, loss = 0.045336, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-10 20:08:09.897360: step 163500, loss = 0.067676, learning_rate = 0.000000 (2571.6 examples/sec)
=> 2021-11-10 20:08:30.724079: step 163600, loss = 0.077859, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-10 20:08:50.696414: step 163700, loss = 0.104282, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 20:09:10.733171: step 163800, loss = 0.066557, learning_rate = 0.000000 (2577.3 examples/sec)
=> 2021-11-10 20:09:31.973053: step 163900, loss = 0.061073, learning_rate = 0.000000 (2689.1 examples/sec)
=> 2021-11-10 20:09:52.811974: step 164000, loss = 0.082244, learning_rate = 0.000000 (2598.8 examples/sec)
=> Model saved to file: ./logs_res/model-164000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:10:25.302164: step 164100, loss = 0.066750, learning_rate = 0.000000 (2595.3 examples/sec)
=> 2021-11-10 20:10:45.286087: step 164200, loss = 0.098776, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 20:11:05.519751: step 164300, loss = 0.062040, learning_rate = 0.000000 (2553.9 examples/sec)
=> 2021-11-10 20:11:26.305399: step 164400, loss = 0.049780, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-10 20:11:46.234260: step 164500, loss = 0.091773, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-10 20:12:06.163892: step 164600, loss = 0.099791, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-10 20:12:26.102428: step 164700, loss = 0.056790, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 20:12:46.847917: step 164800, loss = 0.063625, learning_rate = 0.000000 (2608.6 examples/sec)
=> 2021-11-10 20:13:06.777683: step 164900, loss = 0.082625, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 20:13:26.712382: step 165000, loss = 0.092409, learning_rate = 0.000000 (2590.0 examples/sec)
=> Model saved to file: ./logs_res/model-165000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:13:58.440202: step 165100, loss = 0.093335, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-10 20:14:19.234888: step 165200, loss = 0.078871, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-10 20:14:39.168976: step 165300, loss = 0.046008, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 20:14:59.090183: step 165400, loss = 0.046887, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-10 20:15:19.005198: step 165500, loss = 0.104010, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-10 20:15:38.934059: step 165600, loss = 0.066526, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 20:15:59.866626: step 165700, loss = 0.076504, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-10 20:16:21.053856: step 165800, loss = 0.074274, learning_rate = 0.000000 (2673.4 examples/sec)
=> 2021-11-10 20:16:40.987668: step 165900, loss = 0.042693, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 20:17:00.914144: step 166000, loss = 0.058638, learning_rate = 0.000000 (2591.0 examples/sec)
=> Model saved to file: ./logs_res/model-166000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:17:33.848264: step 166100, loss = 0.095532, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-10 20:17:53.781823: step 166200, loss = 0.091456, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 20:18:13.693788: step 166300, loss = 0.070800, learning_rate = 0.000000 (2593.1 examples/sec)
=> 2021-11-10 20:18:33.616235: step 166400, loss = 0.086285, learning_rate = 0.000000 (2591.6 examples/sec)
=> 2021-11-10 20:18:54.602365: step 166500, loss = 0.078085, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-10 20:19:18.999866: step 166600, loss = 0.062189, learning_rate = 0.000000 (2782.3 examples/sec)
=> 2021-11-10 20:19:38.964089: step 166700, loss = 0.117794, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 20:19:58.944624: step 166800, loss = 0.064322, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-10 20:20:20.287880: step 166900, loss = 0.039696, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-10 20:20:40.316022: step 167000, loss = 0.050745, learning_rate = 0.000000 (2579.8 examples/sec)
=> Model saved to file: ./logs_res/model-167000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:21:13.117414: step 167100, loss = 0.072007, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-10 20:21:33.143106: step 167200, loss = 0.082444, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-10 20:21:54.259786: step 167300, loss = 0.060484, learning_rate = 0.000000 (2596.3 examples/sec)
=> 2021-11-10 20:22:14.318111: step 167400, loss = 0.055597, learning_rate = 0.000000 (2576.0 examples/sec)
=> 2021-11-10 20:22:34.356466: step 167500, loss = 0.085430, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-10 20:22:54.398554: step 167600, loss = 0.078316, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-10 20:23:15.520088: step 167700, loss = 0.064820, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 20:23:35.482781: step 167800, loss = 0.084578, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 20:23:55.455226: step 167900, loss = 0.057644, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 20:24:15.452655: step 168000, loss = 0.029206, learning_rate = 0.000000 (2583.0 examples/sec)
=> Model saved to file: ./logs_res/model-168000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:24:48.135207: step 168100, loss = 0.055440, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-10 20:25:08.054715: step 168200, loss = 0.071782, learning_rate = 0.000000 (2592.0 examples/sec)
=> 2021-11-10 20:25:27.991515: step 168300, loss = 0.029169, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 20:25:47.940065: step 168400, loss = 0.063098, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 20:26:08.778077: step 168500, loss = 0.037683, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-10 20:26:28.761047: step 168600, loss = 0.055710, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 20:26:48.716880: step 168700, loss = 0.049791, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 20:27:08.662471: step 168800, loss = 0.056428, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-10 20:27:28.621793: step 168900, loss = 0.070604, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 20:27:49.404207: step 169000, loss = 0.069075, learning_rate = 0.000000 (2606.0 examples/sec)
=> Model saved to file: ./logs_res/model-169000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:28:21.375812: step 169100, loss = 0.089513, learning_rate = 0.000000 (2595.6 examples/sec)
=> 2021-11-10 20:28:41.287319: step 169200, loss = 0.059869, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-10 20:29:01.217378: step 169300, loss = 0.117793, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 20:29:21.982798: step 169400, loss = 0.037399, learning_rate = 0.000000 (2611.6 examples/sec)
=> 2021-11-10 20:29:41.913628: step 169500, loss = 0.073485, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 20:30:01.888003: step 169600, loss = 0.065776, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 20:30:21.807446: step 169700, loss = 0.070326, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:30:42.618726: step 169800, loss = 0.060746, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-10 20:31:02.570251: step 169900, loss = 0.062498, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 20:31:22.497780: step 170000, loss = 0.072220, learning_rate = 0.000000 (2591.2 examples/sec)
=> Model saved to file: ./logs_res/model-170000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:31:54.201880: step 170100, loss = 0.065840, learning_rate = 0.000000 (2595.5 examples/sec)
=> 2021-11-10 20:32:15.102846: step 170200, loss = 0.094937, learning_rate = 0.000000 (2596.5 examples/sec)
=> 2021-11-10 20:32:35.017656: step 170300, loss = 0.107252, learning_rate = 0.000000 (2592.8 examples/sec)
=> 2021-11-10 20:32:54.954253: step 170400, loss = 0.051035, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 20:33:14.871503: step 170500, loss = 0.058832, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:33:35.717863: step 170600, loss = 0.026343, learning_rate = 0.000000 (2597.8 examples/sec)
=> 2021-11-10 20:33:55.650896: step 170700, loss = 0.102986, learning_rate = 0.000000 (2591.1 examples/sec)
=> 2021-11-10 20:34:15.580205: step 170800, loss = 0.056676, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 20:34:35.505304: step 170900, loss = 0.051720, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-10 20:34:56.330013: step 171000, loss = 0.054048, learning_rate = 0.000000 (2601.4 examples/sec)
=> Model saved to file: ./logs_res/model-171000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:35:34.407170: step 171100, loss = 0.090746, learning_rate = 0.000000 (2596.7 examples/sec)
=> 2021-11-10 20:35:54.317768: step 171200, loss = 0.078176, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-10 20:36:14.268925: step 171300, loss = 0.060145, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 20:36:35.140782: step 171400, loss = 0.114731, learning_rate = 0.000000 (2605.4 examples/sec)
=> 2021-11-10 20:36:55.106801: step 171500, loss = 0.097447, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 20:37:15.070174: step 171600, loss = 0.064183, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 20:37:35.051445: step 171700, loss = 0.062250, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-10 20:37:55.009801: step 171800, loss = 0.069773, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 20:38:15.883269: step 171900, loss = 0.039590, learning_rate = 0.000000 (2603.2 examples/sec)
=> 2021-11-10 20:38:35.873674: step 172000, loss = 0.076864, learning_rate = 0.000000 (2583.1 examples/sec)
=> Model saved to file: ./logs_res/model-172000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948500, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:39:08.336521: step 172100, loss = 0.095077, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-10 20:39:32.204186: step 172200, loss = 0.092049, learning_rate = 0.000000 (2812.7 examples/sec)
=> 2021-11-10 20:39:53.191768: step 172300, loss = 0.038438, learning_rate = 0.000000 (2609.2 examples/sec)
=> 2021-11-10 20:40:13.677170: step 172400, loss = 0.077604, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-10 20:40:33.612839: step 172500, loss = 0.062102, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 20:40:53.556638: step 172600, loss = 0.064702, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 20:41:14.423882: step 172700, loss = 0.031721, learning_rate = 0.000000 (2606.6 examples/sec)
=> 2021-11-10 20:41:34.391387: step 172800, loss = 0.056196, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 20:41:54.359148: step 172900, loss = 0.071867, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 20:42:14.326254: step 173000, loss = 0.051151, learning_rate = 0.000000 (2586.2 examples/sec)
=> Model saved to file: ./logs_res/model-173000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:42:47.168109: step 173100, loss = 0.069530, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-10 20:43:07.111323: step 173200, loss = 0.082496, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 20:43:27.030696: step 173300, loss = 0.054189, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:43:46.949090: step 173400, loss = 0.083093, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:44:07.829976: step 173500, loss = 0.044496, learning_rate = 0.000000 (2608.7 examples/sec)
=> 2021-11-10 20:44:27.762022: step 173600, loss = 0.077915, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 20:44:47.696383: step 173700, loss = 0.064759, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 20:45:07.643845: step 173800, loss = 0.079487, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-10 20:45:28.454686: step 173900, loss = 0.039009, learning_rate = 0.000000 (2605.9 examples/sec)
=> 2021-11-10 20:45:48.414163: step 174000, loss = 0.078843, learning_rate = 0.000000 (2586.9 examples/sec)
=> Model saved to file: ./logs_res/model-174000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:46:20.546240: step 174100, loss = 0.052312, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 20:46:40.479303: step 174200, loss = 0.069194, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 20:47:01.402535: step 174300, loss = 0.071331, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-10 20:47:21.331626: step 174400, loss = 0.058961, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-10 20:47:41.248245: step 174500, loss = 0.075440, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-10 20:48:01.160702: step 174600, loss = 0.113988, learning_rate = 0.000000 (2593.4 examples/sec)
=> 2021-11-10 20:48:21.092738: step 174700, loss = 0.072813, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-10 20:48:41.889087: step 174800, loss = 0.053434, learning_rate = 0.000000 (2606.9 examples/sec)
=> 2021-11-10 20:49:01.829487: step 174900, loss = 0.047275, learning_rate = 0.000000 (2607.1 examples/sec)
=> 2021-11-10 20:49:21.818956: step 175000, loss = 0.031655, learning_rate = 0.000000 (2583.0 examples/sec)
=> Model saved to file: ./logs_res/model-175000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:49:53.767193: step 175100, loss = 0.079121, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 20:50:14.709846: step 175200, loss = 0.093099, learning_rate = 0.000000 (2607.4 examples/sec)
=> 2021-11-10 20:50:34.623336: step 175300, loss = 0.043612, learning_rate = 0.000000 (2593.1 examples/sec)
=> 2021-11-10 20:50:57.536290: step 175400, loss = 0.099518, learning_rate = 0.000000 (2765.0 examples/sec)
=> 2021-11-10 20:51:24.603450: step 175500, loss = 0.079528, learning_rate = 0.000000 (3030.5 examples/sec)
=> 2021-11-10 20:51:45.386577: step 175600, loss = 0.071540, learning_rate = 0.000000 (2606.0 examples/sec)
=> 2021-11-10 20:52:05.300571: step 175700, loss = 0.084178, learning_rate = 0.000000 (2592.9 examples/sec)
=> 2021-11-10 20:52:25.222509: step 175800, loss = 0.073416, learning_rate = 0.000000 (2592.0 examples/sec)
=> 2021-11-10 20:52:45.153996: step 175900, loss = 0.077991, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-10 20:53:05.911002: step 176000, loss = 0.036622, learning_rate = 0.000000 (2609.7 examples/sec)
=> Model saved to file: ./logs_res/model-176000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:53:37.815040: step 176100, loss = 0.074831, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 20:53:57.767007: step 176200, loss = 0.066396, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 20:54:17.768279: step 176300, loss = 0.066291, learning_rate = 0.000000 (2581.3 examples/sec)
=> 2021-11-10 20:54:38.708686: step 176400, loss = 0.054759, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 20:54:58.759555: step 176500, loss = 0.035912, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-10 20:55:18.840295: step 176600, loss = 0.093202, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-10 20:55:38.927838: step 176700, loss = 0.085954, learning_rate = 0.000000 (2570.6 examples/sec)
=> 2021-11-10 20:55:59.936208: step 176800, loss = 0.071955, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-10 20:56:20.048350: step 176900, loss = 0.059233, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-10 20:56:40.179547: step 177000, loss = 0.044815, learning_rate = 0.000000 (2564.9 examples/sec)
=> Model saved to file: ./logs_res/model-177000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 20:57:12.307308: step 177100, loss = 0.091287, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-10 20:57:33.269578: step 177200, loss = 0.059201, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 20:57:53.346372: step 177300, loss = 0.074254, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-10 20:58:13.459959: step 177400, loss = 0.046540, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-10 20:58:33.572568: step 177500, loss = 0.032941, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-10 20:58:53.698808: step 177600, loss = 0.051728, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-10 20:59:14.715745: step 177700, loss = 0.032998, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-10 20:59:34.862482: step 177800, loss = 0.058992, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-10 20:59:54.974324: step 177900, loss = 0.030889, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-10 21:00:15.109169: step 178000, loss = 0.032358, learning_rate = 0.000000 (2564.2 examples/sec)
=> Model saved to file: ./logs_res/model-178000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:00:47.852555: step 178100, loss = 0.064946, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 21:01:07.943790: step 178200, loss = 0.084766, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-10 21:01:28.042725: step 178300, loss = 0.097897, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-10 21:01:48.140634: step 178400, loss = 0.053290, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-10 21:02:09.109157: step 178500, loss = 0.033420, learning_rate = 0.000000 (2598.7 examples/sec)
=> 2021-11-10 21:02:29.241317: step 178600, loss = 0.060673, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-10 21:02:49.380192: step 178700, loss = 0.041821, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-10 21:03:09.509176: step 178800, loss = 0.038970, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-10 21:03:30.592644: step 178900, loss = 0.084090, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 21:03:50.688182: step 179000, loss = 0.082080, learning_rate = 0.000000 (2569.2 examples/sec)
=> Model saved to file: ./logs_res/model-179000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949189, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:04:22.781682: step 179100, loss = 0.052089, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-10 21:04:42.856184: step 179200, loss = 0.061163, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-10 21:05:03.885435: step 179300, loss = 0.029342, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-10 21:05:23.978107: step 179400, loss = 0.042910, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-10 21:05:44.136642: step 179500, loss = 0.039924, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-10 21:06:04.238523: step 179600, loss = 0.056412, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-10 21:06:25.329479: step 179700, loss = 0.057440, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 21:06:45.454374: step 179800, loss = 0.055873, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-10 21:07:05.566490: step 179900, loss = 0.067083, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-10 21:07:25.684133: step 180000, loss = 0.051971, learning_rate = 0.000000 (2566.9 examples/sec)
=> Model saved to file: ./logs_res/model-180000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:07:58.415107: step 180100, loss = 0.037304, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-10 21:08:18.455456: step 180200, loss = 0.072122, learning_rate = 0.000000 (2576.4 examples/sec)
=> 2021-11-10 21:08:38.527841: step 180300, loss = 0.049966, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-10 21:08:58.605576: step 180400, loss = 0.078527, learning_rate = 0.000000 (2571.6 examples/sec)
=> 2021-11-10 21:09:18.697659: step 180500, loss = 0.083036, learning_rate = 0.000000 (2570.5 examples/sec)
=> 2021-11-10 21:09:39.631956: step 180600, loss = 0.049830, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 21:09:59.742952: step 180700, loss = 0.039071, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-10 21:10:19.883813: step 180800, loss = 0.056102, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-10 21:10:40.004433: step 180900, loss = 0.069928, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-10 21:11:00.943993: step 181000, loss = 0.108938, learning_rate = 0.000000 (2589.5 examples/sec)
=> Model saved to file: ./logs_res/model-181000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:11:33.258652: step 181100, loss = 0.038900, learning_rate = 0.000000 (2574.4 examples/sec)
=> 2021-11-10 21:11:53.302738: step 181200, loss = 0.059297, learning_rate = 0.000000 (2575.8 examples/sec)
=> 2021-11-10 21:12:13.396143: step 181300, loss = 0.068832, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-10 21:12:34.500617: step 181400, loss = 0.021714, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 21:12:54.579728: step 181500, loss = 0.058574, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-10 21:13:14.680162: step 181600, loss = 0.046763, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-10 21:13:34.778820: step 181700, loss = 0.054665, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-10 21:13:55.888871: step 181800, loss = 0.068844, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 21:14:15.989997: step 181900, loss = 0.071467, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-10 21:14:36.095452: step 182000, loss = 0.060475, learning_rate = 0.000000 (2568.1 examples/sec)
=> Model saved to file: ./logs_res/model-182000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:15:08.260389: step 182100, loss = 0.059516, learning_rate = 0.000000 (2575.2 examples/sec)
=> 2021-11-10 21:15:29.160690: step 182200, loss = 0.104677, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-10 21:15:49.215129: step 182300, loss = 0.060624, learning_rate = 0.000000 (2574.7 examples/sec)
=> 2021-11-10 21:16:09.280863: step 182400, loss = 0.058148, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-10 21:16:29.363566: step 182500, loss = 0.073704, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-10 21:16:50.364396: step 182600, loss = 0.036587, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 21:17:10.448535: step 182700, loss = 0.058031, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-10 21:17:30.551778: step 182800, loss = 0.056611, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-10 21:17:50.632313: step 182900, loss = 0.026732, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-10 21:18:11.569386: step 183000, loss = 0.102706, learning_rate = 0.000000 (2588.0 examples/sec)
=> Model saved to file: ./logs_res/model-183000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:18:43.451567: step 183100, loss = 0.059923, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-10 21:19:03.497121: step 183200, loss = 0.057445, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-10 21:19:23.563463: step 183300, loss = 0.093981, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-10 21:19:43.622170: step 183400, loss = 0.074752, learning_rate = 0.000000 (2574.6 examples/sec)
=> 2021-11-10 21:20:04.572128: step 183500, loss = 0.045995, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 21:20:24.665689: step 183600, loss = 0.040133, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-10 21:20:44.830619: step 183700, loss = 0.074305, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-10 21:21:04.924034: step 183800, loss = 0.043401, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-10 21:21:25.877694: step 183900, loss = 0.074222, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-10 21:21:45.976634: step 184000, loss = 0.059850, learning_rate = 0.000000 (2569.0 examples/sec)
=> Model saved to file: ./logs_res/model-184000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:22:17.934755: step 184100, loss = 0.066537, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-10 21:22:38.021022: step 184200, loss = 0.062109, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-10 21:22:58.988181: step 184300, loss = 0.034765, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 21:23:19.075403: step 184400, loss = 0.078717, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-10 21:23:39.179695: step 184500, loss = 0.068387, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-10 21:23:59.275252: step 184600, loss = 0.087691, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-10 21:24:20.199706: step 184700, loss = 0.076392, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 21:24:40.285783: step 184800, loss = 0.058982, learning_rate = 0.000000 (2570.6 examples/sec)
=> 2021-11-10 21:25:00.384273: step 184900, loss = 0.061297, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-10 21:25:20.478521: step 185000, loss = 0.052908, learning_rate = 0.000000 (2569.8 examples/sec)
=> Model saved to file: ./logs_res/model-185000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954086, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:25:53.873268: step 185100, loss = 0.047530, learning_rate = 0.000000 (2594.3 examples/sec)
=> 2021-11-10 21:26:13.946438: step 185200, loss = 0.086300, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-10 21:26:34.012488: step 185300, loss = 0.068893, learning_rate = 0.000000 (2573.0 examples/sec)
=> 2021-11-10 21:26:54.092617: step 185400, loss = 0.102128, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-10 21:27:15.218200: step 185500, loss = 0.071860, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-10 21:27:35.314168: step 185600, loss = 0.047033, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-10 21:27:55.407296: step 185700, loss = 0.091419, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-10 21:28:15.491390: step 185800, loss = 0.040642, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-10 21:28:36.442087: step 185900, loss = 0.080369, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 21:28:56.522716: step 186000, loss = 0.064390, learning_rate = 0.000000 (2571.0 examples/sec)
=> Model saved to file: ./logs_res/model-186000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950566, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:29:28.840381: step 186100, loss = 0.029716, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-10 21:29:48.929529: step 186200, loss = 0.046616, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-10 21:30:08.985788: step 186300, loss = 0.082116, learning_rate = 0.000000 (2574.4 examples/sec)
=> 2021-11-10 21:30:30.101463: step 186400, loss = 0.053026, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-10 21:30:50.199736: step 186500, loss = 0.058418, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-10 21:31:10.295568: step 186600, loss = 0.052530, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-10 21:31:30.415189: step 186700, loss = 0.065307, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-10 21:31:51.401407: step 186800, loss = 0.034231, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 21:32:11.526961: step 186900, loss = 0.062946, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-10 21:32:31.641625: step 187000, loss = 0.080464, learning_rate = 0.000000 (2566.5 examples/sec)
=> Model saved to file: ./logs_res/model-187000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949954, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:33:03.731649: step 187100, loss = 0.100972, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-10 21:33:24.976380: step 187200, loss = 0.042874, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-10 21:33:45.169637: step 187300, loss = 0.050852, learning_rate = 0.000000 (2557.9 examples/sec)
=> 2021-11-10 21:34:05.335392: step 187400, loss = 0.064571, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-10 21:34:25.433161: step 187500, loss = 0.054597, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-10 21:34:46.497997: step 187600, loss = 0.037882, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-10 21:35:06.584969: step 187700, loss = 0.064677, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-10 21:35:26.673443: step 187800, loss = 0.049219, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-10 21:35:46.779412: step 187900, loss = 0.067329, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-10 21:36:07.785034: step 188000, loss = 0.029281, learning_rate = 0.000000 (2581.3 examples/sec)
=> Model saved to file: ./logs_res/model-188000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:36:40.299373: step 188100, loss = 0.069505, learning_rate = 0.000000 (2572.1 examples/sec)
=> 2021-11-10 21:37:00.369597: step 188200, loss = 0.050384, learning_rate = 0.000000 (2573.0 examples/sec)
=> 2021-11-10 21:37:20.440112: step 188300, loss = 0.047593, learning_rate = 0.000000 (2573.0 examples/sec)
=> 2021-11-10 21:37:41.365447: step 188400, loss = 0.046189, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 21:38:01.462738: step 188500, loss = 0.052012, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-10 21:38:21.568200: step 188600, loss = 0.082022, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-10 21:38:41.659378: step 188700, loss = 0.049422, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-10 21:39:02.679896: step 188800, loss = 0.038211, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 21:39:22.755769: step 188900, loss = 0.081724, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-10 21:39:42.843799: step 189000, loss = 0.038452, learning_rate = 0.000000 (2570.1 examples/sec)
=> Model saved to file: ./logs_res/model-189000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:40:14.824371: step 189100, loss = 0.045123, learning_rate = 0.000000 (2576.0 examples/sec)
=> 2021-11-10 21:40:35.950607: step 189200, loss = 0.065984, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 21:40:56.012532: step 189300, loss = 0.042244, learning_rate = 0.000000 (2573.5 examples/sec)
=> 2021-11-10 21:41:16.103381: step 189400, loss = 0.057416, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-10 21:41:36.216129: step 189500, loss = 0.050441, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-10 21:41:56.310909: step 189600, loss = 0.051365, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-10 21:42:17.345863: step 189700, loss = 0.048988, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 21:42:37.459359: step 189800, loss = 0.035468, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-10 21:42:57.543793: step 189900, loss = 0.053367, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-10 21:43:17.660196: step 190000, loss = 0.027494, learning_rate = 0.000000 (2566.5 examples/sec)
=> Model saved to file: ./logs_res/model-190000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:43:50.670456: step 190100, loss = 0.060053, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 21:44:10.735843: step 190200, loss = 0.040360, learning_rate = 0.000000 (2572.9 examples/sec)
=> 2021-11-10 21:44:30.818196: step 190300, loss = 0.070819, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-10 21:44:50.894643: step 190400, loss = 0.083248, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-10 21:45:11.851458: step 190500, loss = 0.041844, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 21:45:31.937551: step 190600, loss = 0.072741, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-10 21:45:52.031550: step 190700, loss = 0.071187, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-10 21:46:12.131779: step 190800, loss = 0.060734, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-10 21:46:33.141477: step 190900, loss = 0.054801, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-10 21:46:53.237443: step 191000, loss = 0.055868, learning_rate = 0.000000 (2569.2 examples/sec)
=> Model saved to file: ./logs_res/model-191000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:47:25.393878: step 191100, loss = 0.064688, learning_rate = 0.000000 (2575.7 examples/sec)
=> 2021-11-10 21:47:45.535263: step 191200, loss = 0.045433, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-10 21:48:06.458525: step 191300, loss = 0.028746, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 21:48:26.530097: step 191400, loss = 0.110162, learning_rate = 0.000000 (2572.5 examples/sec)
=> 2021-11-10 21:48:46.618624: step 191500, loss = 0.066623, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-10 21:49:06.720336: step 191600, loss = 0.036704, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-10 21:49:27.673696: step 191700, loss = 0.072726, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-10 21:49:47.771633: step 191800, loss = 0.066817, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-10 21:50:07.862428: step 191900, loss = 0.069170, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-10 21:50:27.949996: step 192000, loss = 0.039505, learning_rate = 0.000000 (2570.2 examples/sec)
=> Model saved to file: ./logs_res/model-192000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:51:00.868888: step 192100, loss = 0.036366, learning_rate = 0.000000 (2593.9 examples/sec)
=> 2021-11-10 21:51:20.948496: step 192200, loss = 0.076617, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-10 21:51:41.052937: step 192300, loss = 0.079784, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-10 21:52:01.143041: step 192400, loss = 0.034903, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-10 21:52:21.233134: step 192500, loss = 0.032206, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-10 21:52:42.142646: step 192600, loss = 0.026059, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 21:53:02.248877: step 192700, loss = 0.039594, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-10 21:53:22.341331: step 192800, loss = 0.078839, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-10 21:53:42.443285: step 192900, loss = 0.071478, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-10 21:54:03.423609: step 193000, loss = 0.043170, learning_rate = 0.000000 (2579.0 examples/sec)
=> Model saved to file: ./logs_res/model-193000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:54:35.272885: step 193100, loss = 0.047777, learning_rate = 0.000000 (2580.0 examples/sec)
=> 2021-11-10 21:54:55.320295: step 193200, loss = 0.075213, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-10 21:55:15.376838: step 193300, loss = 0.067304, learning_rate = 0.000000 (2574.3 examples/sec)
=> 2021-11-10 21:55:36.281975: step 193400, loss = 0.041360, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 21:55:56.358726: step 193500, loss = 0.089959, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-10 21:56:16.446777: step 193600, loss = 0.071923, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-10 21:56:36.526627: step 193700, loss = 0.040491, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-10 21:56:57.444997: step 193800, loss = 0.031745, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 21:57:17.518229: step 193900, loss = 0.045701, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-10 21:57:37.596148: step 194000, loss = 0.096144, learning_rate = 0.000000 (2571.5 examples/sec)
=> Model saved to file: ./logs_res/model-194000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950031, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 21:58:09.512187: step 194100, loss = 0.029115, learning_rate = 0.000000 (2577.3 examples/sec)
=> 2021-11-10 21:58:30.374489: step 194200, loss = 0.042262, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-10 21:58:50.431343: step 194300, loss = 0.032820, learning_rate = 0.000000 (2574.1 examples/sec)
=> 2021-11-10 21:59:10.526470: step 194400, loss = 0.046040, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-10 21:59:30.620910: step 194500, loss = 0.079339, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-10 21:59:51.562885: step 194600, loss = 0.045413, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 22:00:11.658418: step 194700, loss = 0.072261, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-10 22:00:31.763023: step 194800, loss = 0.052266, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-10 22:00:51.848952: step 194900, loss = 0.053034, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-10 22:01:12.806192: step 195000, loss = 0.057146, learning_rate = 0.000000 (2584.5 examples/sec)
=> Model saved to file: ./logs_res/model-195000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:01:44.806960: step 195100, loss = 0.029138, learning_rate = 0.000000 (2574.6 examples/sec)
=> 2021-11-10 22:02:04.856090: step 195200, loss = 0.040555, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-10 22:02:24.937793: step 195300, loss = 0.065629, learning_rate = 0.000000 (2571.3 examples/sec)
=> 2021-11-10 22:02:45.069251: step 195400, loss = 0.024396, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-10 22:03:06.048402: step 195500, loss = 0.051762, learning_rate = 0.000000 (2595.6 examples/sec)
=> 2021-11-10 22:03:26.126551: step 195600, loss = 0.042010, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-10 22:03:46.220178: step 195700, loss = 0.042301, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-10 22:04:06.310059: step 195800, loss = 0.054626, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-10 22:04:27.266992: step 195900, loss = 0.057409, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-10 22:04:47.365768: step 196000, loss = 0.048585, learning_rate = 0.000000 (2569.1 examples/sec)
=> Model saved to file: ./logs_res/model-196000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:05:19.553959: step 196100, loss = 0.108213, learning_rate = 0.000000 (2578.9 examples/sec)
=> 2021-11-10 22:05:39.604486: step 196200, loss = 0.025692, learning_rate = 0.000000 (2575.1 examples/sec)
=> 2021-11-10 22:06:00.761422: step 196300, loss = 0.034233, learning_rate = 0.000000 (2607.5 examples/sec)
=> 2021-11-10 22:06:20.797241: step 196400, loss = 0.060715, learning_rate = 0.000000 (2577.1 examples/sec)
=> 2021-11-10 22:06:40.818560: step 196500, loss = 0.073332, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-10 22:07:00.830182: step 196600, loss = 0.047679, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-10 22:07:21.738893: step 196700, loss = 0.047936, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-10 22:07:41.681833: step 196800, loss = 0.064329, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 22:08:01.637358: step 196900, loss = 0.021630, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 22:08:21.595518: step 197000, loss = 0.031774, learning_rate = 0.000000 (2587.1 examples/sec)
=> Model saved to file: ./logs_res/model-197000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:08:55.349480: step 197100, loss = 0.052922, learning_rate = 0.000000 (2575.6 examples/sec)
=> 2021-11-10 22:09:15.314721: step 197200, loss = 0.039524, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 22:09:35.295406: step 197300, loss = 0.055803, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-10 22:09:55.264891: step 197400, loss = 0.025633, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 22:10:16.472025: step 197500, loss = 0.056390, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 22:10:36.495392: step 197600, loss = 0.037633, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-10 22:10:56.645286: step 197700, loss = 0.058711, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-10 22:11:16.629146: step 197800, loss = 0.033375, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 22:11:37.752116: step 197900, loss = 0.024695, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-10 22:11:57.902784: step 198000, loss = 0.049148, learning_rate = 0.000000 (2563.4 examples/sec)
=> Model saved to file: ./logs_res/model-198000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:12:30.605624: step 198100, loss = 0.036493, learning_rate = 0.000000 (2594.5 examples/sec)
=> 2021-11-10 22:12:50.520914: step 198200, loss = 0.063848, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-10 22:13:10.465561: step 198300, loss = 0.107458, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-10 22:13:31.499157: step 198400, loss = 0.060812, learning_rate = 0.000000 (2613.1 examples/sec)
=> 2021-11-10 22:13:51.437496: step 198500, loss = 0.027292, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 22:14:11.441268: step 198600, loss = 0.047469, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 22:14:31.411253: step 198700, loss = 0.028174, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-10 22:14:52.267554: step 198800, loss = 0.055368, learning_rate = 0.000000 (2601.5 examples/sec)
=> 2021-11-10 22:15:12.203268: step 198900, loss = 0.047751, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-10 22:15:32.153989: step 199000, loss = 0.112292, learning_rate = 0.000000 (2588.2 examples/sec)
=> Model saved to file: ./logs_res/model-199000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:16:04.144461: step 199100, loss = 0.097438, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 22:16:25.051261: step 199200, loss = 0.034341, learning_rate = 0.000000 (2604.6 examples/sec)
=> 2021-11-10 22:16:44.985256: step 199300, loss = 0.018169, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 22:17:04.918523: step 199400, loss = 0.054826, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 22:17:24.870305: step 199500, loss = 0.053424, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 22:17:45.830851: step 199600, loss = 0.057790, learning_rate = 0.000000 (2604.4 examples/sec)
=> 2021-11-10 22:18:05.778476: step 199700, loss = 0.049821, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 22:18:25.726218: step 199800, loss = 0.032377, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 22:18:45.664216: step 199900, loss = 0.029192, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 22:19:06.545979: step 200000, loss = 0.042693, learning_rate = 0.000000 (2604.8 examples/sec)
=> Model saved to file: ./logs_res/model-200000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:19:38.393563: step 200100, loss = 0.077326, learning_rate = 0.000000 (2574.9 examples/sec)
=> 2021-11-10 22:19:58.362444: step 200200, loss = 0.032713, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 22:20:18.299148: step 200300, loss = 0.059154, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-10 22:20:39.091115: step 200400, loss = 0.032620, learning_rate = 0.000000 (2602.3 examples/sec)
=> 2021-11-10 22:20:59.098024: step 200500, loss = 0.048626, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-10 22:21:19.082657: step 200600, loss = 0.035209, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-10 22:21:39.036226: step 200700, loss = 0.052561, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-10 22:21:59.947446: step 200800, loss = 0.045296, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-10 22:22:19.919463: step 200900, loss = 0.041593, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-10 22:22:39.877266: step 201000, loss = 0.061769, learning_rate = 0.000000 (2587.0 examples/sec)
=> Model saved to file: ./logs_res/model-201000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947429, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:23:11.750641: step 201100, loss = 0.038910, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 22:23:31.694949: step 201200, loss = 0.037909, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 22:23:52.497827: step 201300, loss = 0.056794, learning_rate = 0.000000 (2604.5 examples/sec)
=> 2021-11-10 22:24:12.449105: step 201400, loss = 0.040519, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-10 22:24:32.490814: step 201500, loss = 0.065161, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-10 22:24:52.616650: step 201600, loss = 0.022517, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-10 22:25:13.648593: step 201700, loss = 0.051958, learning_rate = 0.000000 (2596.0 examples/sec)
=> 2021-11-10 22:25:33.738848: step 201800, loss = 0.039705, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-10 22:25:53.805987: step 201900, loss = 0.041822, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-10 22:26:13.840773: step 202000, loss = 0.030104, learning_rate = 0.000000 (2577.3 examples/sec)
=> Model saved to file: ./logs_res/model-202000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:26:47.273517: step 202100, loss = 0.036744, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-10 22:27:07.270225: step 202200, loss = 0.024125, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-10 22:27:27.274712: step 202300, loss = 0.031468, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-10 22:27:47.237739: step 202400, loss = 0.060110, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 22:28:08.240613: step 202500, loss = 0.056640, learning_rate = 0.000000 (2604.5 examples/sec)
=> 2021-11-10 22:28:28.201375: step 202600, loss = 0.042751, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 22:28:48.176336: step 202700, loss = 0.035025, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 22:29:08.151904: step 202800, loss = 0.056052, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 22:29:29.202059: step 202900, loss = 0.036977, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 22:29:49.161307: step 203000, loss = 0.047925, learning_rate = 0.000000 (2587.1 examples/sec)
=> Model saved to file: ./logs_res/model-203000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:30:24.497102: step 203100, loss = 0.045935, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 22:30:44.427969: step 203200, loss = 0.056275, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-10 22:31:05.396859: step 203300, loss = 0.055298, learning_rate = 0.000000 (2701.5 examples/sec)
=> 2021-11-10 22:31:25.331385: step 203400, loss = 0.062156, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-10 22:31:45.287537: step 203500, loss = 0.032916, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 22:32:05.270538: step 203600, loss = 0.031872, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-10 22:32:26.257759: step 203700, loss = 0.057207, learning_rate = 0.000000 (2601.5 examples/sec)
=> 2021-11-10 22:32:46.237859: step 203800, loss = 0.062251, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 22:33:06.207581: step 203900, loss = 0.032874, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 22:33:26.170930: step 204000, loss = 0.070109, learning_rate = 0.000000 (2586.2 examples/sec)
=> Model saved to file: ./logs_res/model-204000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:33:59.130426: step 204100, loss = 0.036783, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-10 22:34:19.886844: step 204200, loss = 0.040243, learning_rate = 0.000000 (2609.4 examples/sec)
=> 2021-11-10 22:34:39.819375: step 204300, loss = 0.026241, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-10 22:34:59.962934: step 204400, loss = 0.074401, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-10 22:35:19.906523: step 204500, loss = 0.032878, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-10 22:35:40.892082: step 204600, loss = 0.077309, learning_rate = 0.000000 (2599.6 examples/sec)
=> 2021-11-10 22:36:00.858000: step 204700, loss = 0.064032, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 22:36:20.814535: step 204800, loss = 0.037373, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-10 22:36:40.780602: step 204900, loss = 0.044594, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 22:37:01.692044: step 205000, loss = 0.052079, learning_rate = 0.000000 (2594.3 examples/sec)
=> Model saved to file: ./logs_res/model-205000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:37:33.682016: step 205100, loss = 0.047271, learning_rate = 0.000000 (2593.7 examples/sec)
=> 2021-11-10 22:37:53.601224: step 205200, loss = 0.034949, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-10 22:38:13.587304: step 205300, loss = 0.077667, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 22:38:34.417398: step 205400, loss = 0.051560, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-10 22:38:54.391498: step 205500, loss = 0.065764, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 22:39:14.541673: step 205600, loss = 0.044595, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-10 22:39:34.520670: step 205700, loss = 0.029286, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-10 22:39:55.380520: step 205800, loss = 0.043710, learning_rate = 0.000000 (2599.6 examples/sec)
=> 2021-11-10 22:40:15.351192: step 205900, loss = 0.058886, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 22:40:35.345313: step 206000, loss = 0.094265, learning_rate = 0.000000 (2582.5 examples/sec)
=> Model saved to file: ./logs_res/model-206000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950260, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:41:07.233551: step 206100, loss = 0.021476, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 22:41:28.132899: step 206200, loss = 0.046781, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-10 22:41:48.079555: step 206300, loss = 0.063541, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-10 22:42:08.024848: step 206400, loss = 0.076653, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-10 22:42:27.979225: step 206500, loss = 0.032700, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 22:42:48.937344: step 206600, loss = 0.042171, learning_rate = 0.000000 (2599.9 examples/sec)
=> 2021-11-10 22:43:08.897823: step 206700, loss = 0.062865, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 22:43:28.853885: step 206800, loss = 0.041575, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 22:43:48.829358: step 206900, loss = 0.044396, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 22:44:08.793124: step 207000, loss = 0.033445, learning_rate = 0.000000 (2588.4 examples/sec)
=> Model saved to file: ./logs_res/model-207000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:44:42.787930: step 207100, loss = 0.039850, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-10 22:45:02.788441: step 207200, loss = 0.060974, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-10 22:45:22.785951: step 207300, loss = 0.019348, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 22:45:42.986559: step 207400, loss = 0.039899, learning_rate = 0.000000 (2555.6 examples/sec)
=> 2021-11-10 22:46:03.952504: step 207500, loss = 0.067534, learning_rate = 0.000000 (2594.6 examples/sec)
=> 2021-11-10 22:46:23.969381: step 207600, loss = 0.037735, learning_rate = 0.000000 (2579.5 examples/sec)
=> 2021-11-10 22:46:43.959733: step 207700, loss = 0.053587, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 22:47:03.936850: step 207800, loss = 0.049011, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-10 22:47:24.876939: step 207900, loss = 0.039988, learning_rate = 0.000000 (2601.5 examples/sec)
=> 2021-11-10 22:47:44.821508: step 208000, loss = 0.065790, learning_rate = 0.000000 (2588.7 examples/sec)
=> Model saved to file: ./logs_res/model-208000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:48:16.775737: step 208100, loss = 0.057839, learning_rate = 0.000000 (2591.8 examples/sec)
=> 2021-11-10 22:48:36.714885: step 208200, loss = 0.035309, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 22:48:57.515288: step 208300, loss = 0.055182, learning_rate = 0.000000 (2602.5 examples/sec)
=> 2021-11-10 22:49:17.458491: step 208400, loss = 0.060982, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 22:49:37.413098: step 208500, loss = 0.053568, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 22:49:57.352226: step 208600, loss = 0.063357, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 22:50:18.148374: step 208700, loss = 0.047859, learning_rate = 0.000000 (2605.0 examples/sec)
=> 2021-11-10 22:50:38.109078: step 208800, loss = 0.082690, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 22:50:58.047580: step 208900, loss = 0.047239, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-10 22:51:18.026362: step 209000, loss = 0.073664, learning_rate = 0.000000 (2584.6 examples/sec)
=> Model saved to file: ./logs_res/model-209000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:51:50.740353: step 209100, loss = 0.072173, learning_rate = 0.000000 (2607.4 examples/sec)
=> 2021-11-10 22:52:10.678245: step 209200, loss = 0.042306, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 22:52:30.640386: step 209300, loss = 0.025415, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 22:52:50.604714: step 209400, loss = 0.057876, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-10 22:53:11.436818: step 209500, loss = 0.036132, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-10 22:53:31.462205: step 209600, loss = 0.064098, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-10 22:53:51.452965: step 209700, loss = 0.023981, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 22:54:11.403296: step 209800, loss = 0.049630, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 22:54:32.264385: step 209900, loss = 0.041422, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-10 22:54:52.219807: step 210000, loss = 0.054134, learning_rate = 0.000000 (2587.4 examples/sec)
=> Model saved to file: ./logs_res/model-210000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949878, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:55:23.847588: step 210100, loss = 0.055957, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 22:55:43.909187: step 210200, loss = 0.030441, learning_rate = 0.000000 (2573.8 examples/sec)
=> 2021-11-10 22:56:03.878957: step 210300, loss = 0.042160, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-10 22:56:24.739460: step 210400, loss = 0.090825, learning_rate = 0.000000 (2599.7 examples/sec)
=> 2021-11-10 22:56:44.735334: step 210500, loss = 0.052860, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 22:57:04.707948: step 210600, loss = 0.037561, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 22:57:24.685679: step 210700, loss = 0.033002, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-10 22:57:45.664817: step 210800, loss = 0.027326, learning_rate = 0.000000 (2599.4 examples/sec)
=> 2021-11-10 22:58:05.660623: step 210900, loss = 0.043453, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 22:58:25.650455: step 211000, loss = 0.042406, learning_rate = 0.000000 (2582.8 examples/sec)
=> Model saved to file: ./logs_res/model-211000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 22:58:57.512092: step 211100, loss = 0.046927, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 22:59:18.318895: step 211200, loss = 0.054883, learning_rate = 0.000000 (2601.8 examples/sec)
=> 2021-11-10 22:59:38.299348: step 211300, loss = 0.035399, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-10 22:59:58.272571: step 211400, loss = 0.052880, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-10 23:00:18.232325: step 211500, loss = 0.042910, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 23:00:39.037140: step 211600, loss = 0.135679, learning_rate = 0.000000 (2603.9 examples/sec)
=> 2021-11-10 23:00:59.029974: step 211700, loss = 0.044353, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 23:01:19.015627: step 211800, loss = 0.044255, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-10 23:01:38.980247: step 211900, loss = 0.055458, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-10 23:01:59.940522: step 212000, loss = 0.039787, learning_rate = 0.000000 (2598.7 examples/sec)
=> Model saved to file: ./logs_res/model-212000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:02:31.866582: step 212100, loss = 0.046003, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-10 23:02:51.823307: step 212200, loss = 0.021461, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-10 23:03:11.809432: step 212300, loss = 0.014837, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 23:03:32.636298: step 212400, loss = 0.050690, learning_rate = 0.000000 (2600.4 examples/sec)
=> 2021-11-10 23:03:52.648073: step 212500, loss = 0.037080, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-10 23:04:12.728008: step 212600, loss = 0.051617, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-10 23:04:32.823850: step 212700, loss = 0.055798, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-10 23:04:53.671781: step 212800, loss = 0.051835, learning_rate = 0.000000 (2594.7 examples/sec)
=> 2021-11-10 23:05:13.714391: step 212900, loss = 0.051425, learning_rate = 0.000000 (2575.9 examples/sec)
=> 2021-11-10 23:05:33.733107: step 213000, loss = 0.050664, learning_rate = 0.000000 (2578.9 examples/sec)
=> Model saved to file: ./logs_res/model-213000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:06:05.587776: step 213100, loss = 0.034060, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-10 23:06:25.569337: step 213200, loss = 0.063125, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 23:06:46.437096: step 213300, loss = 0.075327, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-10 23:07:06.438551: step 213400, loss = 0.048017, learning_rate = 0.000000 (2581.2 examples/sec)
=> 2021-11-10 23:07:26.480784: step 213500, loss = 0.044642, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-10 23:07:46.490073: step 213600, loss = 0.071533, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-10 23:08:07.397195: step 213700, loss = 0.044505, learning_rate = 0.000000 (2596.2 examples/sec)
=> 2021-11-10 23:08:27.410243: step 213800, loss = 0.045369, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-10 23:08:47.417106: step 213900, loss = 0.060459, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-10 23:09:07.421938: step 214000, loss = 0.036045, learning_rate = 0.000000 (2580.8 examples/sec)
=> Model saved to file: ./logs_res/model-214000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:09:40.612483: step 214100, loss = 0.043461, learning_rate = 0.000000 (2603.5 examples/sec)
=> 2021-11-10 23:10:00.586580: step 214200, loss = 0.069790, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-10 23:10:20.599943: step 214300, loss = 0.048558, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-10 23:10:40.608919: step 214400, loss = 0.070394, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-10 23:11:01.678829: step 214500, loss = 0.043104, learning_rate = 0.000000 (2598.9 examples/sec)
=> 2021-11-10 23:11:21.705950: step 214600, loss = 0.044131, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-10 23:11:41.742618: step 214700, loss = 0.041297, learning_rate = 0.000000 (2577.1 examples/sec)
=> 2021-11-10 23:12:01.762399: step 214800, loss = 0.027108, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-10 23:12:22.639320: step 214900, loss = 0.046734, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-10 23:12:42.631912: step 215000, loss = 0.052882, learning_rate = 0.000000 (2582.6 examples/sec)
=> Model saved to file: ./logs_res/model-215000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:13:14.371800: step 215100, loss = 0.042219, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-10 23:13:34.367600: step 215200, loss = 0.027774, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 23:13:55.339858: step 215300, loss = 0.032910, learning_rate = 0.000000 (2598.5 examples/sec)
=> 2021-11-10 23:14:15.299341: step 215400, loss = 0.039200, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 23:14:35.248709: step 215500, loss = 0.024279, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-10 23:14:55.216575: step 215600, loss = 0.055928, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 23:15:16.039924: step 215700, loss = 0.038786, learning_rate = 0.000000 (2601.7 examples/sec)
=> 2021-11-10 23:15:35.997538: step 215800, loss = 0.058910, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-10 23:15:55.966524: step 215900, loss = 0.046208, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-10 23:16:16.072037: step 216000, loss = 0.046069, learning_rate = 0.000000 (2567.8 examples/sec)
=> Model saved to file: ./logs_res/model-216000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:16:47.902632: step 216100, loss = 0.038660, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 23:17:08.762998: step 216200, loss = 0.040472, learning_rate = 0.000000 (2602.0 examples/sec)
=> 2021-11-10 23:17:28.709469: step 216300, loss = 0.056343, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 23:17:48.656443: step 216400, loss = 0.095127, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-10 23:18:08.611117: step 216500, loss = 0.043358, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-10 23:18:29.419598: step 216600, loss = 0.047392, learning_rate = 0.000000 (2604.1 examples/sec)
=> 2021-11-10 23:18:49.377253: step 216700, loss = 0.020535, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 23:19:09.326882: step 216800, loss = 0.061312, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 23:19:29.319058: step 216900, loss = 0.039737, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-10 23:19:50.127560: step 217000, loss = 0.033597, learning_rate = 0.000000 (2600.8 examples/sec)
=> Model saved to file: ./logs_res/model-217000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:20:21.811646: step 217100, loss = 0.047292, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-10 23:20:41.743033: step 217200, loss = 0.061438, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-10 23:21:01.701176: step 217300, loss = 0.048651, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-10 23:21:22.538016: step 217400, loss = 0.036648, learning_rate = 0.000000 (2599.4 examples/sec)
=> 2021-11-10 23:21:42.527798: step 217500, loss = 0.062640, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-10 23:22:02.518436: step 217600, loss = 0.030637, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-10 23:22:22.506716: step 217700, loss = 0.052233, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-10 23:22:43.362265: step 217800, loss = 0.060898, learning_rate = 0.000000 (2599.5 examples/sec)
=> 2021-11-10 23:23:03.347619: step 217900, loss = 0.030567, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 23:23:23.362015: step 218000, loss = 0.066696, learning_rate = 0.000000 (2581.2 examples/sec)
=> Model saved to file: ./logs_res/model-218000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:23:55.778090: step 218100, loss = 0.054998, learning_rate = 0.000000 (2590.4 examples/sec)
=> 2021-11-10 23:24:16.603305: step 218200, loss = 0.036154, learning_rate = 0.000000 (2601.2 examples/sec)
=> 2021-11-10 23:24:36.578740: step 218300, loss = 0.021601, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 23:24:56.553228: step 218400, loss = 0.041501, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 23:25:16.524983: step 218500, loss = 0.070337, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-10 23:25:37.336660: step 218600, loss = 0.048222, learning_rate = 0.000000 (2600.3 examples/sec)
=> 2021-11-10 23:25:57.285128: step 218700, loss = 0.064598, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 23:26:17.254962: step 218800, loss = 0.042851, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-10 23:26:37.215881: step 218900, loss = 0.035355, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-10 23:26:57.182570: step 219000, loss = 0.051147, learning_rate = 0.000000 (2586.6 examples/sec)
=> Model saved to file: ./logs_res/model-219000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:27:29.892159: step 219100, loss = 0.024881, learning_rate = 0.000000 (2604.4 examples/sec)
=> 2021-11-10 23:27:49.855006: step 219200, loss = 0.019625, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 23:28:09.846885: step 219300, loss = 0.035747, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 23:28:29.830677: step 219400, loss = 0.037016, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 23:28:50.781770: step 219500, loss = 0.029809, learning_rate = 0.000000 (2602.8 examples/sec)
=> 2021-11-10 23:29:10.769254: step 219600, loss = 0.035914, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-10 23:29:30.761805: step 219700, loss = 0.031208, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-10 23:29:50.758274: step 219800, loss = 0.039859, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-10 23:30:11.617784: step 219900, loss = 0.039009, learning_rate = 0.000000 (2601.8 examples/sec)
=> 2021-11-10 23:30:31.606850: step 220000, loss = 0.038186, learning_rate = 0.000000 (2583.3 examples/sec)
=> Model saved to file: ./logs_res/model-220000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:31:03.409494: step 220100, loss = 0.031613, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-10 23:31:23.361243: step 220200, loss = 0.052027, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-10 23:31:44.180590: step 220300, loss = 0.050471, learning_rate = 0.000000 (2601.7 examples/sec)
=> 2021-11-10 23:32:04.134703: step 220400, loss = 0.058343, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-10 23:32:24.173197: step 220500, loss = 0.042829, learning_rate = 0.000000 (2576.8 examples/sec)
=> 2021-11-10 23:32:44.122907: step 220600, loss = 0.054086, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-10 23:33:04.928090: step 220700, loss = 0.027843, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-10 23:33:24.949315: step 220800, loss = 0.065278, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-10 23:33:44.953005: step 220900, loss = 0.026717, learning_rate = 0.000000 (2581.2 examples/sec)
=> 2021-11-10 23:34:04.956756: step 221000, loss = 0.084088, learning_rate = 0.000000 (2581.1 examples/sec)
=> Model saved to file: ./logs_res/model-221000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:34:37.951001: step 221100, loss = 0.038027, learning_rate = 0.000000 (2604.9 examples/sec)
=> 2021-11-10 23:34:57.898978: step 221200, loss = 0.060504, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-10 23:35:17.847321: step 221300, loss = 0.031074, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 23:35:37.799843: step 221400, loss = 0.052392, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-10 23:35:58.639957: step 221500, loss = 0.027998, learning_rate = 0.000000 (2599.5 examples/sec)
=> 2021-11-10 23:36:18.625807: step 221600, loss = 0.052321, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-10 23:36:38.619385: step 221700, loss = 0.037606, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-10 23:36:58.579831: step 221800, loss = 0.034987, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 23:37:18.559378: step 221900, loss = 0.032174, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-10 23:37:39.379205: step 222000, loss = 0.025349, learning_rate = 0.000000 (2598.8 examples/sec)
=> Model saved to file: ./logs_res/model-222000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:38:11.188096: step 222100, loss = 0.056898, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-10 23:38:31.128682: step 222200, loss = 0.034299, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-10 23:38:51.169428: step 222300, loss = 0.051978, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-10 23:39:11.974977: step 222400, loss = 0.022767, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-10 23:39:31.935552: step 222500, loss = 0.031934, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-10 23:39:51.898995: step 222600, loss = 0.069570, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-10 23:40:11.861452: step 222700, loss = 0.038754, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-10 23:40:32.644449: step 222800, loss = 0.041591, learning_rate = 0.000000 (2604.2 examples/sec)
=> 2021-11-10 23:40:52.609126: step 222900, loss = 0.043902, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-10 23:41:12.566640: step 223000, loss = 0.032148, learning_rate = 0.000000 (2587.2 examples/sec)
=> Model saved to file: ./logs_res/model-223000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.954316
=> patience = 99
=> 2021-11-10 23:41:44.241938: step 223100, loss = 0.050213, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-10 23:42:05.152472: step 223200, loss = 0.027773, learning_rate = 0.000000 (2602.2 examples/sec)
=> 2021-11-10 23:42:25.151919: step 223300, loss = 0.037627, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-10 23:42:45.162927: step 223400, loss = 0.054934, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-10 23:43:05.155614: step 223500, loss = 0.033140, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-10 23:43:26.032427: step 223600, loss = 0.049399, learning_rate = 0.000000 (2597.2 examples/sec)
=> 2021-11-10 23:43:46.012327: step 223700, loss = 0.040207, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-10 23:44:05.997566: step 223800, loss = 0.053417, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-10 23:44:25.982983: step 223900, loss = 0.037854, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-10 23:44:46.847175: step 224000, loss = 0.048566, learning_rate = 0.000000 (2594.9 examples/sec)
=> Model saved to file: ./logs_res/model-224000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955158, best accuracy 0.954316
=> Model saved to file: ./logs_res/model-224000.pdparams
=> patience = 100
=> 2021-11-10 23:45:19.452985: step 224100, loss = 0.040455, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-10 23:45:39.398099: step 224200, loss = 0.055237, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-10 23:45:59.354650: step 224300, loss = 0.029369, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-10 23:46:20.142696: step 224400, loss = 0.042659, learning_rate = 0.000000 (2603.5 examples/sec)
=> 2021-11-10 23:46:40.123120: step 224500, loss = 0.040463, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-10 23:47:00.119875: step 224600, loss = 0.060926, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-10 23:47:20.098223: step 224700, loss = 0.055256, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-10 23:47:40.088766: step 224800, loss = 0.063049, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-10 23:48:00.895812: step 224900, loss = 0.031122, learning_rate = 0.000000 (2599.9 examples/sec)
=> 2021-11-10 23:48:20.857863: step 225000, loss = 0.048753, learning_rate = 0.000000 (2586.5 examples/sec)
=> Model saved to file: ./logs_res/model-225000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955158
=> patience = 99
=> 2021-11-10 23:48:52.537745: step 225100, loss = 0.046355, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-10 23:49:12.497542: step 225200, loss = 0.081006, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-10 23:49:33.500313: step 225300, loss = 0.069628, learning_rate = 0.000000 (2594.0 examples/sec)
=> 2021-11-10 23:49:53.476191: step 225400, loss = 0.093711, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-10 23:50:13.463750: step 225500, loss = 0.030904, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-10 23:50:33.473446: step 225600, loss = 0.026131, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-10 23:50:54.339051: step 225700, loss = 0.032062, learning_rate = 0.000000 (2597.4 examples/sec)
=> 2021-11-10 23:51:14.333991: step 225800, loss = 0.045012, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-10 23:51:34.314591: step 225900, loss = 0.045497, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-10 23:51:54.270042: step 226000, loss = 0.038662, learning_rate = 0.000000 (2587.1 examples/sec)
=> Model saved to file: ./logs_res/model-226000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955158
=> patience = 99
=> 2021-11-10 23:52:27.131602: step 226100, loss = 0.046221, learning_rate = 0.000000 (2606.2 examples/sec)
=> 2021-11-10 23:52:47.099126: step 226200, loss = 0.057029, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-10 23:53:07.048157: step 226300, loss = 0.035346, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-10 23:53:27.001373: step 226400, loss = 0.026043, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-10 23:53:47.793277: step 226500, loss = 0.054317, learning_rate = 0.000000 (2603.7 examples/sec)
=> 2021-11-10 23:54:07.769621: step 226600, loss = 0.032316, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-10 23:54:27.730274: step 226700, loss = 0.025279, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-10 23:54:47.693871: step 226800, loss = 0.037845, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-10 23:55:08.547834: step 226900, loss = 0.060406, learning_rate = 0.000000 (2595.1 examples/sec)
=> 2021-11-10 23:55:28.628115: step 227000, loss = 0.028211, learning_rate = 0.000000 (2571.1 examples/sec)
=> Model saved to file: ./logs_res/model-227000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.955158
=> patience = 99
=> 2021-11-10 23:56:00.538029: step 227100, loss = 0.081446, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-10 23:56:20.614275: step 227200, loss = 0.028564, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-10 23:56:41.649740: step 227300, loss = 0.035285, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-10 23:57:01.743531: step 227400, loss = 0.038474, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-10 23:57:21.852178: step 227500, loss = 0.067767, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-10 23:57:41.987822: step 227600, loss = 0.023405, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-10 23:58:02.125048: step 227700, loss = 0.056604, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-10 23:58:23.309340: step 227800, loss = 0.041527, learning_rate = 0.000000 (2551.2 examples/sec)
=> 2021-11-10 23:58:43.486598: step 227900, loss = 0.042425, learning_rate = 0.000000 (2558.6 examples/sec)
=> 2021-11-10 23:59:03.645703: step 228000, loss = 0.034538, learning_rate = 0.000000 (2561.1 examples/sec)
=> Model saved to file: ./logs_res/model-228000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955158
=> patience = 99
=> 2021-11-10 23:59:35.601808: step 228100, loss = 0.028640, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-10 23:59:56.537239: step 228200, loss = 0.025182, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-11 00:00:16.644622: step 228300, loss = 0.035584, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 00:00:36.746355: step 228400, loss = 0.035581, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 00:00:56.872789: step 228500, loss = 0.069370, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 00:01:17.885844: step 228600, loss = 0.029165, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 00:01:38.007252: step 228700, loss = 0.052436, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 00:01:58.140074: step 228800, loss = 0.028907, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 00:02:18.280221: step 228900, loss = 0.034789, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 00:02:39.344992: step 229000, loss = 0.059506, learning_rate = 0.000000 (2578.5 examples/sec)
=> Model saved to file: ./logs_res/model-229000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950031, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:03:11.529734: step 229100, loss = 0.067182, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 00:03:31.614017: step 229200, loss = 0.053751, learning_rate = 0.000000 (2571.0 examples/sec)
=> 2021-11-11 00:03:51.783391: step 229300, loss = 0.044272, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 00:04:12.814113: step 229400, loss = 0.063198, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 00:04:32.923406: step 229500, loss = 0.026351, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 00:04:53.077829: step 229600, loss = 0.034243, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 00:05:13.210320: step 229700, loss = 0.076957, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 00:05:34.162575: step 229800, loss = 0.021952, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 00:05:54.260505: step 229900, loss = 0.040464, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 00:06:14.351755: step 230000, loss = 0.077885, learning_rate = 0.000000 (2569.7 examples/sec)
=> Model saved to file: ./logs_res/model-230000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:06:46.750096: step 230100, loss = 0.051082, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-11 00:07:07.712312: step 230200, loss = 0.060289, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-11 00:07:27.777137: step 230300, loss = 0.024045, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-11 00:07:47.865600: step 230400, loss = 0.085225, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 00:08:07.967341: step 230500, loss = 0.024125, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 00:08:28.900080: step 230600, loss = 0.024971, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-11 00:08:49.055790: step 230700, loss = 0.099609, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 00:09:09.167765: step 230800, loss = 0.061140, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 00:09:29.267487: step 230900, loss = 0.058392, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 00:09:49.370445: step 231000, loss = 0.034893, learning_rate = 0.000000 (2568.4 examples/sec)
=> Model saved to file: ./logs_res/model-231000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:10:22.174772: step 231100, loss = 0.026877, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 00:10:42.249699: step 231200, loss = 0.019760, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-11 00:11:02.356794: step 231300, loss = 0.020953, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 00:11:22.469154: step 231400, loss = 0.055585, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 00:11:43.501456: step 231500, loss = 0.037424, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-11 00:12:03.597690: step 231600, loss = 0.051182, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 00:12:23.767169: step 231700, loss = 0.039111, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 00:12:43.856307: step 231800, loss = 0.037879, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 00:13:04.971965: step 231900, loss = 0.036387, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 00:13:25.100685: step 232000, loss = 0.046920, learning_rate = 0.000000 (2565.2 examples/sec)
=> Model saved to file: ./logs_res/model-232000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:13:57.020361: step 232100, loss = 0.019818, learning_rate = 0.000000 (2574.0 examples/sec)
=> 2021-11-11 00:14:17.076548: step 232200, loss = 0.034167, learning_rate = 0.000000 (2574.5 examples/sec)
=> 2021-11-11 00:14:38.128627: step 232300, loss = 0.037654, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 00:14:58.296299: step 232400, loss = 0.043102, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 00:15:18.411252: step 232500, loss = 0.047959, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 00:15:38.485342: step 232600, loss = 0.029688, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-11 00:15:59.435661: step 232700, loss = 0.045169, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-11 00:16:19.531235: step 232800, loss = 0.060492, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 00:16:39.623220: step 232900, loss = 0.020503, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 00:16:59.753779: step 233000, loss = 0.038577, learning_rate = 0.000000 (2565.4 examples/sec)
=> Model saved to file: ./logs_res/model-233000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:17:33.801457: step 233100, loss = 0.035216, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 00:17:53.836531: step 233200, loss = 0.039232, learning_rate = 0.000000 (2577.0 examples/sec)
=> 2021-11-11 00:18:13.902604: step 233300, loss = 0.012357, learning_rate = 0.000000 (2572.9 examples/sec)
=> 2021-11-11 00:18:33.979307: step 233400, loss = 0.066062, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-11 00:18:54.903556: step 233500, loss = 0.039384, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 00:19:14.980380: step 233600, loss = 0.030392, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-11 00:19:35.081508: step 233700, loss = 0.072859, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 00:19:55.173721: step 233800, loss = 0.050157, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 00:20:15.284384: step 233900, loss = 0.026292, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 00:20:36.257244: step 234000, loss = 0.056496, learning_rate = 0.000000 (2582.7 examples/sec)
=> Model saved to file: ./logs_res/model-234000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:21:08.546833: step 234100, loss = 0.035149, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 00:21:28.571680: step 234200, loss = 0.044851, learning_rate = 0.000000 (2578.3 examples/sec)
=> 2021-11-11 00:21:48.631413: step 234300, loss = 0.076281, learning_rate = 0.000000 (2573.8 examples/sec)
=> 2021-11-11 00:22:09.733882: step 234400, loss = 0.044400, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-11 00:22:29.813673: step 234500, loss = 0.044360, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 00:22:49.913531: step 234600, loss = 0.044565, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 00:23:10.004638: step 234700, loss = 0.028154, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 00:23:31.102551: step 234800, loss = 0.029670, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-11 00:23:51.195692: step 234900, loss = 0.018417, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 00:24:11.296947: step 235000, loss = 0.053833, learning_rate = 0.000000 (2568.4 examples/sec)
=> Model saved to file: ./logs_res/model-235000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950413, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:24:43.367716: step 235100, loss = 0.039910, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 00:25:04.420830: step 235200, loss = 0.031131, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-11 00:25:24.475132: step 235300, loss = 0.032248, learning_rate = 0.000000 (2574.5 examples/sec)
=> 2021-11-11 00:25:44.566500: step 235400, loss = 0.023056, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 00:26:04.661264: step 235500, loss = 0.020800, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 00:26:25.677678: step 235600, loss = 0.017696, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 00:26:45.763388: step 235700, loss = 0.035247, learning_rate = 0.000000 (2570.5 examples/sec)
=> 2021-11-11 00:27:05.835740: step 235800, loss = 0.047711, learning_rate = 0.000000 (2572.1 examples/sec)
=> 2021-11-11 00:27:25.913801: step 235900, loss = 0.026060, learning_rate = 0.000000 (2571.3 examples/sec)
=> 2021-11-11 00:27:46.850474: step 236000, loss = 0.028456, learning_rate = 0.000000 (2585.2 examples/sec)
=> Model saved to file: ./logs_res/model-236000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:28:18.801103: step 236100, loss = 0.063835, learning_rate = 0.000000 (2580.0 examples/sec)
=> 2021-11-11 00:28:38.843327: step 236200, loss = 0.038857, learning_rate = 0.000000 (2576.0 examples/sec)
=> 2021-11-11 00:28:58.894241: step 236300, loss = 0.050887, learning_rate = 0.000000 (2574.9 examples/sec)
=> 2021-11-11 00:29:19.807420: step 236400, loss = 0.066834, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-11 00:29:39.891893: step 236500, loss = 0.052736, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 00:30:00.040891: step 236600, loss = 0.028894, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 00:30:20.110219: step 236700, loss = 0.029014, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-11 00:30:40.196677: step 236800, loss = 0.035648, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-11 00:31:01.132086: step 236900, loss = 0.024371, learning_rate = 0.000000 (2596.2 examples/sec)
=> 2021-11-11 00:31:21.243647: step 237000, loss = 0.032670, learning_rate = 0.000000 (2567.5 examples/sec)
=> Model saved to file: ./logs_res/model-237000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:31:53.403028: step 237100, loss = 0.043735, learning_rate = 0.000000 (2577.1 examples/sec)
=> 2021-11-11 00:32:13.465925: step 237200, loss = 0.038867, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 00:32:34.388768: step 237300, loss = 0.032031, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 00:32:54.468782: step 237400, loss = 0.043726, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-11 00:33:14.551126: step 237500, loss = 0.025353, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-11 00:33:34.652305: step 237600, loss = 0.055945, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 00:33:55.576448: step 237700, loss = 0.055122, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-11 00:34:15.664732: step 237800, loss = 0.026846, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 00:34:35.757173: step 237900, loss = 0.014676, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 00:34:55.848966: step 238000, loss = 0.024908, learning_rate = 0.000000 (2569.6 examples/sec)
=> Model saved to file: ./logs_res/model-238000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:35:28.661642: step 238100, loss = 0.018961, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-11 00:35:48.755133: step 238200, loss = 0.038769, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 00:36:08.847685: step 238300, loss = 0.036226, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 00:36:28.942278: step 238400, loss = 0.027429, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 00:36:49.881817: step 238500, loss = 0.032675, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-11 00:37:09.947678: step 238600, loss = 0.036383, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 00:37:30.004890: step 238700, loss = 0.047952, learning_rate = 0.000000 (2574.3 examples/sec)
=> 2021-11-11 00:37:50.108834: step 238800, loss = 0.066671, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 00:38:11.019967: step 238900, loss = 0.034467, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-11 00:38:31.091627: step 239000, loss = 0.032620, learning_rate = 0.000000 (2572.5 examples/sec)
=> Model saved to file: ./logs_res/model-239000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:39:02.872210: step 239100, loss = 0.035439, learning_rate = 0.000000 (2575.1 examples/sec)
=> 2021-11-11 00:39:22.967724: step 239200, loss = 0.030864, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 00:39:43.915383: step 239300, loss = 0.017335, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 00:40:04.031618: step 239400, loss = 0.049948, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 00:40:24.169059: step 239500, loss = 0.038071, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 00:40:44.302969: step 239600, loss = 0.028396, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 00:41:04.457065: step 239700, loss = 0.041828, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 00:41:25.438301: step 239800, loss = 0.018369, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 00:41:45.644406: step 239900, loss = 0.028590, learning_rate = 0.000000 (2555.2 examples/sec)
=> 2021-11-11 00:42:05.816611: step 240000, loss = 0.033429, learning_rate = 0.000000 (2559.6 examples/sec)
=> Model saved to file: ./logs_res/model-240000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:42:37.964994: step 240100, loss = 0.029117, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 00:42:58.961506: step 240200, loss = 0.038671, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-11 00:43:19.133697: step 240300, loss = 0.037579, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 00:43:39.292286: step 240400, loss = 0.029057, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 00:43:59.506786: step 240500, loss = 0.022789, learning_rate = 0.000000 (2554.3 examples/sec)
=> 2021-11-11 00:44:20.490890: step 240600, loss = 0.047576, learning_rate = 0.000000 (2577.4 examples/sec)
=> 2021-11-11 00:44:40.653017: step 240700, loss = 0.060416, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 00:45:00.816672: step 240800, loss = 0.031958, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 00:45:20.987589: step 240900, loss = 0.024824, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 00:45:42.139825: step 241000, loss = 0.017560, learning_rate = 0.000000 (2577.2 examples/sec)
=> Model saved to file: ./logs_res/model-241000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:46:14.200921: step 241100, loss = 0.051565, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 00:46:34.321185: step 241200, loss = 0.041817, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 00:46:54.472634: step 241300, loss = 0.029221, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 00:47:15.499410: step 241400, loss = 0.037956, learning_rate = 0.000000 (2574.2 examples/sec)
=> 2021-11-11 00:47:35.659632: step 241500, loss = 0.034595, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 00:47:55.798987: step 241600, loss = 0.053094, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 00:48:15.939882: step 241700, loss = 0.018022, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 00:48:36.901944: step 241800, loss = 0.036305, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 00:48:57.061411: step 241900, loss = 0.025721, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 00:49:17.240014: step 242000, loss = 0.060154, learning_rate = 0.000000 (2558.9 examples/sec)
=> Model saved to file: ./logs_res/model-242000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:49:49.579937: step 242100, loss = 0.027221, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 00:50:10.508773: step 242200, loss = 0.032489, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 00:50:30.633946: step 242300, loss = 0.023878, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 00:50:50.776389: step 242400, loss = 0.039649, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 00:51:10.923313: step 242500, loss = 0.037622, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 00:51:31.075492: step 242600, loss = 0.022350, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 00:51:52.084869: step 242700, loss = 0.046084, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-11 00:52:12.229845: step 242800, loss = 0.055230, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 00:52:32.414702: step 242900, loss = 0.024299, learning_rate = 0.000000 (2557.8 examples/sec)
=> 2021-11-11 00:52:52.555296: step 243000, loss = 0.043589, learning_rate = 0.000000 (2563.6 examples/sec)
=> Model saved to file: ./logs_res/model-243000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:53:25.443038: step 243100, loss = 0.036712, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-11 00:53:45.566456: step 243200, loss = 0.080681, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 00:54:05.717694: step 243300, loss = 0.034857, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 00:54:25.836931: step 243400, loss = 0.042560, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 00:54:46.834962: step 243500, loss = 0.035193, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-11 00:55:06.984374: step 243600, loss = 0.026721, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 00:55:27.127689: step 243700, loss = 0.024774, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 00:55:47.280943: step 243800, loss = 0.025581, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 00:56:08.447696: step 243900, loss = 0.031588, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-11 00:56:28.619493: step 244000, loss = 0.016281, learning_rate = 0.000000 (2559.6 examples/sec)
=> Model saved to file: ./logs_res/model-244000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 00:57:00.872268: step 244100, loss = 0.032013, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 00:57:20.980907: step 244200, loss = 0.036340, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 00:57:41.984308: step 244300, loss = 0.027867, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-11 00:58:02.143495: step 244400, loss = 0.041481, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 00:58:22.292315: step 244500, loss = 0.042909, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 00:58:42.428706: step 244600, loss = 0.024463, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 00:59:03.462643: step 244700, loss = 0.025908, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-11 00:59:23.599242: step 244800, loss = 0.066485, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 00:59:43.744603: step 244900, loss = 0.077975, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 01:00:03.890221: step 245000, loss = 0.034546, learning_rate = 0.000000 (2562.7 examples/sec)
=> Model saved to file: ./logs_res/model-245000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:00:36.851137: step 245100, loss = 0.019767, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-11 01:00:57.000183: step 245200, loss = 0.061301, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 01:01:17.140353: step 245300, loss = 0.047561, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 01:01:37.313786: step 245400, loss = 0.041922, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 01:01:57.481228: step 245500, loss = 0.029068, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 01:02:18.612131: step 245600, loss = 0.082765, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 01:02:38.795558: step 245700, loss = 0.023545, learning_rate = 0.000000 (2558.2 examples/sec)
=> 2021-11-11 01:02:58.983725: step 245800, loss = 0.041881, learning_rate = 0.000000 (2557.1 examples/sec)
=> 2021-11-11 01:03:19.162380: step 245900, loss = 0.030860, learning_rate = 0.000000 (2558.8 examples/sec)
=> 2021-11-11 01:03:40.189303: step 246000, loss = 0.061084, learning_rate = 0.000000 (2577.2 examples/sec)
=> Model saved to file: ./logs_res/model-246000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:04:12.782869: step 246100, loss = 0.041514, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 01:04:32.878126: step 246200, loss = 0.028592, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 01:04:53.014488: step 246300, loss = 0.022577, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 01:05:14.136716: step 246400, loss = 0.031769, learning_rate = 0.000000 (2573.8 examples/sec)
=> 2021-11-11 01:05:34.270461: step 246500, loss = 0.022750, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 01:05:54.396633: step 246600, loss = 0.051625, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 01:06:14.517286: step 246700, loss = 0.040000, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 01:06:35.472369: step 246800, loss = 0.021118, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 01:06:55.618676: step 246900, loss = 0.031365, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 01:07:15.769861: step 247000, loss = 0.016687, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-247000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949724, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:07:47.699508: step 247100, loss = 0.028913, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 01:08:08.733108: step 247200, loss = 0.049894, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-11 01:08:28.874819: step 247300, loss = 0.022452, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 01:08:48.997787: step 247400, loss = 0.063693, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 01:09:09.146685: step 247500, loss = 0.044584, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 01:09:30.165014: step 247600, loss = 0.029599, learning_rate = 0.000000 (2573.8 examples/sec)
=> 2021-11-11 01:09:50.323278: step 247700, loss = 0.025056, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 01:10:10.463913: step 247800, loss = 0.034619, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 01:10:30.680800: step 247900, loss = 0.021726, learning_rate = 0.000000 (2553.8 examples/sec)
=> 2021-11-11 01:10:51.665392: step 248000, loss = 0.035747, learning_rate = 0.000000 (2578.2 examples/sec)
=> Model saved to file: ./logs_res/model-248000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:11:24.022956: step 248100, loss = 0.031305, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 01:11:44.130604: step 248200, loss = 0.036595, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 01:12:04.246458: step 248300, loss = 0.019296, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 01:12:24.390704: step 248400, loss = 0.041850, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 01:12:45.532870: step 248500, loss = 0.011113, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 01:13:05.665558: step 248600, loss = 0.048109, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 01:13:25.801474: step 248700, loss = 0.039196, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 01:13:45.930111: step 248800, loss = 0.014665, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 01:14:06.939029: step 248900, loss = 0.032175, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 01:14:27.088428: step 249000, loss = 0.061174, learning_rate = 0.000000 (2562.5 examples/sec)
=> Model saved to file: ./logs_res/model-249000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:14:59.399684: step 249100, loss = 0.038045, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 01:15:19.517157: step 249200, loss = 0.030641, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 01:15:40.510785: step 249300, loss = 0.040958, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 01:16:00.647212: step 249400, loss = 0.023523, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 01:16:20.770933: step 249500, loss = 0.030501, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 01:16:40.893153: step 249600, loss = 0.068542, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 01:17:01.907626: step 249700, loss = 0.036232, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 01:17:22.051412: step 249800, loss = 0.057022, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 01:17:42.203633: step 249900, loss = 0.022327, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 01:18:02.380862: step 250000, loss = 0.026010, learning_rate = 0.000000 (2559.3 examples/sec)
=> Model saved to file: ./logs_res/model-250000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:18:35.134521: step 250100, loss = 0.073812, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 01:18:55.263559: step 250200, loss = 0.037086, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 01:19:15.426120: step 250300, loss = 0.028479, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 01:19:35.596342: step 250400, loss = 0.040697, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 01:19:56.676908: step 250500, loss = 0.047127, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 01:20:16.829101: step 250600, loss = 0.039200, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 01:20:36.969805: step 250700, loss = 0.065961, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 01:20:57.116563: step 250800, loss = 0.043808, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 01:21:18.121549: step 250900, loss = 0.043483, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 01:21:38.263281: step 251000, loss = 0.029841, learning_rate = 0.000000 (2563.4 examples/sec)
=> Model saved to file: ./logs_res/model-251000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:22:10.653834: step 251100, loss = 0.026887, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 01:22:30.795076: step 251200, loss = 0.039512, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 01:22:51.802512: step 251300, loss = 0.032703, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 01:23:11.947130: step 251400, loss = 0.040877, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 01:23:32.089471: step 251500, loss = 0.030018, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 01:23:52.232608: step 251600, loss = 0.045729, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 01:24:12.403617: step 251700, loss = 0.028869, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 01:24:33.552112: step 251800, loss = 0.035531, learning_rate = 0.000000 (2574.3 examples/sec)
=> 2021-11-11 01:24:53.732230: step 251900, loss = 0.045086, learning_rate = 0.000000 (2558.5 examples/sec)
=> 2021-11-11 01:25:13.920502: step 252000, loss = 0.040308, learning_rate = 0.000000 (2557.4 examples/sec)
=> Model saved to file: ./logs_res/model-252000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:25:45.838567: step 252100, loss = 0.030375, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 01:26:06.826981: step 252200, loss = 0.040567, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 01:26:26.961547: step 252300, loss = 0.069184, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 01:26:47.088573: step 252400, loss = 0.018460, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 01:27:07.246196: step 252500, loss = 0.022537, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 01:27:28.339544: step 252600, loss = 0.029985, learning_rate = 0.000000 (2578.9 examples/sec)
=> 2021-11-11 01:27:48.464869: step 252700, loss = 0.019602, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 01:28:08.633591: step 252800, loss = 0.029459, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 01:28:28.810430: step 252900, loss = 0.024264, learning_rate = 0.000000 (2558.9 examples/sec)
=> 2021-11-11 01:28:49.831792: step 253000, loss = 0.032970, learning_rate = 0.000000 (2576.3 examples/sec)
=> Model saved to file: ./logs_res/model-253000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955158
=> patience = 99
=> 2021-11-11 01:29:22.133837: step 253100, loss = 0.028429, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 01:29:42.291569: step 253200, loss = 0.036830, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 01:30:02.446729: step 253300, loss = 0.074749, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 01:30:23.479303: step 253400, loss = 0.041562, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-11 01:30:43.617314: step 253500, loss = 0.065954, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 01:31:03.776372: step 253600, loss = 0.034946, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 01:31:23.934746: step 253700, loss = 0.084569, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 01:31:44.929907: step 253800, loss = 0.050207, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 01:32:05.067519: step 253900, loss = 0.030285, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 01:32:25.215699: step 254000, loss = 0.031060, learning_rate = 0.000000 (2564.0 examples/sec)
=> Model saved to file: ./logs_res/model-254000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955464, best accuracy 0.955158
=> Model saved to file: ./logs_res/model-254000.pdparams
=> patience = 100
=> 2021-11-11 01:32:57.702079: step 254100, loss = 0.021213, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 01:33:18.640749: step 254200, loss = 0.030038, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 01:33:38.760386: step 254300, loss = 0.024302, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 01:33:59.090096: step 254400, loss = 0.055049, learning_rate = 0.000000 (2539.8 examples/sec)
=> 2021-11-11 01:34:19.255485: step 254500, loss = 0.038313, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 01:34:39.426271: step 254600, loss = 0.030539, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 01:35:00.380739: step 254700, loss = 0.029368, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 01:35:20.537233: step 254800, loss = 0.028952, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 01:35:40.690970: step 254900, loss = 0.031746, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 01:36:00.858234: step 255000, loss = 0.024507, learning_rate = 0.000000 (2560.1 examples/sec)
=> Model saved to file: ./logs_res/model-255000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:36:33.644802: step 255100, loss = 0.031836, learning_rate = 0.000000 (2587.2 examples/sec)
=> 2021-11-11 01:36:53.753198: step 255200, loss = 0.035478, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 01:37:13.903145: step 255300, loss = 0.066400, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 01:37:34.049640: step 255400, loss = 0.020933, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 01:37:55.025983: step 255500, loss = 0.024964, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 01:38:15.183655: step 255600, loss = 0.017755, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 01:38:35.312994: step 255700, loss = 0.039502, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 01:38:55.453253: step 255800, loss = 0.039923, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 01:39:16.518191: step 255900, loss = 0.019609, learning_rate = 0.000000 (2576.2 examples/sec)
=> 2021-11-11 01:39:36.666624: step 256000, loss = 0.021798, learning_rate = 0.000000 (2562.5 examples/sec)
=> Model saved to file: ./logs_res/model-256000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954163, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:40:08.554522: step 256100, loss = 0.025358, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 01:40:28.683510: step 256200, loss = 0.046429, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 01:40:49.678396: step 256300, loss = 0.038266, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 01:41:09.824092: step 256400, loss = 0.016537, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 01:41:29.978121: step 256500, loss = 0.027214, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 01:41:50.140482: step 256600, loss = 0.052805, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 01:42:11.155430: step 256700, loss = 0.042096, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 01:42:31.304078: step 256800, loss = 0.035813, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 01:42:51.462124: step 256900, loss = 0.039523, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 01:43:11.638676: step 257000, loss = 0.037340, learning_rate = 0.000000 (2559.3 examples/sec)
=> Model saved to file: ./logs_res/model-257000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:43:44.616953: step 257100, loss = 0.023976, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 01:44:04.755383: step 257200, loss = 0.043245, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 01:44:24.885597: step 257300, loss = 0.049203, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 01:44:45.024056: step 257400, loss = 0.029115, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 01:45:05.152775: step 257500, loss = 0.038000, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 01:45:26.126794: step 257600, loss = 0.026317, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 01:45:46.259683: step 257700, loss = 0.022600, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 01:46:06.388370: step 257800, loss = 0.037385, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 01:46:26.539813: step 257900, loss = 0.036776, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 01:46:47.519400: step 258000, loss = 0.031091, learning_rate = 0.000000 (2577.4 examples/sec)
=> Model saved to file: ./logs_res/model-258000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:47:19.536704: step 258100, loss = 0.029726, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-11 01:47:39.650252: step 258200, loss = 0.035504, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 01:47:59.764891: step 258300, loss = 0.059158, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 01:48:20.711609: step 258400, loss = 0.021743, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 01:48:40.835609: step 258500, loss = 0.041464, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 01:49:00.971024: step 258600, loss = 0.027279, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 01:49:21.097073: step 258700, loss = 0.021982, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 01:49:42.076518: step 258800, loss = 0.020906, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 01:50:02.222832: step 258900, loss = 0.031534, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 01:50:22.383066: step 259000, loss = 0.012452, learning_rate = 0.000000 (2560.9 examples/sec)
=> Model saved to file: ./logs_res/model-259000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:50:54.477052: step 259100, loss = 0.039742, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 01:51:15.408369: step 259200, loss = 0.016934, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-11 01:51:35.547228: step 259300, loss = 0.040553, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 01:51:55.679172: step 259400, loss = 0.029552, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 01:52:15.847256: step 259500, loss = 0.017994, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 01:52:36.977205: step 259600, loss = 0.016015, learning_rate = 0.000000 (2578.9 examples/sec)
=> 2021-11-11 01:52:57.127755: step 259700, loss = 0.031864, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 01:53:17.260119: step 259800, loss = 0.018149, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 01:53:37.395255: step 259900, loss = 0.029051, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 01:53:58.450730: step 260000, loss = 0.046181, learning_rate = 0.000000 (2576.2 examples/sec)
=> Model saved to file: ./logs_res/model-260000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:54:30.472730: step 260100, loss = 0.029179, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 01:54:50.591805: step 260200, loss = 0.031880, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 01:55:10.726948: step 260300, loss = 0.030666, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 01:55:30.900125: step 260400, loss = 0.048194, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 01:55:51.986444: step 260500, loss = 0.031056, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-11 01:56:12.249274: step 260600, loss = 0.031535, learning_rate = 0.000000 (2548.1 examples/sec)
=> 2021-11-11 01:56:32.393646: step 260700, loss = 0.040284, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 01:56:52.548359: step 260800, loss = 0.033124, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 01:57:13.678420: step 260900, loss = 0.023078, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 01:57:33.822956: step 261000, loss = 0.049258, learning_rate = 0.000000 (2563.1 examples/sec)
=> Model saved to file: ./logs_res/model-261000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 01:58:05.800823: step 261100, loss = 0.022046, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 01:58:25.924755: step 261200, loss = 0.026578, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 01:58:46.919509: step 261300, loss = 0.023819, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 01:59:07.111688: step 261400, loss = 0.034184, learning_rate = 0.000000 (2556.9 examples/sec)
=> 2021-11-11 01:59:27.265815: step 261500, loss = 0.032106, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 01:59:47.426646: step 261600, loss = 0.041789, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 02:00:08.528678: step 261700, loss = 0.023128, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-11 02:00:28.669622: step 261800, loss = 0.023652, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 02:00:48.812912: step 261900, loss = 0.039352, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 02:01:08.943555: step 262000, loss = 0.026929, learning_rate = 0.000000 (2564.5 examples/sec)
=> Model saved to file: ./logs_res/model-262000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:01:42.120208: step 262100, loss = 0.022094, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 02:02:02.250362: step 262200, loss = 0.032995, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 02:02:22.379212: step 262300, loss = 0.028885, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 02:02:42.545024: step 262400, loss = 0.034483, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 02:03:03.597963: step 262500, loss = 0.036774, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 02:03:23.739148: step 262600, loss = 0.036121, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 02:03:43.895044: step 262700, loss = 0.045979, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 02:04:04.028403: step 262800, loss = 0.065157, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 02:04:25.011847: step 262900, loss = 0.032847, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 02:04:45.136881: step 263000, loss = 0.024106, learning_rate = 0.000000 (2565.7 examples/sec)
=> Model saved to file: ./logs_res/model-263000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:05:17.180513: step 263100, loss = 0.034980, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-11 02:05:37.282379: step 263200, loss = 0.023263, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 02:05:57.407039: step 263300, loss = 0.036629, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 02:06:18.397648: step 263400, loss = 0.026720, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 02:06:38.527161: step 263500, loss = 0.021681, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 02:06:58.679210: step 263600, loss = 0.019327, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 02:07:18.823003: step 263700, loss = 0.044455, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 02:07:39.883586: step 263800, loss = 0.065790, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-11 02:08:00.047536: step 263900, loss = 0.044370, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 02:08:20.201172: step 264000, loss = 0.034649, learning_rate = 0.000000 (2561.8 examples/sec)
=> Model saved to file: ./logs_res/model-264000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:08:52.261374: step 264100, loss = 0.035638, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 02:09:13.332548: step 264200, loss = 0.027515, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 02:09:33.452812: step 264300, loss = 0.012882, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 02:09:53.594448: step 264400, loss = 0.039492, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 02:10:13.743275: step 264500, loss = 0.027191, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 02:10:34.779326: step 264600, loss = 0.078277, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 02:10:54.914631: step 264700, loss = 0.038835, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 02:11:15.075885: step 264800, loss = 0.035675, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 02:11:35.234774: step 264900, loss = 0.026110, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 02:11:56.267623: step 265000, loss = 0.019317, learning_rate = 0.000000 (2573.3 examples/sec)
=> Model saved to file: ./logs_res/model-265000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:12:28.552738: step 265100, loss = 0.028747, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 02:12:48.676098: step 265200, loss = 0.028620, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 02:13:08.788893: step 265300, loss = 0.021582, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 02:13:29.774341: step 265400, loss = 0.045110, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-11 02:13:49.931176: step 265500, loss = 0.022547, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 02:14:10.130618: step 265600, loss = 0.030414, learning_rate = 0.000000 (2556.1 examples/sec)
=> 2021-11-11 02:14:30.289440: step 265700, loss = 0.019212, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 02:14:51.278804: step 265800, loss = 0.026850, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 02:15:11.436668: step 265900, loss = 0.031567, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 02:15:31.601777: step 266000, loss = 0.033960, learning_rate = 0.000000 (2560.4 examples/sec)
=> Model saved to file: ./logs_res/model-266000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:16:03.685367: step 266100, loss = 0.053761, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 02:16:23.830922: step 266200, loss = 0.053022, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 02:16:44.925179: step 266300, loss = 0.026335, learning_rate = 0.000000 (2576.0 examples/sec)
=> 2021-11-11 02:17:05.089973: step 266400, loss = 0.032515, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 02:17:25.249450: step 266500, loss = 0.038789, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 02:17:45.475359: step 266600, loss = 0.035559, learning_rate = 0.000000 (2552.7 examples/sec)
=> 2021-11-11 02:18:06.474246: step 266700, loss = 0.047982, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 02:18:26.629787: step 266800, loss = 0.050129, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 02:18:46.774146: step 266900, loss = 0.039402, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 02:19:06.973630: step 267000, loss = 0.050796, learning_rate = 0.000000 (2556.2 examples/sec)
=> Model saved to file: ./logs_res/model-267000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:19:39.898180: step 267100, loss = 0.035627, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-11 02:19:59.990004: step 267200, loss = 0.046900, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 02:20:20.111908: step 267300, loss = 0.023952, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 02:20:40.244547: step 267400, loss = 0.030157, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 02:21:01.209142: step 267500, loss = 0.037332, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 02:21:21.352506: step 267600, loss = 0.023439, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 02:21:41.512307: step 267700, loss = 0.026114, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 02:22:01.669328: step 267800, loss = 0.059311, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 02:22:22.656110: step 267900, loss = 0.043588, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 02:22:42.812636: step 268000, loss = 0.028346, learning_rate = 0.000000 (2561.6 examples/sec)
=> Model saved to file: ./logs_res/model-268000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:23:14.819897: step 268100, loss = 0.035441, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 02:23:34.944309: step 268200, loss = 0.024469, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 02:23:56.072086: step 268300, loss = 0.024105, learning_rate = 0.000000 (2592.5 examples/sec)
=> 2021-11-11 02:24:16.202309: step 268400, loss = 0.042622, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 02:24:36.332981: step 268500, loss = 0.020859, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 02:24:56.476216: step 268600, loss = 0.045704, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 02:25:17.455454: step 268700, loss = 0.021404, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 02:25:37.590571: step 268800, loss = 0.037606, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 02:25:57.722219: step 268900, loss = 0.049660, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 02:26:17.863603: step 269000, loss = 0.020767, learning_rate = 0.000000 (2563.3 examples/sec)
=> Model saved to file: ./logs_res/model-269000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:26:49.700207: step 269100, loss = 0.039550, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 02:27:10.763891: step 269200, loss = 0.036442, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 02:27:30.903841: step 269300, loss = 0.041626, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 02:27:51.036169: step 269400, loss = 0.041299, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 02:28:11.200933: step 269500, loss = 0.021104, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 02:28:32.279179: step 269600, loss = 0.024653, learning_rate = 0.000000 (2578.3 examples/sec)
=> 2021-11-11 02:28:52.431373: step 269700, loss = 0.051071, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 02:29:12.577254: step 269800, loss = 0.018568, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 02:29:32.742245: step 269900, loss = 0.057422, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 02:29:53.740966: step 270000, loss = 0.024283, learning_rate = 0.000000 (2578.7 examples/sec)
=> Model saved to file: ./logs_res/model-270000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:30:25.759589: step 270100, loss = 0.024472, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 02:30:45.853327: step 270200, loss = 0.024608, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 02:31:05.979640: step 270300, loss = 0.047129, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 02:31:26.978204: step 270400, loss = 0.028426, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 02:31:47.123401: step 270500, loss = 0.064762, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 02:32:07.247995: step 270600, loss = 0.036217, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 02:32:27.392836: step 270700, loss = 0.054807, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 02:32:48.364671: step 270800, loss = 0.019834, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 02:33:08.507565: step 270900, loss = 0.011898, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 02:33:28.652724: step 271000, loss = 0.041746, learning_rate = 0.000000 (2562.7 examples/sec)
=> Model saved to file: ./logs_res/model-271000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:34:00.850999: step 271100, loss = 0.014186, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 02:34:21.935583: step 271200, loss = 0.051810, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 02:34:42.056305: step 271300, loss = 0.055919, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 02:35:02.169932: step 271400, loss = 0.027056, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 02:35:22.306897: step 271500, loss = 0.068844, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 02:35:43.461767: step 271600, loss = 0.013601, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 02:36:03.598918: step 271700, loss = 0.030642, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 02:36:23.747592: step 271800, loss = 0.068253, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 02:36:43.916509: step 271900, loss = 0.030933, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 02:37:04.885215: step 272000, loss = 0.051219, learning_rate = 0.000000 (2593.3 examples/sec)
=> Model saved to file: ./logs_res/model-272000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:37:36.963334: step 272100, loss = 0.024714, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 02:37:57.080039: step 272200, loss = 0.019997, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 02:38:17.201389: step 272300, loss = 0.029524, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 02:38:37.341325: step 272400, loss = 0.026254, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 02:38:58.319732: step 272500, loss = 0.044850, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 02:39:18.452378: step 272600, loss = 0.045375, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 02:39:38.591177: step 272700, loss = 0.030079, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 02:39:58.723924: step 272800, loss = 0.090411, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 02:40:19.694975: step 272900, loss = 0.028253, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 02:40:39.843875: step 273000, loss = 0.022282, learning_rate = 0.000000 (2562.2 examples/sec)
=> Model saved to file: ./logs_res/model-273000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:41:11.883109: step 273100, loss = 0.070423, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-11 02:41:32.035180: step 273200, loss = 0.034583, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 02:41:53.118872: step 273300, loss = 0.033063, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 02:42:13.261756: step 273400, loss = 0.032420, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 02:42:33.407299: step 273500, loss = 0.030191, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 02:42:53.564025: step 273600, loss = 0.057545, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 02:43:14.721781: step 273700, loss = 0.016840, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 02:43:34.868329: step 273800, loss = 0.020635, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 02:43:55.046094: step 273900, loss = 0.026686, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 02:44:15.214741: step 274000, loss = 0.045503, learning_rate = 0.000000 (2560.0 examples/sec)
=> Model saved to file: ./logs_res/model-274000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:44:48.290642: step 274100, loss = 0.019061, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 02:45:08.399425: step 274200, loss = 0.046338, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 02:45:28.550179: step 274300, loss = 0.026887, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 02:45:48.707867: step 274400, loss = 0.032950, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 02:46:09.762051: step 274500, loss = 0.038520, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-11 02:46:29.911460: step 274600, loss = 0.037833, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 02:46:50.065853: step 274700, loss = 0.026855, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 02:47:10.241650: step 274800, loss = 0.020500, learning_rate = 0.000000 (2558.8 examples/sec)
=> 2021-11-11 02:47:31.284771: step 274900, loss = 0.027825, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 02:47:51.485414: step 275000, loss = 0.027290, learning_rate = 0.000000 (2555.6 examples/sec)
=> Model saved to file: ./logs_res/model-275000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:48:23.448351: step 275100, loss = 0.022561, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 02:48:43.560459: step 275200, loss = 0.025168, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 02:49:03.698196: step 275300, loss = 0.026996, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 02:49:24.739068: step 275400, loss = 0.050147, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 02:49:44.890277: step 275500, loss = 0.040802, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 02:50:05.027908: step 275600, loss = 0.027056, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 02:50:25.166068: step 275700, loss = 0.045714, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 02:50:46.221450: step 275800, loss = 0.031593, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 02:51:06.364879: step 275900, loss = 0.017906, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 02:51:26.495281: step 276000, loss = 0.028092, learning_rate = 0.000000 (2564.8 examples/sec)
=> Model saved to file: ./logs_res/model-276000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:51:58.425475: step 276100, loss = 0.039109, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 02:52:19.405760: step 276200, loss = 0.025903, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 02:52:39.508678: step 276300, loss = 0.035185, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 02:52:59.646364: step 276400, loss = 0.032861, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 02:53:19.769141: step 276500, loss = 0.033250, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 02:53:40.921013: step 276600, loss = 0.031313, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-11 02:54:01.062199: step 276700, loss = 0.021782, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 02:54:21.212824: step 276800, loss = 0.047963, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 02:54:41.341120: step 276900, loss = 0.032495, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 02:55:02.349764: step 277000, loss = 0.028761, learning_rate = 0.000000 (2575.2 examples/sec)
=> Model saved to file: ./logs_res/model-277000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:55:34.412846: step 277100, loss = 0.024566, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 02:55:54.548886: step 277200, loss = 0.035663, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 02:56:14.669816: step 277300, loss = 0.027860, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 02:56:35.656582: step 277400, loss = 0.046776, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 02:56:55.778899: step 277500, loss = 0.023809, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 02:57:15.917653: step 277600, loss = 0.041186, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 02:57:36.048973: step 277700, loss = 0.069528, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 02:57:57.053019: step 277800, loss = 0.035812, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 02:58:17.184174: step 277900, loss = 0.018886, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 02:58:37.314999: step 278000, loss = 0.038451, learning_rate = 0.000000 (2564.5 examples/sec)
=> Model saved to file: ./logs_res/model-278000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 02:59:09.360456: step 278100, loss = 0.022806, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 02:59:29.479487: step 278200, loss = 0.025754, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 02:59:50.477300: step 278300, loss = 0.027026, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 03:00:10.594008: step 278400, loss = 0.019496, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 03:00:30.723272: step 278500, loss = 0.026536, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 03:00:50.861271: step 278600, loss = 0.015952, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 03:01:11.865148: step 278700, loss = 0.037383, learning_rate = 0.000000 (2574.6 examples/sec)
=> 2021-11-11 03:01:32.043298: step 278800, loss = 0.022546, learning_rate = 0.000000 (2558.8 examples/sec)
=> 2021-11-11 03:01:52.210899: step 278900, loss = 0.018827, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 03:02:12.381727: step 279000, loss = 0.033837, learning_rate = 0.000000 (2560.4 examples/sec)
=> Model saved to file: ./logs_res/model-279000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:02:45.205186: step 279100, loss = 0.064666, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 03:03:05.323691: step 279200, loss = 0.050582, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 03:03:25.448350: step 279300, loss = 0.038872, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 03:03:45.571851: step 279400, loss = 0.042978, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 03:04:06.566774: step 279500, loss = 0.042980, learning_rate = 0.000000 (2595.4 examples/sec)
=> 2021-11-11 03:04:26.707216: step 279600, loss = 0.034214, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 03:04:46.849335: step 279700, loss = 0.025965, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 03:05:07.029190: step 279800, loss = 0.046030, learning_rate = 0.000000 (2558.5 examples/sec)
=> 2021-11-11 03:05:27.988094: step 279900, loss = 0.055824, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 03:05:48.142600: step 280000, loss = 0.018600, learning_rate = 0.000000 (2561.8 examples/sec)
=> Model saved to file: ./logs_res/model-280000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:06:20.297803: step 280100, loss = 0.076566, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 03:06:40.432466: step 280200, loss = 0.031148, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 03:07:01.391948: step 280300, loss = 0.011382, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 03:07:21.532638: step 280400, loss = 0.054326, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 03:07:41.692713: step 280500, loss = 0.033779, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 03:08:01.848702: step 280600, loss = 0.041513, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 03:08:22.851457: step 280700, loss = 0.019880, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 03:08:43.031411: step 280800, loss = 0.011824, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 03:09:03.189681: step 280900, loss = 0.021099, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 03:09:23.367849: step 281000, loss = 0.058404, learning_rate = 0.000000 (2559.0 examples/sec)
=> Model saved to file: ./logs_res/model-281000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:09:55.510774: step 281100, loss = 0.029552, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 03:10:16.449739: step 281200, loss = 0.036018, learning_rate = 0.000000 (2583.4 examples/sec)
=> 2021-11-11 03:10:36.599490: step 281300, loss = 0.025525, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 03:10:56.736805: step 281400, loss = 0.036097, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 03:11:16.915896: step 281500, loss = 0.022605, learning_rate = 0.000000 (2558.8 examples/sec)
=> 2021-11-11 03:11:37.913799: step 281600, loss = 0.034786, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 03:11:58.084869: step 281700, loss = 0.013385, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 03:12:18.269168: step 281800, loss = 0.013764, learning_rate = 0.000000 (2558.0 examples/sec)
=> 2021-11-11 03:12:38.430657: step 281900, loss = 0.022837, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 03:12:59.449972: step 282000, loss = 0.028776, learning_rate = 0.000000 (2574.8 examples/sec)
=> Model saved to file: ./logs_res/model-282000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:13:31.491756: step 282100, loss = 0.042636, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 03:13:51.588857: step 282200, loss = 0.032049, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 03:14:11.711782: step 282300, loss = 0.021151, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 03:14:32.804598: step 282400, loss = 0.041998, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 03:14:52.942385: step 282500, loss = 0.032853, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 03:15:13.085306: step 282600, loss = 0.099891, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 03:15:33.262592: step 282700, loss = 0.041565, learning_rate = 0.000000 (2558.9 examples/sec)
=> 2021-11-11 03:15:54.247795: step 282800, loss = 0.037836, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-11 03:16:14.404032: step 282900, loss = 0.034804, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 03:16:34.559767: step 283000, loss = 0.037612, learning_rate = 0.000000 (2561.6 examples/sec)
=> Model saved to file: ./logs_res/model-283000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:17:06.788786: step 283100, loss = 0.031938, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 03:17:27.777963: step 283200, loss = 0.019161, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 03:17:47.910961: step 283300, loss = 0.046009, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 03:18:08.029241: step 283400, loss = 0.022791, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 03:18:28.170749: step 283500, loss = 0.024057, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 03:18:49.158440: step 283600, loss = 0.012976, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-11 03:19:09.291326: step 283700, loss = 0.024728, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 03:19:29.455645: step 283800, loss = 0.029442, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 03:19:49.632598: step 283900, loss = 0.011095, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 03:20:09.797629: step 284000, loss = 0.055521, learning_rate = 0.000000 (2561.1 examples/sec)
=> Model saved to file: ./logs_res/model-284000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954622, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:20:42.776001: step 284100, loss = 0.016188, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-11 03:21:02.890770: step 284200, loss = 0.010998, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 03:21:22.991381: step 284300, loss = 0.045421, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 03:21:43.147183: step 284400, loss = 0.046155, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 03:22:04.096621: step 284500, loss = 0.011602, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 03:22:24.239055: step 284600, loss = 0.031273, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 03:22:44.391824: step 284700, loss = 0.025583, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 03:23:04.526603: step 284800, loss = 0.017754, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 03:23:25.560005: step 284900, loss = 0.038505, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 03:23:45.711470: step 285000, loss = 0.033193, learning_rate = 0.000000 (2562.1 examples/sec)
=> Model saved to file: ./logs_res/model-285000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947582, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:24:18.179635: step 285100, loss = 0.037477, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 03:24:38.272778: step 285200, loss = 0.044296, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 03:24:59.206103: step 285300, loss = 0.028556, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 03:25:19.332301: step 285400, loss = 0.057292, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 03:25:39.440873: step 285500, loss = 0.037069, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 03:25:59.569161: step 285600, loss = 0.018257, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 03:26:20.610805: step 285700, loss = 0.019221, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 03:26:40.766022: step 285800, loss = 0.031819, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 03:27:00.947706: step 285900, loss = 0.026764, learning_rate = 0.000000 (2558.3 examples/sec)
=> 2021-11-11 03:27:21.095856: step 286000, loss = 0.046025, learning_rate = 0.000000 (2562.5 examples/sec)
=> Model saved to file: ./logs_res/model-286000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:27:53.793285: step 286100, loss = 0.029289, learning_rate = 0.000000 (2599.1 examples/sec)
=> 2021-11-11 03:28:13.890297: step 286200, loss = 0.028204, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 03:28:33.990446: step 286300, loss = 0.027702, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 03:28:54.101617: step 286400, loss = 0.014558, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 03:29:15.057021: step 286500, loss = 0.025302, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 03:29:35.190437: step 286600, loss = 0.029699, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 03:29:55.342468: step 286700, loss = 0.025131, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 03:30:15.487747: step 286800, loss = 0.031232, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 03:30:35.617858: step 286900, loss = 0.014548, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 03:30:56.625559: step 287000, loss = 0.030016, learning_rate = 0.000000 (2576.8 examples/sec)
=> Model saved to file: ./logs_res/model-287000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:31:28.767147: step 287100, loss = 0.020996, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 03:31:48.895459: step 287200, loss = 0.035574, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 03:32:09.046273: step 287300, loss = 0.032282, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 03:32:30.071731: step 287400, loss = 0.033764, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-11 03:32:50.206526: step 287500, loss = 0.033817, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 03:33:10.340662: step 287600, loss = 0.029039, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 03:33:30.489631: step 287700, loss = 0.040304, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 03:33:51.515208: step 287800, loss = 0.026984, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 03:34:11.648920: step 287900, loss = 0.023731, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 03:34:31.790558: step 288000, loss = 0.042098, learning_rate = 0.000000 (2563.3 examples/sec)
=> Model saved to file: ./logs_res/model-288000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:35:04.062408: step 288100, loss = 0.048096, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 03:35:25.014369: step 288200, loss = 0.027261, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-11 03:35:45.165581: step 288300, loss = 0.010303, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 03:36:05.327721: step 288400, loss = 0.019276, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 03:36:25.472885: step 288500, loss = 0.022455, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 03:36:46.467985: step 288600, loss = 0.030131, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-11 03:37:06.623303: step 288700, loss = 0.021624, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 03:37:26.761034: step 288800, loss = 0.027320, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 03:37:46.919883: step 288900, loss = 0.020586, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 03:38:07.898528: step 289000, loss = 0.058613, learning_rate = 0.000000 (2579.8 examples/sec)
=> Model saved to file: ./logs_res/model-289000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:38:39.864415: step 289100, loss = 0.050755, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 03:38:59.983126: step 289200, loss = 0.028466, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 03:39:20.144794: step 289300, loss = 0.031319, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 03:39:41.163131: step 289400, loss = 0.020459, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 03:40:01.273759: step 289500, loss = 0.024497, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 03:40:21.405032: step 289600, loss = 0.032886, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 03:40:41.545168: step 289700, loss = 0.032373, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 03:41:01.692268: step 289800, loss = 0.038962, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 03:41:22.786436: step 289900, loss = 0.043630, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 03:41:42.935174: step 290000, loss = 0.069376, learning_rate = 0.000000 (2562.4 examples/sec)
=> Model saved to file: ./logs_res/model-290000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:42:15.018323: step 290100, loss = 0.064247, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 03:42:35.136925: step 290200, loss = 0.021207, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 03:42:56.119749: step 290300, loss = 0.012031, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 03:43:16.260752: step 290400, loss = 0.016073, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 03:43:36.414655: step 290500, loss = 0.032782, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 03:43:56.575860: step 290600, loss = 0.033598, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 03:44:17.669562: step 290700, loss = 0.027772, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 03:44:37.822492: step 290800, loss = 0.018922, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 03:44:57.972638: step 290900, loss = 0.014546, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 03:45:18.119372: step 291000, loss = 0.033318, learning_rate = 0.000000 (2562.6 examples/sec)
=> Model saved to file: ./logs_res/model-291000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:45:50.730438: step 291100, loss = 0.009857, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-11 03:46:10.857420: step 291200, loss = 0.024268, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 03:46:31.005495: step 291300, loss = 0.029355, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 03:46:51.119525: step 291400, loss = 0.037244, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 03:47:12.119947: step 291500, loss = 0.030604, learning_rate = 0.000000 (2574.7 examples/sec)
=> 2021-11-11 03:47:32.278154: step 291600, loss = 0.014054, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 03:47:52.435763: step 291700, loss = 0.015182, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 03:48:12.588406: step 291800, loss = 0.023958, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 03:48:33.584047: step 291900, loss = 0.026174, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 03:48:53.703831: step 292000, loss = 0.033672, learning_rate = 0.000000 (2566.0 examples/sec)
=> Model saved to file: ./logs_res/model-292000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:49:25.778542: step 292100, loss = 0.040049, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 03:49:45.876659: step 292200, loss = 0.033481, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 03:50:07.016312: step 292300, loss = 0.033338, learning_rate = 0.000000 (2581.2 examples/sec)
=> 2021-11-11 03:50:27.145309: step 292400, loss = 0.016208, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 03:50:47.276544: step 292500, loss = 0.027719, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 03:51:07.420537: step 292600, loss = 0.017136, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 03:51:28.380772: step 292700, loss = 0.019231, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 03:51:48.548643: step 292800, loss = 0.033524, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 03:52:08.696205: step 292900, loss = 0.038770, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 03:52:28.851743: step 293000, loss = 0.021793, learning_rate = 0.000000 (2561.6 examples/sec)
=> Model saved to file: ./logs_res/model-293000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:53:00.981776: step 293100, loss = 0.016303, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 03:53:21.933286: step 293200, loss = 0.015493, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 03:53:42.059552: step 293300, loss = 0.034796, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 03:54:02.167918: step 293400, loss = 0.036109, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 03:54:22.284477: step 293500, loss = 0.059058, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 03:54:43.240419: step 293600, loss = 0.038680, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 03:55:03.371205: step 293700, loss = 0.064159, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 03:55:23.470759: step 293800, loss = 0.036346, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 03:55:43.604576: step 293900, loss = 0.047291, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 03:56:04.620221: step 294000, loss = 0.024468, learning_rate = 0.000000 (2581.2 examples/sec)
=> Model saved to file: ./logs_res/model-294000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 03:56:36.729953: step 294100, loss = 0.047693, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 03:56:56.849295: step 294200, loss = 0.048432, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 03:57:16.985444: step 294300, loss = 0.030984, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 03:57:38.064879: step 294400, loss = 0.017566, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 03:57:58.204597: step 294500, loss = 0.020597, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 03:58:18.360859: step 294600, loss = 0.026827, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 03:58:38.512492: step 294700, loss = 0.034801, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 03:58:59.794587: step 294800, loss = 0.041702, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 03:59:19.996180: step 294900, loss = 0.041453, learning_rate = 0.000000 (2555.9 examples/sec)
=> 2021-11-11 03:59:40.172647: step 295000, loss = 0.054390, learning_rate = 0.000000 (2558.8 examples/sec)
=> Model saved to file: ./logs_res/model-295000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:00:12.448209: step 295100, loss = 0.049964, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 04:00:33.422063: step 295200, loss = 0.017682, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 04:00:53.547791: step 295300, loss = 0.039907, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 04:01:13.690007: step 295400, loss = 0.048839, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 04:01:33.827283: step 295500, loss = 0.040816, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 04:01:54.843835: step 295600, loss = 0.043822, learning_rate = 0.000000 (2577.8 examples/sec)
=> 2021-11-11 04:02:14.981369: step 295700, loss = 0.032509, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 04:02:35.129007: step 295800, loss = 0.045007, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 04:02:55.293075: step 295900, loss = 0.031865, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 04:03:15.455959: step 296000, loss = 0.030686, learning_rate = 0.000000 (2560.6 examples/sec)
=> Model saved to file: ./logs_res/model-296000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:03:48.219877: step 296100, loss = 0.070045, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 04:04:08.324994: step 296200, loss = 0.018496, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 04:04:28.443746: step 296300, loss = 0.050733, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 04:04:48.582979: step 296400, loss = 0.043768, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 04:05:09.746079: step 296500, loss = 0.079360, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 04:05:29.930916: step 296600, loss = 0.018821, learning_rate = 0.000000 (2558.1 examples/sec)
=> 2021-11-11 04:05:50.094269: step 296700, loss = 0.040404, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 04:06:10.247327: step 296800, loss = 0.050843, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 04:06:31.387040: step 296900, loss = 0.027630, learning_rate = 0.000000 (2575.8 examples/sec)
=> 2021-11-11 04:06:51.551105: step 297000, loss = 0.022740, learning_rate = 0.000000 (2560.5 examples/sec)
=> Model saved to file: ./logs_res/model-297000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:07:23.544108: step 297100, loss = 0.021428, learning_rate = 0.000000 (2570.5 examples/sec)
=> 2021-11-11 04:07:43.649789: step 297200, loss = 0.037931, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 04:08:04.584776: step 297300, loss = 0.022994, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 04:08:24.712870: step 297400, loss = 0.029958, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 04:08:44.839247: step 297500, loss = 0.012761, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 04:09:04.982761: step 297600, loss = 0.035347, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 04:09:25.947926: step 297700, loss = 0.029349, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 04:09:46.108962: step 297800, loss = 0.043839, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 04:10:06.237710: step 297900, loss = 0.047532, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 04:10:26.389423: step 298000, loss = 0.046914, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-298000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:10:59.548157: step 298100, loss = 0.039562, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-11 04:11:19.658621: step 298200, loss = 0.017323, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 04:11:39.754679: step 298300, loss = 0.023752, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 04:11:59.882840: step 298400, loss = 0.020106, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 04:12:20.983918: step 298500, loss = 0.016613, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 04:12:41.133522: step 298600, loss = 0.032134, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 04:13:01.327687: step 298700, loss = 0.039946, learning_rate = 0.000000 (2556.7 examples/sec)
=> 2021-11-11 04:13:21.455453: step 298800, loss = 0.032969, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 04:13:41.591620: step 298900, loss = 0.028395, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 04:14:02.571475: step 299000, loss = 0.052383, learning_rate = 0.000000 (2578.5 examples/sec)
=> Model saved to file: ./logs_res/model-299000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:14:34.508293: step 299100, loss = 0.028429, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 04:14:54.618770: step 299200, loss = 0.033262, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 04:15:14.762443: step 299300, loss = 0.015763, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 04:15:35.810443: step 299400, loss = 0.024483, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-11 04:15:55.938359: step 299500, loss = 0.033254, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 04:16:16.088022: step 299600, loss = 0.016973, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 04:16:36.213803: step 299700, loss = 0.016639, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 04:16:57.194952: step 299800, loss = 0.012198, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 04:17:17.322486: step 299900, loss = 0.041083, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 04:17:37.456757: step 300000, loss = 0.025435, learning_rate = 0.000000 (2564.1 examples/sec)
=> Model saved to file: ./logs_res/model-300000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:18:09.256860: step 300100, loss = 0.024157, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 04:18:30.195345: step 300200, loss = 0.042100, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-11 04:18:50.313415: step 300300, loss = 0.023297, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 04:19:10.429693: step 300400, loss = 0.043500, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 04:19:30.575852: step 300500, loss = 0.027342, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 04:19:51.555694: step 300600, loss = 0.039914, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 04:20:11.697831: step 300700, loss = 0.040617, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 04:20:31.876172: step 300800, loss = 0.020099, learning_rate = 0.000000 (2559.0 examples/sec)
=> 2021-11-11 04:20:52.024879: step 300900, loss = 0.037165, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 04:21:13.026049: step 301000, loss = 0.019090, learning_rate = 0.000000 (2595.0 examples/sec)
=> Model saved to file: ./logs_res/model-301000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:21:45.221033: step 301100, loss = 0.021911, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 04:22:05.333637: step 301200, loss = 0.034497, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 04:22:25.508819: step 301300, loss = 0.018724, learning_rate = 0.000000 (2559.2 examples/sec)
=> 2021-11-11 04:22:46.481892: step 301400, loss = 0.025089, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 04:23:06.627786: step 301500, loss = 0.026934, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 04:23:26.800139: step 301600, loss = 0.027020, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 04:23:46.975600: step 301700, loss = 0.037244, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 04:24:07.137520: step 301800, loss = 0.020489, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 04:24:28.143969: step 301900, loss = 0.042725, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 04:24:48.305474: step 302000, loss = 0.022397, learning_rate = 0.000000 (2560.8 examples/sec)
=> Model saved to file: ./logs_res/model-302000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:25:20.335472: step 302100, loss = 0.020409, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 04:25:40.466212: step 302200, loss = 0.048629, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 04:26:01.434583: step 302300, loss = 0.053237, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 04:26:21.580167: step 302400, loss = 0.057189, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 04:26:41.710917: step 302500, loss = 0.020707, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 04:27:01.841373: step 302600, loss = 0.049712, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 04:27:22.821860: step 302700, loss = 0.031356, learning_rate = 0.000000 (2577.3 examples/sec)
=> 2021-11-11 04:27:42.973084: step 302800, loss = 0.016712, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 04:28:03.187335: step 302900, loss = 0.060682, learning_rate = 0.000000 (2554.1 examples/sec)
=> 2021-11-11 04:28:23.344477: step 303000, loss = 0.035818, learning_rate = 0.000000 (2561.3 examples/sec)
=> Model saved to file: ./logs_res/model-303000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:28:56.341509: step 303100, loss = 0.016768, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 04:29:16.455149: step 303200, loss = 0.024583, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 04:29:36.587770: step 303300, loss = 0.025832, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 04:29:56.722916: step 303400, loss = 0.020755, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 04:30:17.694070: step 303500, loss = 0.021816, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 04:30:37.828092: step 303600, loss = 0.033072, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 04:30:57.967751: step 303700, loss = 0.023124, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 04:31:18.094643: step 303800, loss = 0.062384, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 04:31:39.070177: step 303900, loss = 0.015923, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-11 04:31:59.253204: step 304000, loss = 0.046581, learning_rate = 0.000000 (2558.0 examples/sec)
=> Model saved to file: ./logs_res/model-304000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:32:31.500573: step 304100, loss = 0.011377, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 04:32:51.629035: step 304200, loss = 0.052263, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 04:33:12.608005: step 304300, loss = 0.042138, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 04:33:32.741464: step 304400, loss = 0.031364, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 04:33:52.874990: step 304500, loss = 0.029394, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 04:34:13.013132: step 304600, loss = 0.015489, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 04:34:33.149441: step 304700, loss = 0.027292, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 04:34:54.137571: step 304800, loss = 0.022727, learning_rate = 0.000000 (2575.9 examples/sec)
=> 2021-11-11 04:35:14.285333: step 304900, loss = 0.017971, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 04:35:34.406641: step 305000, loss = 0.021508, learning_rate = 0.000000 (2565.9 examples/sec)
=> Model saved to file: ./logs_res/model-305000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:36:06.457801: step 305100, loss = 0.028276, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 04:36:27.424185: step 305200, loss = 0.048798, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-11 04:36:47.549406: step 305300, loss = 0.022244, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 04:37:07.704353: step 305400, loss = 0.031781, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 04:37:27.874951: step 305500, loss = 0.022602, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 04:37:48.897105: step 305600, loss = 0.040129, learning_rate = 0.000000 (2575.9 examples/sec)
=> 2021-11-11 04:38:09.046593: step 305700, loss = 0.030358, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 04:38:29.214971: step 305800, loss = 0.040750, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 04:38:49.355996: step 305900, loss = 0.022572, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 04:39:10.404519: step 306000, loss = 0.035102, learning_rate = 0.000000 (2572.3 examples/sec)
=> Model saved to file: ./logs_res/model-306000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:39:42.408629: step 306100, loss = 0.027201, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 04:40:02.534240: step 306200, loss = 0.047757, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 04:40:22.684516: step 306300, loss = 0.021010, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 04:40:43.674699: step 306400, loss = 0.032201, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 04:41:03.810997: step 306500, loss = 0.038336, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 04:41:23.953469: step 306600, loss = 0.035941, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 04:41:44.106453: step 306700, loss = 0.017685, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 04:42:05.172279: step 306800, loss = 0.041768, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-11 04:42:25.333572: step 306900, loss = 0.019914, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 04:42:45.483726: step 307000, loss = 0.052993, learning_rate = 0.000000 (2562.3 examples/sec)
=> Model saved to file: ./logs_res/model-307000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:43:17.494196: step 307100, loss = 0.023957, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 04:43:38.462846: step 307200, loss = 0.050439, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 04:43:58.593016: step 307300, loss = 0.029010, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 04:44:18.735070: step 307400, loss = 0.029799, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 04:44:38.869167: step 307500, loss = 0.012113, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 04:44:58.999061: step 307600, loss = 0.033749, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 04:45:19.978510: step 307700, loss = 0.017982, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-11 04:45:40.115357: step 307800, loss = 0.028146, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 04:46:00.253056: step 307900, loss = 0.029847, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 04:46:20.389980: step 308000, loss = 0.038311, learning_rate = 0.000000 (2563.9 examples/sec)
=> Model saved to file: ./logs_res/model-308000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:46:53.113569: step 308100, loss = 0.033971, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 04:47:13.300087: step 308200, loss = 0.033258, learning_rate = 0.000000 (2557.5 examples/sec)
=> 2021-11-11 04:47:33.439136: step 308300, loss = 0.036159, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 04:47:53.560159: step 308400, loss = 0.022905, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 04:48:14.628464: step 308500, loss = 0.024065, learning_rate = 0.000000 (2578.9 examples/sec)
=> 2021-11-11 04:48:34.767671: step 308600, loss = 0.020540, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 04:48:54.914156: step 308700, loss = 0.036160, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 04:49:15.066145: step 308800, loss = 0.056244, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 04:49:36.223272: step 308900, loss = 0.027036, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 04:49:56.372705: step 309000, loss = 0.024824, learning_rate = 0.000000 (2562.2 examples/sec)
=> Model saved to file: ./logs_res/model-309000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:50:28.390181: step 309100, loss = 0.048557, learning_rate = 0.000000 (2570.6 examples/sec)
=> 2021-11-11 04:50:48.514991: step 309200, loss = 0.024859, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 04:51:09.476296: step 309300, loss = 0.033234, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 04:51:29.619795: step 309400, loss = 0.040515, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 04:51:49.761569: step 309500, loss = 0.048098, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 04:52:09.896480: step 309600, loss = 0.014938, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 04:52:30.949537: step 309700, loss = 0.051313, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 04:52:51.105749: step 309800, loss = 0.028822, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 04:53:11.285423: step 309900, loss = 0.038642, learning_rate = 0.000000 (2558.4 examples/sec)
=> 2021-11-11 04:53:31.430751: step 310000, loss = 0.022303, learning_rate = 0.000000 (2563.1 examples/sec)
=> Model saved to file: ./logs_res/model-310000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:54:04.348087: step 310100, loss = 0.032250, learning_rate = 0.000000 (2601.8 examples/sec)
=> 2021-11-11 04:54:24.458586: step 310200, loss = 0.026290, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 04:54:44.604057: step 310300, loss = 0.032383, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 04:55:04.740263: step 310400, loss = 0.027265, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 04:55:24.900529: step 310500, loss = 0.034118, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 04:55:46.025967: step 310600, loss = 0.023102, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 04:56:06.170379: step 310700, loss = 0.015202, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 04:56:26.305131: step 310800, loss = 0.045204, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 04:56:46.515078: step 310900, loss = 0.064341, learning_rate = 0.000000 (2554.7 examples/sec)
=> 2021-11-11 04:57:07.492338: step 311000, loss = 0.039866, learning_rate = 0.000000 (2578.7 examples/sec)
=> Model saved to file: ./logs_res/model-311000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 04:57:39.276155: step 311100, loss = 0.034189, learning_rate = 0.000000 (2571.3 examples/sec)
=> 2021-11-11 04:57:59.394406: step 311200, loss = 0.038867, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 04:58:19.522518: step 311300, loss = 0.049210, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 04:58:40.486200: step 311400, loss = 0.017052, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-11 04:59:00.730382: step 311500, loss = 0.055467, learning_rate = 0.000000 (2550.3 examples/sec)
=> 2021-11-11 04:59:20.900567: step 311600, loss = 0.021684, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 04:59:41.077679: step 311700, loss = 0.045407, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 05:00:02.131816: step 311800, loss = 0.028832, learning_rate = 0.000000 (2576.8 examples/sec)
=> 2021-11-11 05:00:22.281357: step 311900, loss = 0.024248, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 05:00:42.472147: step 312000, loss = 0.023559, learning_rate = 0.000000 (2557.2 examples/sec)
=> Model saved to file: ./logs_res/model-312000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:01:14.456594: step 312100, loss = 0.034722, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 05:01:35.579768: step 312200, loss = 0.012767, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 05:01:55.714061: step 312300, loss = 0.036218, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 05:02:15.867570: step 312400, loss = 0.024589, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 05:02:36.033497: step 312500, loss = 0.017445, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 05:02:57.074065: step 312600, loss = 0.030057, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 05:03:17.262743: step 312700, loss = 0.041236, learning_rate = 0.000000 (2557.2 examples/sec)
=> 2021-11-11 05:03:37.414043: step 312800, loss = 0.019843, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 05:03:57.570432: step 312900, loss = 0.057099, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 05:04:18.584750: step 313000, loss = 0.030421, learning_rate = 0.000000 (2577.3 examples/sec)
=> Model saved to file: ./logs_res/model-313000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:04:50.448046: step 313100, loss = 0.018098, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 05:05:10.588170: step 313200, loss = 0.042870, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 05:05:30.737234: step 313300, loss = 0.016632, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 05:05:51.741614: step 313400, loss = 0.046458, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-11 05:06:11.902816: step 313500, loss = 0.021246, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 05:06:32.081877: step 313600, loss = 0.016913, learning_rate = 0.000000 (2558.6 examples/sec)
=> 2021-11-11 05:06:52.233562: step 313700, loss = 0.033832, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 05:07:12.422054: step 313800, loss = 0.031182, learning_rate = 0.000000 (2556.9 examples/sec)
=> 2021-11-11 05:07:33.462238: step 313900, loss = 0.025129, learning_rate = 0.000000 (2575.7 examples/sec)
=> 2021-11-11 05:07:53.609068: step 314000, loss = 0.030571, learning_rate = 0.000000 (2562.7 examples/sec)
=> Model saved to file: ./logs_res/model-314000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:08:25.775869: step 314100, loss = 0.021691, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 05:08:45.881289: step 314200, loss = 0.023783, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 05:09:06.860107: step 314300, loss = 0.016073, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 05:09:27.003292: step 314400, loss = 0.014541, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 05:09:47.131128: step 314500, loss = 0.017781, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 05:10:07.265112: step 314600, loss = 0.021606, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 05:10:28.219789: step 314700, loss = 0.039468, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 05:10:48.381010: step 314800, loss = 0.039308, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 05:11:08.529005: step 314900, loss = 0.034101, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 05:11:28.689649: step 315000, loss = 0.016418, learning_rate = 0.000000 (2560.8 examples/sec)
=> Model saved to file: ./logs_res/model-315000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:12:01.497059: step 315100, loss = 0.025966, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 05:12:21.765137: step 315200, loss = 0.026419, learning_rate = 0.000000 (2547.2 examples/sec)
=> 2021-11-11 05:12:41.921418: step 315300, loss = 0.022881, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 05:13:02.058727: step 315400, loss = 0.069726, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 05:13:23.227941: step 315500, loss = 0.034432, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 05:13:43.376401: step 315600, loss = 0.020123, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 05:14:03.513031: step 315700, loss = 0.019234, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 05:14:23.648511: step 315800, loss = 0.029743, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 05:14:44.672414: step 315900, loss = 0.049037, learning_rate = 0.000000 (2574.0 examples/sec)
=> 2021-11-11 05:15:04.860776: step 316000, loss = 0.020119, learning_rate = 0.000000 (2557.4 examples/sec)
=> Model saved to file: ./logs_res/model-316000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950566, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:15:37.048699: step 316100, loss = 0.026642, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-11 05:15:57.200821: step 316200, loss = 0.028859, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 05:16:18.233477: step 316300, loss = 0.034662, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 05:16:38.351590: step 316400, loss = 0.040670, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 05:16:58.570557: step 316500, loss = 0.044814, learning_rate = 0.000000 (2553.4 examples/sec)
=> 2021-11-11 05:17:18.701427: step 316600, loss = 0.032863, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 05:17:38.838192: step 316700, loss = 0.029625, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 05:17:59.878662: step 316800, loss = 0.026167, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-11 05:18:20.020315: step 316900, loss = 0.046919, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 05:18:40.162673: step 317000, loss = 0.029448, learning_rate = 0.000000 (2563.1 examples/sec)
=> Model saved to file: ./logs_res/model-317000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:19:12.205249: step 317100, loss = 0.023696, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 05:19:33.195849: step 317200, loss = 0.044747, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-11 05:19:53.324247: step 317300, loss = 0.027524, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 05:20:13.456783: step 317400, loss = 0.040285, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 05:20:33.596210: step 317500, loss = 0.016635, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 05:20:54.633591: step 317600, loss = 0.025760, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 05:21:14.863446: step 317700, loss = 0.030931, learning_rate = 0.000000 (2552.1 examples/sec)
=> 2021-11-11 05:21:35.010319: step 317800, loss = 0.042013, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 05:21:55.159286: step 317900, loss = 0.035588, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 05:22:16.171768: step 318000, loss = 0.058922, learning_rate = 0.000000 (2577.5 examples/sec)
=> Model saved to file: ./logs_res/model-318000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:22:47.957251: step 318100, loss = 0.023976, learning_rate = 0.000000 (2572.3 examples/sec)
=> 2021-11-11 05:23:08.070653: step 318200, loss = 0.028881, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 05:23:28.191098: step 318300, loss = 0.024425, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 05:23:49.173765: step 318400, loss = 0.066102, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 05:24:09.285527: step 318500, loss = 0.013861, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 05:24:29.429707: step 318600, loss = 0.018739, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 05:24:49.582531: step 318700, loss = 0.020342, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 05:25:10.560790: step 318800, loss = 0.046556, learning_rate = 0.000000 (2576.4 examples/sec)
=> 2021-11-11 05:25:30.708632: step 318900, loss = 0.014434, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 05:25:50.840803: step 319000, loss = 0.033433, learning_rate = 0.000000 (2564.5 examples/sec)
=> Model saved to file: ./logs_res/model-319000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:26:22.807896: step 319100, loss = 0.035443, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 05:26:43.764149: step 319200, loss = 0.037420, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-11 05:27:03.901619: step 319300, loss = 0.042955, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 05:27:24.052432: step 319400, loss = 0.022762, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 05:27:44.215443: step 319500, loss = 0.027451, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 05:28:04.358425: step 319600, loss = 0.030237, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 05:28:25.394184: step 319700, loss = 0.026606, learning_rate = 0.000000 (2573.0 examples/sec)
=> 2021-11-11 05:28:45.640319: step 319800, loss = 0.016555, learning_rate = 0.000000 (2550.1 examples/sec)
=> 2021-11-11 05:29:05.798638: step 319900, loss = 0.063288, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 05:29:25.973320: step 320000, loss = 0.020819, learning_rate = 0.000000 (2559.4 examples/sec)
=> Model saved to file: ./logs_res/model-320000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:29:58.714542: step 320100, loss = 0.068058, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 05:30:18.837379: step 320200, loss = 0.032642, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 05:30:39.041411: step 320300, loss = 0.051793, learning_rate = 0.000000 (2555.2 examples/sec)
=> 2021-11-11 05:30:59.172753: step 320400, loss = 0.016342, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 05:31:20.224364: step 320500, loss = 0.070308, learning_rate = 0.000000 (2581.3 examples/sec)
=> 2021-11-11 05:31:40.376652: step 320600, loss = 0.018520, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 05:32:00.533874: step 320700, loss = 0.030912, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 05:32:20.673392: step 320800, loss = 0.035129, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 05:32:41.718262: step 320900, loss = 0.031314, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-11 05:33:01.884005: step 321000, loss = 0.021450, learning_rate = 0.000000 (2560.4 examples/sec)
=> Model saved to file: ./logs_res/model-321000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:33:33.783427: step 321100, loss = 0.031283, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 05:33:53.918888: step 321200, loss = 0.039840, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 05:34:15.181402: step 321300, loss = 0.036870, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 05:34:35.331253: step 321400, loss = 0.018428, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 05:34:55.477785: step 321500, loss = 0.055075, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 05:35:15.629099: step 321600, loss = 0.012890, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 05:35:36.845414: step 321700, loss = 0.017009, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-11 05:35:57.016620: step 321800, loss = 0.030980, learning_rate = 0.000000 (2559.5 examples/sec)
=> 2021-11-11 05:36:17.180923: step 321900, loss = 0.031828, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 05:36:37.334935: step 322000, loss = 0.048830, learning_rate = 0.000000 (2561.7 examples/sec)
=> Model saved to file: ./logs_res/model-322000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:37:10.155810: step 322100, loss = 0.011173, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 05:37:30.277850: step 322200, loss = 0.116127, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 05:37:50.406173: step 322300, loss = 0.016374, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 05:38:10.556619: step 322400, loss = 0.034307, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 05:38:30.706392: step 322500, loss = 0.034186, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 05:38:51.682437: step 322600, loss = 0.019460, learning_rate = 0.000000 (2577.3 examples/sec)
=> 2021-11-11 05:39:11.836894: step 322700, loss = 0.039941, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 05:39:31.985407: step 322800, loss = 0.025069, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 05:39:52.135368: step 322900, loss = 0.023651, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 05:40:13.107326: step 323000, loss = 0.025401, learning_rate = 0.000000 (2578.5 examples/sec)
=> Model saved to file: ./logs_res/model-323000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:40:45.159756: step 323100, loss = 0.028087, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 05:41:05.297147: step 323200, loss = 0.034442, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 05:41:25.466271: step 323300, loss = 0.051875, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 05:41:46.536690: step 323400, loss = 0.032079, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 05:42:06.704310: step 323500, loss = 0.017577, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 05:42:26.822913: step 323600, loss = 0.036507, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 05:42:46.959836: step 323700, loss = 0.022102, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 05:43:07.935140: step 323800, loss = 0.017499, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 05:43:28.085404: step 323900, loss = 0.019934, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 05:43:48.237491: step 324000, loss = 0.051065, learning_rate = 0.000000 (2562.0 examples/sec)
=> Model saved to file: ./logs_res/model-324000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:44:20.285618: step 324100, loss = 0.023682, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 05:44:41.236496: step 324200, loss = 0.018428, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 05:45:01.376146: step 324300, loss = 0.015340, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 05:45:21.513353: step 324400, loss = 0.044072, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 05:45:41.654734: step 324500, loss = 0.023663, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 05:46:02.843439: step 324600, loss = 0.027894, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 05:46:22.981857: step 324700, loss = 0.021659, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 05:46:43.124021: step 324800, loss = 0.028736, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 05:47:03.264836: step 324900, loss = 0.013882, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 05:47:24.410065: step 325000, loss = 0.028353, learning_rate = 0.000000 (2577.8 examples/sec)
=> Model saved to file: ./logs_res/model-325000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:47:56.324011: step 325100, loss = 0.018033, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 05:48:16.433730: step 325200, loss = 0.022710, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 05:48:36.563054: step 325300, loss = 0.034858, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 05:48:56.690508: step 325400, loss = 0.018949, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 05:49:17.674603: step 325500, loss = 0.027378, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-11 05:49:37.809789: step 325600, loss = 0.029195, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 05:49:57.977848: step 325700, loss = 0.038944, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 05:50:18.128765: step 325800, loss = 0.026012, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 05:50:39.260627: step 325900, loss = 0.023021, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 05:50:59.400693: step 326000, loss = 0.038212, learning_rate = 0.000000 (2563.4 examples/sec)
=> Model saved to file: ./logs_res/model-326000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954852, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:51:31.377802: step 326100, loss = 0.026096, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 05:51:51.495495: step 326200, loss = 0.041481, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 05:52:12.644295: step 326300, loss = 0.036115, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 05:52:32.778809: step 326400, loss = 0.031049, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 05:52:52.923087: step 326500, loss = 0.032957, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 05:53:13.059169: step 326600, loss = 0.040162, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 05:53:34.010185: step 326700, loss = 0.029556, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 05:53:54.145833: step 326800, loss = 0.040646, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 05:54:14.292408: step 326900, loss = 0.069710, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 05:54:34.431523: step 327000, loss = 0.017300, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-327000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:55:07.273960: step 327100, loss = 0.046223, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-11 05:55:27.416878: step 327200, loss = 0.017022, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 05:55:47.520723: step 327300, loss = 0.028373, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 05:56:07.673725: step 327400, loss = 0.018233, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 05:56:28.867942: step 327500, loss = 0.019780, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-11 05:56:49.001992: step 327600, loss = 0.027653, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 05:57:09.122565: step 327700, loss = 0.009175, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 05:57:29.232083: step 327800, loss = 0.064078, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 05:57:50.163571: step 327900, loss = 0.013255, learning_rate = 0.000000 (2599.9 examples/sec)
=> 2021-11-11 05:58:10.277639: step 328000, loss = 0.035432, learning_rate = 0.000000 (2566.8 examples/sec)
=> Model saved to file: ./logs_res/model-328000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 05:58:42.236997: step 328100, loss = 0.023085, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 05:59:02.386414: step 328200, loss = 0.037907, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 05:59:22.541030: step 328300, loss = 0.044280, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 05:59:43.564513: step 328400, loss = 0.015077, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 06:00:03.726650: step 328500, loss = 0.020861, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 06:00:23.892031: step 328600, loss = 0.025432, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 06:00:44.044976: step 328700, loss = 0.028410, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 06:01:05.055333: step 328800, loss = 0.050260, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 06:01:25.206200: step 328900, loss = 0.029175, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 06:01:45.340155: step 329000, loss = 0.032699, learning_rate = 0.000000 (2564.2 examples/sec)
=> Model saved to file: ./logs_res/model-329000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:02:17.740889: step 329100, loss = 0.026629, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 06:02:38.823862: step 329200, loss = 0.033883, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 06:02:59.024932: step 329300, loss = 0.030665, learning_rate = 0.000000 (2555.9 examples/sec)
=> 2021-11-11 06:03:19.173818: step 329400, loss = 0.030263, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 06:03:39.331910: step 329500, loss = 0.025665, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 06:04:00.406369: step 329600, loss = 0.019580, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 06:04:20.549064: step 329700, loss = 0.017385, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 06:04:40.702154: step 329800, loss = 0.036616, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 06:05:00.874359: step 329900, loss = 0.030774, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 06:05:21.910101: step 330000, loss = 0.018278, learning_rate = 0.000000 (2577.3 examples/sec)
=> Model saved to file: ./logs_res/model-330000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:05:54.013190: step 330100, loss = 0.024439, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-11 06:06:14.133627: step 330200, loss = 0.044997, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 06:06:34.248812: step 330300, loss = 0.035638, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 06:06:55.274284: step 330400, loss = 0.012440, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 06:07:15.421083: step 330500, loss = 0.010056, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 06:07:35.579300: step 330600, loss = 0.022518, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 06:07:55.741317: step 330700, loss = 0.018812, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 06:08:16.761739: step 330800, loss = 0.029152, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 06:08:36.910059: step 330900, loss = 0.028408, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 06:08:57.045371: step 331000, loss = 0.031129, learning_rate = 0.000000 (2563.9 examples/sec)
=> Model saved to file: ./logs_res/model-331000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:09:28.929685: step 331100, loss = 0.038854, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 06:09:49.036584: step 331200, loss = 0.031530, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 06:10:10.311435: step 331300, loss = 0.029730, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 06:10:30.443873: step 331400, loss = 0.015114, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 06:10:50.566492: step 331500, loss = 0.018476, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 06:11:10.724874: step 331600, loss = 0.045646, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 06:11:31.714466: step 331700, loss = 0.014151, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 06:11:51.840491: step 331800, loss = 0.019650, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 06:12:11.990049: step 331900, loss = 0.057607, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 06:12:32.142576: step 332000, loss = 0.023205, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-332000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:13:04.998636: step 332100, loss = 0.015536, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-11 06:13:25.109942: step 332200, loss = 0.046691, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 06:13:45.258902: step 332300, loss = 0.022211, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 06:14:05.385863: step 332400, loss = 0.039131, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 06:14:26.390303: step 332500, loss = 0.024084, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 06:14:46.558742: step 332600, loss = 0.035163, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 06:15:06.722523: step 332700, loss = 0.062058, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 06:15:26.881144: step 332800, loss = 0.030455, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 06:15:47.864686: step 332900, loss = 0.033345, learning_rate = 0.000000 (2576.8 examples/sec)
=> 2021-11-11 06:16:08.025476: step 333000, loss = 0.027527, learning_rate = 0.000000 (2560.9 examples/sec)
=> Model saved to file: ./logs_res/model-333000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:16:40.096373: step 333100, loss = 0.031270, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 06:17:00.243375: step 333200, loss = 0.018656, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 06:17:21.207571: step 333300, loss = 0.047872, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 06:17:41.348990: step 333400, loss = 0.024077, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 06:18:01.483668: step 333500, loss = 0.015141, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 06:18:21.613594: step 333600, loss = 0.018397, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 06:18:42.583005: step 333700, loss = 0.018304, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 06:19:02.741608: step 333800, loss = 0.038907, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 06:19:22.881858: step 333900, loss = 0.033208, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 06:19:43.018996: step 334000, loss = 0.042644, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-334000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:20:15.952653: step 334100, loss = 0.024471, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-11 06:20:36.056541: step 334200, loss = 0.024543, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 06:20:56.185784: step 334300, loss = 0.022315, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 06:21:16.328648: step 334400, loss = 0.044081, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 06:21:36.481827: step 334500, loss = 0.042838, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 06:21:57.468497: step 334600, loss = 0.019761, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 06:22:17.643113: step 334700, loss = 0.034297, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 06:22:37.800057: step 334800, loss = 0.022450, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 06:22:57.961171: step 334900, loss = 0.022384, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 06:23:18.959385: step 335000, loss = 0.032280, learning_rate = 0.000000 (2575.9 examples/sec)
=> Model saved to file: ./logs_res/model-335000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:23:50.846360: step 335100, loss = 0.025711, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 06:24:10.951221: step 335200, loss = 0.055665, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 06:24:31.187624: step 335300, loss = 0.019985, learning_rate = 0.000000 (2551.3 examples/sec)
=> 2021-11-11 06:24:52.183781: step 335400, loss = 0.035701, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-11 06:25:12.335265: step 335500, loss = 0.026605, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 06:25:32.527145: step 335600, loss = 0.020908, learning_rate = 0.000000 (2557.0 examples/sec)
=> 2021-11-11 06:25:52.656727: step 335700, loss = 0.018930, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 06:26:13.626429: step 335800, loss = 0.023405, learning_rate = 0.000000 (2581.3 examples/sec)
=> 2021-11-11 06:26:33.797105: step 335900, loss = 0.035805, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 06:26:53.971128: step 336000, loss = 0.035915, learning_rate = 0.000000 (2559.5 examples/sec)
=> Model saved to file: ./logs_res/model-336000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:27:26.018670: step 336100, loss = 0.046990, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 06:27:46.976905: step 336200, loss = 0.034525, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 06:28:07.089336: step 336300, loss = 0.036770, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 06:28:27.214188: step 336400, loss = 0.040085, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 06:28:47.328202: step 336500, loss = 0.009923, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 06:29:08.322255: step 336600, loss = 0.014564, learning_rate = 0.000000 (2577.5 examples/sec)
=> 2021-11-11 06:29:28.466162: step 336700, loss = 0.021844, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 06:29:48.621356: step 336800, loss = 0.030531, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 06:30:08.764234: step 336900, loss = 0.055803, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 06:30:29.764769: step 337000, loss = 0.037200, learning_rate = 0.000000 (2577.5 examples/sec)
=> Model saved to file: ./logs_res/model-337000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955311, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:31:01.688974: step 337100, loss = 0.027204, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 06:31:21.827224: step 337200, loss = 0.017870, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 06:31:41.969130: step 337300, loss = 0.025219, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 06:32:02.143910: step 337400, loss = 0.018314, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 06:32:23.158843: step 337500, loss = 0.034309, learning_rate = 0.000000 (2578.3 examples/sec)
=> 2021-11-11 06:32:43.318978: step 337600, loss = 0.016860, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 06:33:03.452512: step 337700, loss = 0.018264, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 06:33:23.597056: step 337800, loss = 0.024787, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 06:33:44.601164: step 337900, loss = 0.042374, learning_rate = 0.000000 (2579.5 examples/sec)
=> 2021-11-11 06:34:04.744554: step 338000, loss = 0.022783, learning_rate = 0.000000 (2563.2 examples/sec)
=> Model saved to file: ./logs_res/model-338000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:34:36.917309: step 338100, loss = 0.023601, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 06:34:57.040511: step 338200, loss = 0.024729, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 06:35:18.027547: step 338300, loss = 0.036807, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-11 06:35:38.157150: step 338400, loss = 0.029693, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 06:35:58.303990: step 338500, loss = 0.048437, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 06:36:18.468966: step 338600, loss = 0.033802, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 06:36:39.658353: step 338700, loss = 0.021891, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 06:36:59.821540: step 338800, loss = 0.015491, learning_rate = 0.000000 (2560.5 examples/sec)
=> 2021-11-11 06:37:20.070824: step 338900, loss = 0.036480, learning_rate = 0.000000 (2549.9 examples/sec)
=> 2021-11-11 06:37:40.212708: step 339000, loss = 0.054280, learning_rate = 0.000000 (2563.5 examples/sec)
=> Model saved to file: ./logs_res/model-339000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948424, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:38:13.342760: step 339100, loss = 0.036926, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 06:38:33.487906: step 339200, loss = 0.032347, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 06:38:53.617540: step 339300, loss = 0.046216, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 06:39:13.748649: step 339400, loss = 0.062495, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 06:39:34.893085: step 339500, loss = 0.021827, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-11 06:39:55.030117: step 339600, loss = 0.015395, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 06:40:15.182305: step 339700, loss = 0.014967, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 06:40:35.340175: step 339800, loss = 0.019416, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 06:40:56.346583: step 339900, loss = 0.031912, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-11 06:41:16.513166: step 340000, loss = 0.026919, learning_rate = 0.000000 (2560.3 examples/sec)
=> Model saved to file: ./logs_res/model-340000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:41:48.792064: step 340100, loss = 0.038750, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 06:42:08.903140: step 340200, loss = 0.020088, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 06:42:29.035537: step 340300, loss = 0.013259, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 06:42:50.160767: step 340400, loss = 0.030874, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-11 06:43:10.316234: step 340500, loss = 0.073585, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 06:43:30.460515: step 340600, loss = 0.040456, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 06:43:50.643191: step 340700, loss = 0.024325, learning_rate = 0.000000 (2558.4 examples/sec)
=> 2021-11-11 06:44:11.642891: step 340800, loss = 0.038035, learning_rate = 0.000000 (2576.8 examples/sec)
=> 2021-11-11 06:44:31.768549: step 340900, loss = 0.031224, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 06:44:51.926740: step 341000, loss = 0.022168, learning_rate = 0.000000 (2561.2 examples/sec)
=> Model saved to file: ./logs_res/model-341000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:45:23.733274: step 341100, loss = 0.028710, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 06:45:44.722145: step 341200, loss = 0.052102, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 06:46:04.858565: step 341300, loss = 0.023582, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 06:46:25.004736: step 341400, loss = 0.032432, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 06:46:45.156779: step 341500, loss = 0.029265, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 06:47:06.160816: step 341600, loss = 0.054180, learning_rate = 0.000000 (2576.7 examples/sec)
=> 2021-11-11 06:47:26.316992: step 341700, loss = 0.027792, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 06:47:46.456549: step 341800, loss = 0.016362, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 06:48:06.599763: step 341900, loss = 0.034238, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 06:48:27.633248: step 342000, loss = 0.029270, learning_rate = 0.000000 (2582.4 examples/sec)
=> Model saved to file: ./logs_res/model-342000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950413, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:48:59.449216: step 342100, loss = 0.024006, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 06:49:19.575073: step 342200, loss = 0.010155, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 06:49:39.710524: step 342300, loss = 0.034529, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 06:50:00.872187: step 342400, loss = 0.012861, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-11 06:50:20.997950: step 342500, loss = 0.021966, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 06:50:41.148267: step 342600, loss = 0.055644, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 06:51:01.285270: step 342700, loss = 0.010717, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 06:51:22.254668: step 342800, loss = 0.016080, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 06:51:42.381755: step 342900, loss = 0.019005, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 06:52:02.534062: step 343000, loss = 0.020463, learning_rate = 0.000000 (2561.8 examples/sec)
=> Model saved to file: ./logs_res/model-343000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:52:34.747506: step 343100, loss = 0.017401, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 06:52:54.842164: step 343200, loss = 0.046374, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 06:53:15.932072: step 343300, loss = 0.037039, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 06:53:36.063529: step 343400, loss = 0.037702, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 06:53:56.205442: step 343500, loss = 0.017011, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 06:54:16.357503: step 343600, loss = 0.040902, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 06:54:37.532450: step 343700, loss = 0.020783, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-11 06:54:57.695909: step 343800, loss = 0.030175, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 06:55:17.843442: step 343900, loss = 0.023188, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 06:55:37.983789: step 344000, loss = 0.031291, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-344000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:56:10.810184: step 344100, loss = 0.043103, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 06:56:30.990004: step 344200, loss = 0.015121, learning_rate = 0.000000 (2558.4 examples/sec)
=> 2021-11-11 06:56:51.073793: step 344300, loss = 0.018392, learning_rate = 0.000000 (2570.6 examples/sec)
=> 2021-11-11 06:57:11.191124: step 344400, loss = 0.019902, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 06:57:32.169922: step 344500, loss = 0.059379, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 06:57:52.302264: step 344600, loss = 0.021804, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 06:58:12.445640: step 344700, loss = 0.030071, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 06:58:32.582850: step 344800, loss = 0.028089, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 06:58:53.638304: step 344900, loss = 0.022774, learning_rate = 0.000000 (2581.3 examples/sec)
=> 2021-11-11 06:59:13.777308: step 345000, loss = 0.015394, learning_rate = 0.000000 (2563.8 examples/sec)
=> Model saved to file: ./logs_res/model-345000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 06:59:45.643885: step 345100, loss = 0.016081, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 07:00:05.816557: step 345200, loss = 0.040246, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 07:00:26.762375: step 345300, loss = 0.040133, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-11 07:00:46.905746: step 345400, loss = 0.031552, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 07:01:07.053555: step 345500, loss = 0.102738, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 07:01:27.199806: step 345600, loss = 0.072648, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 07:01:48.213002: step 345700, loss = 0.017509, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 07:02:08.363938: step 345800, loss = 0.051510, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 07:02:28.509891: step 345900, loss = 0.068505, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 07:02:48.657761: step 346000, loss = 0.033776, learning_rate = 0.000000 (2562.8 examples/sec)
=> Model saved to file: ./logs_res/model-346000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:03:20.880879: step 346100, loss = 0.016116, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 07:03:41.922459: step 346200, loss = 0.042020, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-11 07:04:02.061034: step 346300, loss = 0.043636, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 07:04:22.202237: step 346400, loss = 0.018228, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 07:04:42.319914: step 346500, loss = 0.015939, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 07:05:03.305670: step 346600, loss = 0.030969, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-11 07:05:23.456034: step 346700, loss = 0.019379, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 07:05:43.574502: step 346800, loss = 0.038282, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 07:06:03.691960: step 346900, loss = 0.027615, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 07:06:24.683903: step 347000, loss = 0.018280, learning_rate = 0.000000 (2590.1 examples/sec)
=> Model saved to file: ./logs_res/model-347000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:06:56.646029: step 347100, loss = 0.067067, learning_rate = 0.000000 (2573.9 examples/sec)
=> 2021-11-11 07:07:16.826964: step 347200, loss = 0.029276, learning_rate = 0.000000 (2558.2 examples/sec)
=> 2021-11-11 07:07:36.919221: step 347300, loss = 0.040515, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 07:07:58.079745: step 347400, loss = 0.011420, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 07:08:18.195472: step 347500, loss = 0.036279, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 07:08:38.310512: step 347600, loss = 0.017860, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 07:08:58.419625: step 347700, loss = 0.031164, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 07:09:19.406215: step 347800, loss = 0.042379, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 07:09:39.532356: step 347900, loss = 0.041886, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 07:09:59.658373: step 348000, loss = 0.038743, learning_rate = 0.000000 (2565.3 examples/sec)
=> Model saved to file: ./logs_res/model-348000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:10:31.464142: step 348100, loss = 0.076051, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-11 07:10:52.537471: step 348200, loss = 0.033882, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 07:11:12.645890: step 348300, loss = 0.044029, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 07:11:32.738235: step 348400, loss = 0.027057, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 07:11:52.853724: step 348500, loss = 0.045105, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 07:12:13.819597: step 348600, loss = 0.095706, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 07:12:33.933748: step 348700, loss = 0.047526, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 07:12:54.067955: step 348800, loss = 0.026070, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 07:13:14.232049: step 348900, loss = 0.013438, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 07:13:34.362105: step 349000, loss = 0.028514, learning_rate = 0.000000 (2565.4 examples/sec)
=> Model saved to file: ./logs_res/model-349000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:14:07.326525: step 349100, loss = 0.022117, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-11 07:14:27.449128: step 349200, loss = 0.012114, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 07:14:47.548697: step 349300, loss = 0.062638, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 07:15:07.655704: step 349400, loss = 0.044245, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 07:15:28.622435: step 349500, loss = 0.029585, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 07:15:48.743606: step 349600, loss = 0.027653, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 07:16:08.865160: step 349700, loss = 0.033246, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 07:16:28.995712: step 349800, loss = 0.022483, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 07:16:49.952633: step 349900, loss = 0.026619, learning_rate = 0.000000 (2600.1 examples/sec)
=> 2021-11-11 07:17:10.060189: step 350000, loss = 0.052891, learning_rate = 0.000000 (2567.6 examples/sec)
=> Model saved to file: ./logs_res/model-350000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:17:42.064186: step 350100, loss = 0.037530, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 07:18:02.256396: step 350200, loss = 0.021423, learning_rate = 0.000000 (2556.7 examples/sec)
=> 2021-11-11 07:18:23.203120: step 350300, loss = 0.022368, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 07:18:43.341232: step 350400, loss = 0.023045, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 07:19:03.476038: step 350500, loss = 0.038832, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 07:19:23.613029: step 350600, loss = 0.021750, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 07:19:44.686762: step 350700, loss = 0.042007, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 07:20:04.809190: step 350800, loss = 0.020916, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 07:20:24.919476: step 350900, loss = 0.013702, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 07:20:45.050204: step 351000, loss = 0.023149, learning_rate = 0.000000 (2564.7 examples/sec)
=> Model saved to file: ./logs_res/model-351000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:21:17.960375: step 351100, loss = 0.023756, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 07:21:38.061698: step 351200, loss = 0.033477, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 07:21:58.159398: step 351300, loss = 0.037072, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 07:22:18.293698: step 351400, loss = 0.022447, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 07:22:39.350563: step 351500, loss = 0.033446, learning_rate = 0.000000 (2577.8 examples/sec)
=> 2021-11-11 07:22:59.448367: step 351600, loss = 0.011056, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 07:23:19.572823: step 351700, loss = 0.016823, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 07:23:39.703599: step 351800, loss = 0.062518, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 07:23:59.825037: step 351900, loss = 0.020343, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 07:24:21.048861: step 352000, loss = 0.041610, learning_rate = 0.000000 (2561.0 examples/sec)
=> Model saved to file: ./logs_res/model-352000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:24:53.152039: step 352100, loss = 0.082189, learning_rate = 0.000000 (2573.5 examples/sec)
=> 2021-11-11 07:25:13.254772: step 352200, loss = 0.036240, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 07:25:33.377203: step 352300, loss = 0.041292, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 07:25:54.386517: step 352400, loss = 0.014920, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-11 07:26:14.476866: step 352500, loss = 0.012555, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 07:26:34.598307: step 352600, loss = 0.029397, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 07:26:54.712505: step 352700, loss = 0.013728, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 07:27:15.680056: step 352800, loss = 0.027053, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 07:27:35.929830: step 352900, loss = 0.036867, learning_rate = 0.000000 (2549.5 examples/sec)
=> 2021-11-11 07:27:56.053167: step 353000, loss = 0.023113, learning_rate = 0.000000 (2565.7 examples/sec)
=> Model saved to file: ./logs_res/model-353000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950107, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:28:27.763650: step 353100, loss = 0.026278, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-11 07:28:48.690274: step 353200, loss = 0.027081, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 07:29:08.797107: step 353300, loss = 0.019855, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 07:29:28.907483: step 353400, loss = 0.021949, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 07:29:49.050744: step 353500, loss = 0.026862, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 07:30:10.221640: step 353600, loss = 0.028764, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-11 07:30:30.330982: step 353700, loss = 0.009206, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 07:30:50.486897: step 353800, loss = 0.017138, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 07:31:10.612845: step 353900, loss = 0.015960, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 07:31:31.628575: step 354000, loss = 0.062897, learning_rate = 0.000000 (2586.9 examples/sec)
=> Model saved to file: ./logs_res/model-354000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:32:03.419914: step 354100, loss = 0.028176, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 07:32:23.532076: step 354200, loss = 0.033709, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 07:32:43.660692: step 354300, loss = 0.047764, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 07:33:04.614791: step 354400, loss = 0.020532, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 07:33:24.728232: step 354500, loss = 0.017666, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 07:33:44.832843: step 354600, loss = 0.029637, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 07:34:04.946503: step 354700, loss = 0.022733, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 07:34:25.874349: step 354800, loss = 0.028122, learning_rate = 0.000000 (2585.7 examples/sec)
=> 2021-11-11 07:34:45.991256: step 354900, loss = 0.021035, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 07:35:06.110994: step 355000, loss = 0.015857, learning_rate = 0.000000 (2566.4 examples/sec)
=> Model saved to file: ./logs_res/model-355000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:35:37.901040: step 355100, loss = 0.022606, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 07:35:58.009075: step 355200, loss = 0.020950, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 07:36:18.963635: step 355300, loss = 0.025418, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 07:36:39.068847: step 355400, loss = 0.030660, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 07:36:59.189378: step 355500, loss = 0.034959, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 07:37:19.327666: step 355600, loss = 0.042652, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 07:37:40.283602: step 355700, loss = 0.021832, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-11 07:38:00.417198: step 355800, loss = 0.027937, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 07:38:20.547226: step 355900, loss = 0.043972, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 07:38:40.672083: step 356000, loss = 0.035099, learning_rate = 0.000000 (2565.3 examples/sec)
=> Model saved to file: ./logs_res/model-356000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:39:13.447903: step 356100, loss = 0.027408, learning_rate = 0.000000 (2586.2 examples/sec)
=> 2021-11-11 07:39:33.546026: step 356200, loss = 0.017847, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 07:39:53.647727: step 356300, loss = 0.016105, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 07:40:13.773316: step 356400, loss = 0.050215, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 07:40:34.758453: step 356500, loss = 0.016056, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-11 07:40:54.869765: step 356600, loss = 0.024622, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 07:41:14.989803: step 356700, loss = 0.022324, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 07:41:35.127612: step 356800, loss = 0.040123, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 07:41:56.084040: step 356900, loss = 0.018823, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 07:42:16.202233: step 357000, loss = 0.025864, learning_rate = 0.000000 (2566.4 examples/sec)
=> Model saved to file: ./logs_res/model-357000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:42:48.234244: step 357100, loss = 0.014720, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 07:43:08.332757: step 357200, loss = 0.101391, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 07:43:29.273943: step 357300, loss = 0.018479, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-11 07:43:49.414157: step 357400, loss = 0.019063, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 07:44:09.525407: step 357500, loss = 0.023692, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 07:44:29.670215: step 357600, loss = 0.075309, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 07:44:50.606273: step 357700, loss = 0.037001, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 07:45:10.714106: step 357800, loss = 0.047320, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 07:45:30.827738: step 357900, loss = 0.015432, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 07:45:50.955056: step 358000, loss = 0.032141, learning_rate = 0.000000 (2565.0 examples/sec)
=> Model saved to file: ./logs_res/model-358000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:46:22.907645: step 358100, loss = 0.025400, learning_rate = 0.000000 (2570.5 examples/sec)
=> 2021-11-11 07:46:43.852030: step 358200, loss = 0.040728, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-11 07:47:03.947488: step 358300, loss = 0.034694, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 07:47:24.063247: step 358400, loss = 0.043117, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 07:47:44.187809: step 358500, loss = 0.033236, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 07:48:05.134224: step 358600, loss = 0.067298, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-11 07:48:25.241409: step 358700, loss = 0.018072, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 07:48:45.371916: step 358800, loss = 0.030035, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 07:49:05.490483: step 358900, loss = 0.059994, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 07:49:26.478411: step 359000, loss = 0.023991, learning_rate = 0.000000 (2579.8 examples/sec)
=> Model saved to file: ./logs_res/model-359000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:49:58.376257: step 359100, loss = 0.019169, learning_rate = 0.000000 (2573.5 examples/sec)
=> 2021-11-11 07:50:18.513148: step 359200, loss = 0.007867, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 07:50:38.612738: step 359300, loss = 0.024122, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 07:50:59.557321: step 359400, loss = 0.044654, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 07:51:19.688968: step 359500, loss = 0.015333, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 07:51:39.814509: step 359600, loss = 0.022612, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 07:51:59.926455: step 359700, loss = 0.022574, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 07:52:20.870052: step 359800, loss = 0.023684, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 07:52:41.004969: step 359900, loss = 0.016843, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 07:53:01.146624: step 360000, loss = 0.039479, learning_rate = 0.000000 (2563.3 examples/sec)
=> Model saved to file: ./logs_res/model-360000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:53:33.226029: step 360100, loss = 0.012084, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 07:53:54.159589: step 360200, loss = 0.017634, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 07:54:14.256555: step 360300, loss = 0.017850, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 07:54:34.364151: step 360400, loss = 0.027061, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 07:54:54.489416: step 360500, loss = 0.034773, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 07:55:15.446256: step 360600, loss = 0.042674, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 07:55:35.588971: step 360700, loss = 0.040505, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 07:55:55.721513: step 360800, loss = 0.019825, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 07:56:15.877004: step 360900, loss = 0.018253, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 07:56:36.020067: step 361000, loss = 0.030907, learning_rate = 0.000000 (2563.9 examples/sec)
=> Model saved to file: ./logs_res/model-361000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948730, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 07:57:09.231876: step 361100, loss = 0.028628, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 07:57:29.352817: step 361200, loss = 0.040450, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 07:57:49.481991: step 361300, loss = 0.015757, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 07:58:09.609996: step 361400, loss = 0.026895, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 07:58:30.575881: step 361500, loss = 0.022688, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 07:58:50.828013: step 361600, loss = 0.016189, learning_rate = 0.000000 (2549.2 examples/sec)
=> 2021-11-11 07:59:10.963133: step 361700, loss = 0.037389, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 07:59:31.099511: step 361800, loss = 0.025483, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 07:59:52.264404: step 361900, loss = 0.008714, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 08:00:12.380382: step 362000, loss = 0.013706, learning_rate = 0.000000 (2566.4 examples/sec)
=> Model saved to file: ./logs_res/model-362000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:00:44.312094: step 362100, loss = 0.055149, learning_rate = 0.000000 (2571.3 examples/sec)
=> 2021-11-11 08:01:04.411613: step 362200, loss = 0.035439, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 08:01:25.501089: step 362300, loss = 0.030569, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 08:01:45.608655: step 362400, loss = 0.010154, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 08:02:05.714520: step 362500, loss = 0.021083, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 08:02:25.850767: step 362600, loss = 0.009539, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 08:02:46.837705: step 362700, loss = 0.014893, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 08:03:07.000770: step 362800, loss = 0.020814, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 08:03:27.151409: step 362900, loss = 0.027254, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 08:03:47.288766: step 363000, loss = 0.018699, learning_rate = 0.000000 (2564.0 examples/sec)
=> Model saved to file: ./logs_res/model-363000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:04:20.164309: step 363100, loss = 0.027406, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 08:04:40.268024: step 363200, loss = 0.017336, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 08:05:00.366698: step 363300, loss = 0.031700, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 08:05:20.464595: step 363400, loss = 0.029358, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 08:05:41.445057: step 363500, loss = 0.028244, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-11 08:06:01.559074: step 363600, loss = 0.026511, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 08:06:21.730644: step 363700, loss = 0.028148, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 08:06:41.828418: step 363800, loss = 0.031764, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 08:07:01.943150: step 363900, loss = 0.023375, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 08:07:22.955251: step 364000, loss = 0.038329, learning_rate = 0.000000 (2575.6 examples/sec)
=> Model saved to file: ./logs_res/model-364000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:07:54.904831: step 364100, loss = 0.018964, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 08:08:15.032612: step 364200, loss = 0.047707, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 08:08:35.151780: step 364300, loss = 0.058518, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 08:08:56.122313: step 364400, loss = 0.029994, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 08:09:16.228900: step 364500, loss = 0.013156, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 08:09:36.425133: step 364600, loss = 0.026830, learning_rate = 0.000000 (2556.5 examples/sec)
=> 2021-11-11 08:09:56.546851: step 364700, loss = 0.015653, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 08:10:17.502469: step 364800, loss = 0.039577, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-11 08:10:37.647762: step 364900, loss = 0.022449, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 08:10:57.828330: step 365000, loss = 0.043595, learning_rate = 0.000000 (2558.1 examples/sec)
=> Model saved to file: ./logs_res/model-365000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:11:29.813808: step 365100, loss = 0.017548, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 08:11:50.802347: step 365200, loss = 0.036425, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-11 08:12:10.915819: step 365300, loss = 0.035704, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 08:12:31.049671: step 365400, loss = 0.033304, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 08:12:51.174887: step 365500, loss = 0.011681, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 08:13:12.144937: step 365600, loss = 0.018797, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 08:13:32.271818: step 365700, loss = 0.024995, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 08:13:52.410256: step 365800, loss = 0.050023, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 08:14:12.547106: step 365900, loss = 0.028676, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 08:14:33.498038: step 366000, loss = 0.041708, learning_rate = 0.000000 (2582.0 examples/sec)
=> Model saved to file: ./logs_res/model-366000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954239, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:15:05.575075: step 366100, loss = 0.013935, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-11 08:15:25.670198: step 366200, loss = 0.038403, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 08:15:45.816085: step 366300, loss = 0.020963, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 08:16:06.750195: step 366400, loss = 0.020471, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-11 08:16:26.869913: step 366500, loss = 0.018275, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 08:16:47.005001: step 366600, loss = 0.019663, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 08:17:07.148005: step 366700, loss = 0.021641, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 08:17:27.287339: step 366800, loss = 0.011156, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 08:17:48.321487: step 366900, loss = 0.013523, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 08:18:08.444295: step 367000, loss = 0.025975, learning_rate = 0.000000 (2565.9 examples/sec)
=> Model saved to file: ./logs_res/model-367000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:18:40.285320: step 367100, loss = 0.027088, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 08:19:00.411746: step 367200, loss = 0.027302, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 08:19:21.397642: step 367300, loss = 0.010136, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 08:19:41.525280: step 367400, loss = 0.029483, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 08:20:01.649047: step 367500, loss = 0.020462, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 08:20:21.793360: step 367600, loss = 0.024179, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 08:20:42.790654: step 367700, loss = 0.026036, learning_rate = 0.000000 (2577.1 examples/sec)
=> 2021-11-11 08:21:02.914722: step 367800, loss = 0.027208, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 08:21:23.056333: step 367900, loss = 0.036006, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 08:21:43.192265: step 368000, loss = 0.021478, learning_rate = 0.000000 (2564.2 examples/sec)
=> Model saved to file: ./logs_res/model-368000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:22:15.788269: step 368100, loss = 0.012223, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 08:22:35.900159: step 368200, loss = 0.015040, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 08:22:55.989094: step 368300, loss = 0.013534, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 08:23:16.145694: step 368400, loss = 0.039871, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 08:23:37.152250: step 368500, loss = 0.015919, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 08:23:57.283165: step 368600, loss = 0.027329, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 08:24:17.405315: step 368700, loss = 0.020665, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 08:24:37.538782: step 368800, loss = 0.021076, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 08:24:58.525302: step 368900, loss = 0.043446, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-11 08:25:18.634750: step 369000, loss = 0.021028, learning_rate = 0.000000 (2567.4 examples/sec)
=> Model saved to file: ./logs_res/model-369000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:25:50.780757: step 369100, loss = 0.037575, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-11 08:26:10.896979: step 369200, loss = 0.015763, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 08:26:31.954932: step 369300, loss = 0.020772, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-11 08:26:52.110255: step 369400, loss = 0.015230, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 08:27:12.254973: step 369500, loss = 0.027807, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 08:27:32.401926: step 369600, loss = 0.054408, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 08:27:52.541040: step 369700, loss = 0.037089, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 08:28:13.670447: step 369800, loss = 0.022266, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-11 08:28:33.841913: step 369900, loss = 0.028778, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 08:28:53.990392: step 370000, loss = 0.034757, learning_rate = 0.000000 (2562.4 examples/sec)
=> Model saved to file: ./logs_res/model-370000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947429, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:29:25.767770: step 370100, loss = 0.026888, learning_rate = 0.000000 (2574.5 examples/sec)
=> 2021-11-11 08:29:46.797096: step 370200, loss = 0.021503, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-11 08:30:06.919168: step 370300, loss = 0.015955, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 08:30:27.052841: step 370400, loss = 0.031033, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 08:30:47.261324: step 370500, loss = 0.020735, learning_rate = 0.000000 (2554.7 examples/sec)
=> 2021-11-11 08:31:08.228602: step 370600, loss = 0.015024, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-11 08:31:28.351290: step 370700, loss = 0.030003, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 08:31:48.484027: step 370800, loss = 0.036309, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 08:32:08.616899: step 370900, loss = 0.049155, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 08:32:29.787182: step 371000, loss = 0.037764, learning_rate = 0.000000 (2580.1 examples/sec)
=> Model saved to file: ./logs_res/model-371000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:33:01.696582: step 371100, loss = 0.028741, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 08:33:21.795396: step 371200, loss = 0.018846, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 08:33:41.917765: step 371300, loss = 0.030639, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 08:34:02.899745: step 371400, loss = 0.025785, learning_rate = 0.000000 (2579.1 examples/sec)
=> 2021-11-11 08:34:23.028630: step 371500, loss = 0.027163, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 08:34:43.157743: step 371600, loss = 0.022874, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 08:35:03.294262: step 371700, loss = 0.030586, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 08:35:24.388586: step 371800, loss = 0.022591, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 08:35:44.525379: step 371900, loss = 0.021297, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 08:36:04.678167: step 372000, loss = 0.025321, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-372000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954622, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:36:36.529634: step 372100, loss = 0.038313, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-11 08:36:57.651031: step 372200, loss = 0.019336, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 08:37:17.710823: step 372300, loss = 0.026750, learning_rate = 0.000000 (2573.8 examples/sec)
=> 2021-11-11 08:37:37.776586: step 372400, loss = 0.032635, learning_rate = 0.000000 (2573.3 examples/sec)
=> 2021-11-11 08:37:57.815190: step 372500, loss = 0.028560, learning_rate = 0.000000 (2577.0 examples/sec)
=> 2021-11-11 08:38:17.826995: step 372600, loss = 0.016180, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 08:38:38.871017: step 372700, loss = 0.034425, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-11 08:38:58.875447: step 372800, loss = 0.017077, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 08:39:18.862289: step 372900, loss = 0.047680, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 08:39:38.854658: step 373000, loss = 0.040844, learning_rate = 0.000000 (2582.4 examples/sec)
=> Model saved to file: ./logs_res/model-373000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:40:11.463816: step 373100, loss = 0.033887, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-11 08:40:31.391890: step 373200, loss = 0.043826, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 08:40:51.346499: step 373300, loss = 0.022869, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 08:41:11.309760: step 373400, loss = 0.023735, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 08:41:32.145330: step 373500, loss = 0.024373, learning_rate = 0.000000 (2603.1 examples/sec)
=> 2021-11-11 08:41:52.125233: step 373600, loss = 0.029752, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 08:42:12.102090: step 373700, loss = 0.035155, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-11 08:42:32.089960: step 373800, loss = 0.016264, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 08:42:53.063134: step 373900, loss = 0.022868, learning_rate = 0.000000 (2605.7 examples/sec)
=> 2021-11-11 08:43:13.033794: step 374000, loss = 0.039374, learning_rate = 0.000000 (2585.2 examples/sec)
=> Model saved to file: ./logs_res/model-374000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:43:44.652776: step 374100, loss = 0.015252, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-11 08:44:04.579791: step 374200, loss = 0.018315, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 08:44:25.378354: step 374300, loss = 0.023738, learning_rate = 0.000000 (2601.0 examples/sec)
=> 2021-11-11 08:44:45.333194: step 374400, loss = 0.035452, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-11 08:45:05.266313: step 374500, loss = 0.026531, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-11 08:45:25.196866: step 374600, loss = 0.026689, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-11 08:45:46.087859: step 374700, loss = 0.042910, learning_rate = 0.000000 (2603.7 examples/sec)
=> 2021-11-11 08:46:06.030115: step 374800, loss = 0.024628, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-11 08:46:25.972973: step 374900, loss = 0.020810, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-11 08:46:45.923414: step 375000, loss = 0.019216, learning_rate = 0.000000 (2587.9 examples/sec)
=> Model saved to file: ./logs_res/model-375000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:47:18.595232: step 375100, loss = 0.014308, learning_rate = 0.000000 (2611.3 examples/sec)
=> 2021-11-11 08:47:38.505248: step 375200, loss = 0.029052, learning_rate = 0.000000 (2593.5 examples/sec)
=> 2021-11-11 08:47:58.451152: step 375300, loss = 0.027873, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 08:48:18.416650: step 375400, loss = 0.031839, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 08:48:39.202624: step 375500, loss = 0.010861, learning_rate = 0.000000 (2608.8 examples/sec)
=> 2021-11-11 08:48:59.130863: step 375600, loss = 0.046486, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-11 08:49:19.064850: step 375700, loss = 0.032075, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-11 08:49:38.988363: step 375800, loss = 0.013437, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-11 08:49:58.917468: step 375900, loss = 0.022955, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-11 08:50:19.736193: step 376000, loss = 0.053982, learning_rate = 0.000000 (2610.0 examples/sec)
=> Model saved to file: ./logs_res/model-376000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:50:52.040372: step 376100, loss = 0.033644, learning_rate = 0.000000 (2596.4 examples/sec)
=> 2021-11-11 08:51:11.977277: step 376200, loss = 0.017496, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-11 08:51:31.935732: step 376300, loss = 0.022927, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 08:51:52.701006: step 376400, loss = 0.011611, learning_rate = 0.000000 (2605.6 examples/sec)
=> 2021-11-11 08:52:12.676169: step 376500, loss = 0.035285, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-11 08:52:32.685294: step 376600, loss = 0.042628, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-11 08:52:52.712187: step 376700, loss = 0.019128, learning_rate = 0.000000 (2578.4 examples/sec)
=> 2021-11-11 08:53:13.632811: step 376800, loss = 0.045906, learning_rate = 0.000000 (2594.4 examples/sec)
=> 2021-11-11 08:53:33.570575: step 376900, loss = 0.020874, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-11 08:53:53.501573: step 377000, loss = 0.034929, learning_rate = 0.000000 (2590.6 examples/sec)
=> Model saved to file: ./logs_res/model-377000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:54:25.261479: step 377100, loss = 0.016349, learning_rate = 0.000000 (2588.3 examples/sec)
=> 2021-11-11 08:54:46.032430: step 377200, loss = 0.017333, learning_rate = 0.000000 (2603.3 examples/sec)
=> 2021-11-11 08:55:05.978016: step 377300, loss = 0.016079, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 08:55:25.941914: step 377400, loss = 0.041268, learning_rate = 0.000000 (2586.8 examples/sec)
=> 2021-11-11 08:55:45.897593: step 377500, loss = 0.032551, learning_rate = 0.000000 (2587.2 examples/sec)
=> 2021-11-11 08:56:06.752641: step 377600, loss = 0.017892, learning_rate = 0.000000 (2599.0 examples/sec)
=> 2021-11-11 08:56:26.780592: step 377700, loss = 0.014248, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 08:56:46.841818: step 377800, loss = 0.029769, learning_rate = 0.000000 (2573.7 examples/sec)
=> 2021-11-11 08:57:06.911224: step 377900, loss = 0.010353, learning_rate = 0.000000 (2572.8 examples/sec)
=> 2021-11-11 08:57:27.956258: step 378000, loss = 0.084338, learning_rate = 0.000000 (2583.3 examples/sec)
=> Model saved to file: ./logs_res/model-378000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 08:57:59.729785: step 378100, loss = 0.030483, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-11 08:58:19.792913: step 378200, loss = 0.043019, learning_rate = 0.000000 (2573.6 examples/sec)
=> 2021-11-11 08:58:39.895614: step 378300, loss = 0.009829, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 08:59:00.903333: step 378400, loss = 0.021104, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-11 08:59:21.038622: step 378500, loss = 0.021284, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 08:59:41.169169: step 378600, loss = 0.030802, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 09:00:01.315796: step 378700, loss = 0.022516, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 09:00:21.492168: step 378800, loss = 0.023787, learning_rate = 0.000000 (2558.9 examples/sec)
=> 2021-11-11 09:00:42.523294: step 378900, loss = 0.035779, learning_rate = 0.000000 (2574.3 examples/sec)
=> 2021-11-11 09:01:02.689831: step 379000, loss = 0.036827, learning_rate = 0.000000 (2560.7 examples/sec)
=> Model saved to file: ./logs_res/model-379000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:01:34.566574: step 379100, loss = 0.029357, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 09:01:54.697493: step 379200, loss = 0.033190, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 09:02:15.656519: step 379300, loss = 0.040204, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-11 09:02:35.800518: step 379400, loss = 0.019906, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 09:02:56.039772: step 379500, loss = 0.034823, learning_rate = 0.000000 (2550.9 examples/sec)
=> 2021-11-11 09:03:16.194090: step 379600, loss = 0.028490, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 09:03:37.374344: step 379700, loss = 0.046059, learning_rate = 0.000000 (2576.4 examples/sec)
=> 2021-11-11 09:03:57.540698: step 379800, loss = 0.018686, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 09:04:17.713547: step 379900, loss = 0.041420, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 09:04:37.880591: step 380000, loss = 0.017553, learning_rate = 0.000000 (2560.3 examples/sec)
=> Model saved to file: ./logs_res/model-380000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947964, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:05:10.997925: step 380100, loss = 0.053025, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-11 09:05:31.132260: step 380200, loss = 0.022955, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 09:05:51.268573: step 380300, loss = 0.053387, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 09:06:11.435737: step 380400, loss = 0.026229, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 09:06:32.454967: step 380500, loss = 0.019919, learning_rate = 0.000000 (2575.6 examples/sec)
=> 2021-11-11 09:06:52.624623: step 380600, loss = 0.049525, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 09:07:12.798920: step 380700, loss = 0.015287, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 09:07:32.961119: step 380800, loss = 0.033091, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 09:07:54.020001: step 380900, loss = 0.017853, learning_rate = 0.000000 (2573.7 examples/sec)
=> 2021-11-11 09:08:14.191239: step 381000, loss = 0.024133, learning_rate = 0.000000 (2559.7 examples/sec)
=> Model saved to file: ./logs_res/model-381000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949265, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:08:46.220047: step 381100, loss = 0.037485, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 09:09:06.355917: step 381200, loss = 0.038562, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 09:09:27.364502: step 381300, loss = 0.047607, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 09:09:47.513131: step 381400, loss = 0.017460, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 09:10:07.671428: step 381500, loss = 0.045417, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 09:10:27.838991: step 381600, loss = 0.021534, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 09:10:48.041514: step 381700, loss = 0.042805, learning_rate = 0.000000 (2556.6 examples/sec)
=> 2021-11-11 09:11:09.055007: step 381800, loss = 0.030072, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-11 09:11:29.300557: step 381900, loss = 0.026981, learning_rate = 0.000000 (2550.1 examples/sec)
=> 2021-11-11 09:11:49.495115: step 382000, loss = 0.030608, learning_rate = 0.000000 (2556.8 examples/sec)
=> Model saved to file: ./logs_res/model-382000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:12:21.488475: step 382100, loss = 0.010878, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 09:12:42.451846: step 382200, loss = 0.036502, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 09:13:02.608325: step 382300, loss = 0.027012, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 09:13:22.784544: step 382400, loss = 0.029510, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 09:13:42.925608: step 382500, loss = 0.017579, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 09:14:03.948822: step 382600, loss = 0.025201, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 09:14:24.116254: step 382700, loss = 0.034708, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 09:14:44.293984: step 382800, loss = 0.060016, learning_rate = 0.000000 (2559.0 examples/sec)
=> 2021-11-11 09:15:04.471627: step 382900, loss = 0.031014, learning_rate = 0.000000 (2558.8 examples/sec)
=> 2021-11-11 09:15:25.532580: step 383000, loss = 0.009623, learning_rate = 0.000000 (2575.6 examples/sec)
=> Model saved to file: ./logs_res/model-383000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:15:57.847157: step 383100, loss = 0.008846, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 09:16:17.983188: step 383200, loss = 0.043977, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 09:16:38.138821: step 383300, loss = 0.027396, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 09:16:59.401886: step 383400, loss = 0.023442, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 09:17:19.604468: step 383500, loss = 0.026112, learning_rate = 0.000000 (2555.8 examples/sec)
=> 2021-11-11 09:17:39.792667: step 383600, loss = 0.015163, learning_rate = 0.000000 (2558.2 examples/sec)
=> 2021-11-11 09:17:59.981735: step 383700, loss = 0.051059, learning_rate = 0.000000 (2557.6 examples/sec)
=> 2021-11-11 09:18:21.074806: step 383800, loss = 0.037283, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 09:18:41.239324: step 383900, loss = 0.039736, learning_rate = 0.000000 (2560.5 examples/sec)
=> 2021-11-11 09:19:01.448135: step 384000, loss = 0.028232, learning_rate = 0.000000 (2554.9 examples/sec)
=> Model saved to file: ./logs_res/model-384000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:19:33.758681: step 384100, loss = 0.010552, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 09:19:54.871492: step 384200, loss = 0.016070, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-11 09:20:15.027761: step 384300, loss = 0.044419, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 09:20:35.231236: step 384400, loss = 0.032708, learning_rate = 0.000000 (2555.5 examples/sec)
=> 2021-11-11 09:20:55.410109: step 384500, loss = 0.050027, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 09:21:15.588203: step 384600, loss = 0.020279, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 09:21:36.712752: step 384700, loss = 0.035810, learning_rate = 0.000000 (2575.2 examples/sec)
=> 2021-11-11 09:21:56.886996: step 384800, loss = 0.036365, learning_rate = 0.000000 (2559.5 examples/sec)
=> 2021-11-11 09:22:17.057250: step 384900, loss = 0.044604, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 09:22:37.230793: step 385000, loss = 0.015766, learning_rate = 0.000000 (2559.4 examples/sec)
=> Model saved to file: ./logs_res/model-385000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:23:10.030890: step 385100, loss = 0.015719, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 09:23:30.168951: step 385200, loss = 0.038386, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 09:23:50.311726: step 385300, loss = 0.014017, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 09:24:10.459177: step 385400, loss = 0.043674, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 09:24:31.476433: step 385500, loss = 0.030760, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 09:24:51.651760: step 385600, loss = 0.055686, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 09:25:11.825028: step 385700, loss = 0.041542, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 09:25:32.015482: step 385800, loss = 0.022910, learning_rate = 0.000000 (2557.2 examples/sec)
=> 2021-11-11 09:25:53.101270: step 385900, loss = 0.027251, learning_rate = 0.000000 (2574.0 examples/sec)
=> 2021-11-11 09:26:13.275072: step 386000, loss = 0.014227, learning_rate = 0.000000 (2559.6 examples/sec)
=> Model saved to file: ./logs_res/model-386000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:26:45.509558: step 386100, loss = 0.023575, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 09:27:05.635584: step 386200, loss = 0.023054, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 09:27:26.730228: step 386300, loss = 0.034836, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 09:27:46.870187: step 386400, loss = 0.014680, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 09:28:07.021200: step 386500, loss = 0.019387, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 09:28:27.177805: step 386600, loss = 0.035178, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 09:28:48.196017: step 386700, loss = 0.015199, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 09:29:08.370019: step 386800, loss = 0.027332, learning_rate = 0.000000 (2559.2 examples/sec)
=> 2021-11-11 09:29:28.537452: step 386900, loss = 0.020568, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 09:29:48.685280: step 387000, loss = 0.021056, learning_rate = 0.000000 (2562.7 examples/sec)
=> Model saved to file: ./logs_res/model-387000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:30:22.107182: step 387100, loss = 0.026733, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 09:30:42.245916: step 387200, loss = 0.029202, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 09:31:02.382958: step 387300, loss = 0.059209, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 09:31:22.537457: step 387400, loss = 0.019683, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 09:31:42.711588: step 387500, loss = 0.021278, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 09:32:03.707027: step 387600, loss = 0.014173, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-11 09:32:23.855135: step 387700, loss = 0.028152, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 09:32:44.020031: step 387800, loss = 0.031628, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 09:33:04.192304: step 387900, loss = 0.019100, learning_rate = 0.000000 (2559.5 examples/sec)
=> 2021-11-11 09:33:25.200890: step 388000, loss = 0.018350, learning_rate = 0.000000 (2574.8 examples/sec)
=> Model saved to file: ./logs_res/model-388000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949036, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:33:57.319737: step 388100, loss = 0.029261, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 09:34:17.459885: step 388200, loss = 0.032214, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 09:34:37.607916: step 388300, loss = 0.038541, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 09:34:58.590905: step 388400, loss = 0.018324, learning_rate = 0.000000 (2577.8 examples/sec)
=> 2021-11-11 09:35:18.749945: step 388500, loss = 0.022315, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 09:35:38.940054: step 388600, loss = 0.020070, learning_rate = 0.000000 (2557.5 examples/sec)
=> 2021-11-11 09:35:59.211346: step 388700, loss = 0.020339, learning_rate = 0.000000 (2547.2 examples/sec)
=> 2021-11-11 09:36:20.354619: step 388800, loss = 0.051547, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 09:36:40.566144: step 388900, loss = 0.056258, learning_rate = 0.000000 (2555.0 examples/sec)
=> 2021-11-11 09:37:00.763727: step 389000, loss = 0.041967, learning_rate = 0.000000 (2556.6 examples/sec)
=> Model saved to file: ./logs_res/model-389000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:37:32.948648: step 389100, loss = 0.029282, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 09:37:53.966485: step 389200, loss = 0.029209, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-11 09:38:14.118394: step 389300, loss = 0.038072, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 09:38:34.285230: step 389400, loss = 0.027028, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 09:38:54.459896: step 389500, loss = 0.020425, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 09:39:15.682585: step 389600, loss = 0.035040, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-11 09:39:35.869194: step 389700, loss = 0.020811, learning_rate = 0.000000 (2557.8 examples/sec)
=> 2021-11-11 09:39:56.046926: step 389800, loss = 0.016304, learning_rate = 0.000000 (2558.9 examples/sec)
=> 2021-11-11 09:40:16.243336: step 389900, loss = 0.020939, learning_rate = 0.000000 (2556.5 examples/sec)
=> 2021-11-11 09:40:37.268389: step 390000, loss = 0.020880, learning_rate = 0.000000 (2574.7 examples/sec)
=> Model saved to file: ./logs_res/model-390000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:41:09.622435: step 390100, loss = 0.038910, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 09:41:29.771485: step 390200, loss = 0.021563, learning_rate = 0.000000 (2562.5 examples/sec)
=> 2021-11-11 09:41:49.926991: step 390300, loss = 0.045190, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 09:42:10.077578: step 390400, loss = 0.035021, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 09:42:31.104377: step 390500, loss = 0.019125, learning_rate = 0.000000 (2574.1 examples/sec)
=> 2021-11-11 09:42:51.277805: step 390600, loss = 0.038499, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 09:43:11.441858: step 390700, loss = 0.024392, learning_rate = 0.000000 (2560.5 examples/sec)
=> 2021-11-11 09:43:31.697343: step 390800, loss = 0.030231, learning_rate = 0.000000 (2548.9 examples/sec)
=> 2021-11-11 09:43:52.757320: step 390900, loss = 0.032739, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-11 09:44:12.953073: step 391000, loss = 0.029812, learning_rate = 0.000000 (2556.8 examples/sec)
=> Model saved to file: ./logs_res/model-391000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950490, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:44:44.826991: step 391100, loss = 0.020886, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 09:45:04.963008: step 391200, loss = 0.037363, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 09:45:26.136138: step 391300, loss = 0.013388, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 09:45:46.287870: step 391400, loss = 0.034241, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 09:46:06.455424: step 391500, loss = 0.041253, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 09:46:26.597006: step 391600, loss = 0.046167, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 09:46:47.819475: step 391700, loss = 0.017329, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-11 09:47:07.977417: step 391800, loss = 0.039055, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 09:47:28.150019: step 391900, loss = 0.020185, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 09:47:48.319477: step 392000, loss = 0.023717, learning_rate = 0.000000 (2559.8 examples/sec)
=> Model saved to file: ./logs_res/model-392000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:48:21.561771: step 392100, loss = 0.032490, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 09:48:41.695015: step 392200, loss = 0.014616, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 09:49:01.855840: step 392300, loss = 0.035728, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 09:49:22.002455: step 392400, loss = 0.071402, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 09:49:42.996141: step 392500, loss = 0.030317, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 09:50:03.158340: step 392600, loss = 0.046690, learning_rate = 0.000000 (2560.8 examples/sec)
=> 2021-11-11 09:50:23.326119: step 392700, loss = 0.034454, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 09:50:43.484444: step 392800, loss = 0.038510, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 09:51:04.553717: step 392900, loss = 0.014722, learning_rate = 0.000000 (2572.4 examples/sec)
=> 2021-11-11 09:51:24.714139: step 393000, loss = 0.017464, learning_rate = 0.000000 (2561.0 examples/sec)
=> Model saved to file: ./logs_res/model-393000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:51:56.920912: step 393100, loss = 0.023455, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 09:52:17.054094: step 393200, loss = 0.019756, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 09:52:37.175406: step 393300, loss = 0.035380, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 09:52:58.267724: step 393400, loss = 0.027511, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 09:53:18.409761: step 393500, loss = 0.024908, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 09:53:38.574923: step 393600, loss = 0.052628, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 09:53:58.742809: step 393700, loss = 0.039883, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 09:54:19.963104: step 393800, loss = 0.016228, learning_rate = 0.000000 (2576.1 examples/sec)
=> 2021-11-11 09:54:40.134047: step 393900, loss = 0.025599, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 09:55:00.305631: step 394000, loss = 0.029179, learning_rate = 0.000000 (2559.9 examples/sec)
=> Model saved to file: ./logs_res/model-394000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:55:32.342055: step 394100, loss = 0.023610, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 09:55:53.382888: step 394200, loss = 0.010809, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-11 09:56:13.522638: step 394300, loss = 0.021635, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 09:56:33.703535: step 394400, loss = 0.013398, learning_rate = 0.000000 (2558.4 examples/sec)
=> 2021-11-11 09:56:53.856014: step 394500, loss = 0.022647, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 09:57:14.845942: step 394600, loss = 0.016229, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-11 09:57:35.068433: step 394700, loss = 0.032868, learning_rate = 0.000000 (2553.1 examples/sec)
=> 2021-11-11 09:57:55.225299: step 394800, loss = 0.040841, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 09:58:15.387409: step 394900, loss = 0.051815, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 09:58:36.416541: step 395000, loss = 0.022089, learning_rate = 0.000000 (2576.7 examples/sec)
=> Model saved to file: ./logs_res/model-395000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954392, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 09:59:08.474109: step 395100, loss = 0.037330, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 09:59:28.626654: step 395200, loss = 0.030417, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 09:59:48.797286: step 395300, loss = 0.006502, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:00:09.836234: step 395400, loss = 0.041181, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 10:00:30.010857: step 395500, loss = 0.015667, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 10:00:50.216781: step 395600, loss = 0.022044, learning_rate = 0.000000 (2555.4 examples/sec)
=> 2021-11-11 10:01:10.398320: step 395700, loss = 0.034779, learning_rate = 0.000000 (2558.2 examples/sec)
=> 2021-11-11 10:01:31.425591: step 395800, loss = 0.045782, learning_rate = 0.000000 (2574.3 examples/sec)
=> 2021-11-11 10:01:51.685163: step 395900, loss = 0.016943, learning_rate = 0.000000 (2548.3 examples/sec)
=> 2021-11-11 10:02:11.869855: step 396000, loss = 0.032382, learning_rate = 0.000000 (2557.9 examples/sec)
=> Model saved to file: ./logs_res/model-396000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:02:43.940266: step 396100, loss = 0.028321, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 10:03:04.943140: step 396200, loss = 0.009135, learning_rate = 0.000000 (2577.4 examples/sec)
=> 2021-11-11 10:03:25.085068: step 396300, loss = 0.029336, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 10:03:45.239768: step 396400, loss = 0.025244, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 10:04:05.394984: step 396500, loss = 0.013613, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 10:04:25.560783: step 396600, loss = 0.025815, learning_rate = 0.000000 (2560.5 examples/sec)
=> 2021-11-11 10:04:46.794732: step 396700, loss = 0.017843, learning_rate = 0.000000 (2574.8 examples/sec)
=> 2021-11-11 10:05:06.950430: step 396800, loss = 0.044448, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 10:05:27.092371: step 396900, loss = 0.033511, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 10:05:47.262785: step 397000, loss = 0.041077, learning_rate = 0.000000 (2559.9 examples/sec)
=> Model saved to file: ./logs_res/model-397000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:06:20.110109: step 397100, loss = 0.051110, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 10:06:40.238303: step 397200, loss = 0.019435, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 10:07:00.379001: step 397300, loss = 0.036458, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 10:07:20.537646: step 397400, loss = 0.022670, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 10:07:41.528276: step 397500, loss = 0.015548, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-11 10:08:01.684687: step 397600, loss = 0.012746, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 10:08:21.864746: step 397700, loss = 0.013301, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 10:08:42.047923: step 397800, loss = 0.047718, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 10:09:03.217554: step 397900, loss = 0.026519, learning_rate = 0.000000 (2574.7 examples/sec)
=> 2021-11-11 10:09:23.418160: step 398000, loss = 0.029056, learning_rate = 0.000000 (2556.1 examples/sec)
=> Model saved to file: ./logs_res/model-398000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:09:55.303427: step 398100, loss = 0.039612, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 10:10:15.469860: step 398200, loss = 0.017862, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 10:10:36.485258: step 398300, loss = 0.021836, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 10:10:56.655056: step 398400, loss = 0.019466, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:11:16.825671: step 398500, loss = 0.037885, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:11:36.991005: step 398600, loss = 0.020108, learning_rate = 0.000000 (2560.3 examples/sec)
=> 2021-11-11 10:11:58.022206: step 398700, loss = 0.026920, learning_rate = 0.000000 (2572.7 examples/sec)
=> 2021-11-11 10:12:18.188681: step 398800, loss = 0.034281, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 10:12:38.377065: step 398900, loss = 0.019541, learning_rate = 0.000000 (2557.7 examples/sec)
=> 2021-11-11 10:12:58.541992: step 399000, loss = 0.027107, learning_rate = 0.000000 (2560.5 examples/sec)
=> Model saved to file: ./logs_res/model-399000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:13:31.542041: step 399100, loss = 0.015143, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-11 10:13:51.676686: step 399200, loss = 0.018713, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 10:14:11.825257: step 399300, loss = 0.021232, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 10:14:31.970054: step 399400, loss = 0.030926, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 10:14:52.125548: step 399500, loss = 0.052612, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 10:15:13.202873: step 399600, loss = 0.018962, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 10:15:33.356905: step 399700, loss = 0.023323, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 10:15:53.526084: step 399800, loss = 0.025392, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 10:16:13.696873: step 399900, loss = 0.019135, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:16:34.704367: step 400000, loss = 0.029914, learning_rate = 0.000000 (2575.1 examples/sec)
=> Model saved to file: ./logs_res/model-400000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948883, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:17:06.706446: step 400100, loss = 0.021076, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 10:17:26.830797: step 400200, loss = 0.026706, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 10:17:46.962446: step 400300, loss = 0.029133, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 10:18:07.984705: step 400400, loss = 0.022179, learning_rate = 0.000000 (2576.4 examples/sec)
=> 2021-11-11 10:18:28.149612: step 400500, loss = 0.021219, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 10:18:48.288153: step 400600, loss = 0.027519, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 10:19:08.445525: step 400700, loss = 0.026254, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 10:19:29.539918: step 400800, loss = 0.015370, learning_rate = 0.000000 (2577.7 examples/sec)
=> 2021-11-11 10:19:49.698170: step 400900, loss = 0.027666, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 10:20:09.862437: step 401000, loss = 0.015620, learning_rate = 0.000000 (2560.6 examples/sec)
=> Model saved to file: ./logs_res/model-401000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:20:42.349414: step 401100, loss = 0.024583, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 10:21:03.351845: step 401200, loss = 0.048602, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 10:21:23.484534: step 401300, loss = 0.027965, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 10:21:43.628232: step 401400, loss = 0.021346, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 10:22:03.788028: step 401500, loss = 0.063348, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 10:22:24.783423: step 401600, loss = 0.017537, learning_rate = 0.000000 (2577.6 examples/sec)
=> 2021-11-11 10:22:44.939734: step 401700, loss = 0.026145, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 10:23:05.109153: step 401800, loss = 0.020566, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:23:25.292192: step 401900, loss = 0.038610, learning_rate = 0.000000 (2558.3 examples/sec)
=> 2021-11-11 10:23:46.340179: step 402000, loss = 0.035642, learning_rate = 0.000000 (2575.9 examples/sec)
=> Model saved to file: ./logs_res/model-402000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:24:18.257048: step 402100, loss = 0.032449, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 10:24:38.396621: step 402200, loss = 0.014307, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 10:24:58.566046: step 402300, loss = 0.020551, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 10:25:18.743316: step 402400, loss = 0.068168, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 10:25:39.829499: step 402500, loss = 0.056128, learning_rate = 0.000000 (2577.8 examples/sec)
=> 2021-11-11 10:25:59.981654: step 402600, loss = 0.050486, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 10:26:20.144489: step 402700, loss = 0.033691, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 10:26:40.346243: step 402800, loss = 0.019380, learning_rate = 0.000000 (2556.2 examples/sec)
=> 2021-11-11 10:27:01.428476: step 402900, loss = 0.033168, learning_rate = 0.000000 (2572.5 examples/sec)
=> 2021-11-11 10:27:21.615507: step 403000, loss = 0.024320, learning_rate = 0.000000 (2557.9 examples/sec)
=> Model saved to file: ./logs_res/model-403000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:27:53.872660: step 403100, loss = 0.027380, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 10:28:14.023984: step 403200, loss = 0.019564, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 10:28:35.087378: step 403300, loss = 0.035347, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 10:28:55.247075: step 403400, loss = 0.016554, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 10:29:15.410406: step 403500, loss = 0.025515, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 10:29:35.572347: step 403600, loss = 0.024517, learning_rate = 0.000000 (2561.0 examples/sec)
=> 2021-11-11 10:29:56.622030: step 403700, loss = 0.035032, learning_rate = 0.000000 (2573.5 examples/sec)
=> 2021-11-11 10:30:16.779201: step 403800, loss = 0.021199, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 10:30:36.953262: step 403900, loss = 0.029955, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 10:30:57.112753: step 404000, loss = 0.078885, learning_rate = 0.000000 (2561.4 examples/sec)
=> Model saved to file: ./logs_res/model-404000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:31:30.143121: step 404100, loss = 0.035266, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 10:31:50.323243: step 404200, loss = 0.014912, learning_rate = 0.000000 (2558.9 examples/sec)
=> 2021-11-11 10:32:10.483100: step 404300, loss = 0.021456, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 10:32:30.712385: step 404400, loss = 0.034675, learning_rate = 0.000000 (2552.4 examples/sec)
=> 2021-11-11 10:32:51.767669: step 404500, loss = 0.029811, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 10:33:11.957634: step 404600, loss = 0.053079, learning_rate = 0.000000 (2557.5 examples/sec)
=> 2021-11-11 10:33:32.149778: step 404700, loss = 0.034270, learning_rate = 0.000000 (2557.2 examples/sec)
=> 2021-11-11 10:33:52.337770: step 404800, loss = 0.020030, learning_rate = 0.000000 (2557.8 examples/sec)
=> 2021-11-11 10:34:13.354212: step 404900, loss = 0.021076, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-11 10:34:33.518315: step 405000, loss = 0.024929, learning_rate = 0.000000 (2561.0 examples/sec)
=> Model saved to file: ./logs_res/model-405000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:35:05.611883: step 405100, loss = 0.019115, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 10:35:25.771451: step 405200, loss = 0.011266, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 10:35:45.947553: step 405300, loss = 0.025347, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 10:36:07.090762: step 405400, loss = 0.025805, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 10:36:27.253781: step 405500, loss = 0.014502, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 10:36:47.423442: step 405600, loss = 0.009935, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 10:37:07.604512: step 405700, loss = 0.035842, learning_rate = 0.000000 (2558.5 examples/sec)
=> 2021-11-11 10:37:28.672322: step 405800, loss = 0.032590, learning_rate = 0.000000 (2574.5 examples/sec)
=> 2021-11-11 10:37:48.857203: step 405900, loss = 0.042415, learning_rate = 0.000000 (2558.3 examples/sec)
=> 2021-11-11 10:38:09.033786: step 406000, loss = 0.022508, learning_rate = 0.000000 (2559.0 examples/sec)
=> Model saved to file: ./logs_res/model-406000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954469, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:38:41.186493: step 406100, loss = 0.027123, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 10:39:02.345428: step 406200, loss = 0.010896, learning_rate = 0.000000 (2577.0 examples/sec)
=> 2021-11-11 10:39:22.514152: step 406300, loss = 0.033245, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 10:39:42.671665: step 406400, loss = 0.033838, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 10:40:02.831651: step 406500, loss = 0.036151, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 10:40:23.899602: step 406600, loss = 0.014570, learning_rate = 0.000000 (2574.8 examples/sec)
=> 2021-11-11 10:40:44.051031: step 406700, loss = 0.041676, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 10:41:04.224253: step 406800, loss = 0.009461, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 10:41:24.397404: step 406900, loss = 0.013534, learning_rate = 0.000000 (2559.7 examples/sec)
=> 2021-11-11 10:41:45.630965: step 407000, loss = 0.021277, learning_rate = 0.000000 (2572.3 examples/sec)
=> Model saved to file: ./logs_res/model-407000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:42:17.641950: step 407100, loss = 0.035081, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 10:42:37.801120: step 407200, loss = 0.037385, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 10:42:57.967817: step 407300, loss = 0.020452, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 10:43:18.978950: step 407400, loss = 0.012522, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 10:43:39.136379: step 407500, loss = 0.025613, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 10:43:59.309422: step 407600, loss = 0.012309, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 10:44:19.499587: step 407700, loss = 0.022179, learning_rate = 0.000000 (2557.6 examples/sec)
=> 2021-11-11 10:44:40.557443: step 407800, loss = 0.024624, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-11 10:45:00.776273: step 407900, loss = 0.054400, learning_rate = 0.000000 (2554.2 examples/sec)
=> 2021-11-11 10:45:20.976057: step 408000, loss = 0.051520, learning_rate = 0.000000 (2556.2 examples/sec)
=> Model saved to file: ./logs_res/model-408000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:45:53.171457: step 408100, loss = 0.051279, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 10:46:13.321205: step 408200, loss = 0.034383, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 10:46:34.387393: step 408300, loss = 0.027224, learning_rate = 0.000000 (2576.6 examples/sec)
=> 2021-11-11 10:46:54.553024: step 408400, loss = 0.041469, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 10:47:14.722006: step 408500, loss = 0.023751, learning_rate = 0.000000 (2560.1 examples/sec)
=> 2021-11-11 10:47:34.915669: step 408600, loss = 0.043442, learning_rate = 0.000000 (2557.0 examples/sec)
=> 2021-11-11 10:47:55.961739: step 408700, loss = 0.020319, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 10:48:16.173175: step 408800, loss = 0.037535, learning_rate = 0.000000 (2555.3 examples/sec)
=> 2021-11-11 10:48:36.369838: step 408900, loss = 0.023019, learning_rate = 0.000000 (2557.4 examples/sec)
=> 2021-11-11 10:48:56.579591: step 409000, loss = 0.053376, learning_rate = 0.000000 (2555.5 examples/sec)
=> Model saved to file: ./logs_res/model-409000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:49:29.627534: step 409100, loss = 0.035342, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 10:49:49.761328: step 409200, loss = 0.019427, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 10:50:09.918480: step 409300, loss = 0.018506, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 10:50:30.089371: step 409400, loss = 0.015634, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 10:50:51.220017: step 409500, loss = 0.019290, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 10:51:11.375299: step 409600, loss = 0.030964, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 10:51:31.559997: step 409700, loss = 0.072732, learning_rate = 0.000000 (2558.2 examples/sec)
=> 2021-11-11 10:51:51.728612: step 409800, loss = 0.018489, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 10:52:12.840425: step 409900, loss = 0.027125, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 10:52:32.995497: step 410000, loss = 0.018042, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-410000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949801, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:53:05.139389: step 410100, loss = 0.022673, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 10:53:25.362155: step 410200, loss = 0.014647, learning_rate = 0.000000 (2553.4 examples/sec)
=> 2021-11-11 10:53:46.386235: step 410300, loss = 0.024964, learning_rate = 0.000000 (2578.3 examples/sec)
=> 2021-11-11 10:54:06.533923: step 410400, loss = 0.009713, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 10:54:26.775828: step 410500, loss = 0.037659, learning_rate = 0.000000 (2550.8 examples/sec)
=> 2021-11-11 10:54:46.942419: step 410600, loss = 0.019608, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 10:55:07.990420: step 410700, loss = 0.022400, learning_rate = 0.000000 (2572.6 examples/sec)
=> 2021-11-11 10:55:28.178949: step 410800, loss = 0.018898, learning_rate = 0.000000 (2557.8 examples/sec)
=> 2021-11-11 10:55:48.359788: step 410900, loss = 0.022691, learning_rate = 0.000000 (2558.4 examples/sec)
=> 2021-11-11 10:56:08.524169: step 411000, loss = 0.030359, learning_rate = 0.000000 (2560.6 examples/sec)
=> Model saved to file: ./logs_res/model-411000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 10:56:40.942758: step 411100, loss = 0.012187, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 10:57:02.037155: step 411200, loss = 0.040201, learning_rate = 0.000000 (2575.4 examples/sec)
=> 2021-11-11 10:57:22.218243: step 411300, loss = 0.025377, learning_rate = 0.000000 (2558.6 examples/sec)
=> 2021-11-11 10:57:42.396309: step 411400, loss = 0.016688, learning_rate = 0.000000 (2559.0 examples/sec)
=> 2021-11-11 10:58:02.576992: step 411500, loss = 0.026333, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 10:58:23.700796: step 411600, loss = 0.019783, learning_rate = 0.000000 (2574.8 examples/sec)
=> 2021-11-11 10:58:43.869723: step 411700, loss = 0.065380, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 10:59:04.048721: step 411800, loss = 0.031742, learning_rate = 0.000000 (2558.6 examples/sec)
=> 2021-11-11 10:59:24.239552: step 411900, loss = 0.013838, learning_rate = 0.000000 (2557.2 examples/sec)
=> 2021-11-11 10:59:45.492667: step 412000, loss = 0.022058, learning_rate = 0.000000 (2559.7 examples/sec)
=> Model saved to file: ./logs_res/model-412000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:00:17.642524: step 412100, loss = 0.040627, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 11:00:37.803851: step 412200, loss = 0.025672, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 11:00:57.972226: step 412300, loss = 0.021573, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 11:01:19.044748: step 412400, loss = 0.058774, learning_rate = 0.000000 (2571.0 examples/sec)
=> 2021-11-11 11:01:39.243581: step 412500, loss = 0.022603, learning_rate = 0.000000 (2556.7 examples/sec)
=> 2021-11-11 11:01:59.472481: step 412600, loss = 0.022049, learning_rate = 0.000000 (2552.9 examples/sec)
=> 2021-11-11 11:02:19.672860: step 412700, loss = 0.030443, learning_rate = 0.000000 (2556.2 examples/sec)
=> 2021-11-11 11:02:40.717271: step 412800, loss = 0.036450, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 11:03:00.902230: step 412900, loss = 0.050256, learning_rate = 0.000000 (2558.0 examples/sec)
=> 2021-11-11 11:03:21.070304: step 413000, loss = 0.016271, learning_rate = 0.000000 (2560.2 examples/sec)
=> Model saved to file: ./logs_res/model-413000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:03:53.358118: step 413100, loss = 0.039805, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 11:04:14.453610: step 413200, loss = 0.031834, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 11:04:34.621145: step 413300, loss = 0.005589, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 11:04:54.814121: step 413400, loss = 0.071828, learning_rate = 0.000000 (2557.0 examples/sec)
=> 2021-11-11 11:05:15.002153: step 413500, loss = 0.035918, learning_rate = 0.000000 (2557.7 examples/sec)
=> 2021-11-11 11:05:36.129977: step 413600, loss = 0.024947, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 11:05:56.378199: step 413700, loss = 0.015303, learning_rate = 0.000000 (2550.2 examples/sec)
=> 2021-11-11 11:06:16.645689: step 413800, loss = 0.011611, learning_rate = 0.000000 (2547.6 examples/sec)
=> 2021-11-11 11:06:36.853114: step 413900, loss = 0.039149, learning_rate = 0.000000 (2555.5 examples/sec)
=> 2021-11-11 11:06:57.050470: step 414000, loss = 0.025321, learning_rate = 0.000000 (2556.9 examples/sec)
=> Model saved to file: ./logs_res/model-414000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:07:30.208284: step 414100, loss = 0.024164, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 11:07:50.354686: step 414200, loss = 0.054529, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 11:08:10.487898: step 414300, loss = 0.019169, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 11:08:30.713461: step 414400, loss = 0.023020, learning_rate = 0.000000 (2552.9 examples/sec)
=> 2021-11-11 11:08:51.880397: step 414500, loss = 0.009855, learning_rate = 0.000000 (2574.9 examples/sec)
=> 2021-11-11 11:09:12.076848: step 414600, loss = 0.028342, learning_rate = 0.000000 (2556.7 examples/sec)
=> 2021-11-11 11:09:32.282085: step 414700, loss = 0.028204, learning_rate = 0.000000 (2556.2 examples/sec)
=> 2021-11-11 11:09:52.483454: step 414800, loss = 0.028537, learning_rate = 0.000000 (2555.9 examples/sec)
=> 2021-11-11 11:10:13.484624: step 414900, loss = 0.018711, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 11:10:33.659599: step 415000, loss = 0.026651, learning_rate = 0.000000 (2559.5 examples/sec)
=> Model saved to file: ./logs_res/model-415000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:11:05.662048: step 415100, loss = 0.027476, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 11:11:25.801644: step 415200, loss = 0.023194, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 11:11:46.882960: step 415300, loss = 0.020275, learning_rate = 0.000000 (2574.2 examples/sec)
=> 2021-11-11 11:12:07.063112: step 415400, loss = 0.057298, learning_rate = 0.000000 (2559.2 examples/sec)
=> 2021-11-11 11:12:27.212555: step 415500, loss = 0.016810, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 11:12:47.775053: step 415600, loss = 0.024054, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-11 11:13:09.302169: step 415700, loss = 0.017954, learning_rate = 0.000000 (2572.3 examples/sec)
=> 2021-11-11 11:13:29.508322: step 415800, loss = 0.023147, learning_rate = 0.000000 (2555.6 examples/sec)
=> 2021-11-11 11:13:49.732500: step 415900, loss = 0.019549, learning_rate = 0.000000 (2553.8 examples/sec)
=> 2021-11-11 11:14:09.947819: step 416000, loss = 0.016892, learning_rate = 0.000000 (2554.5 examples/sec)
=> Model saved to file: ./logs_res/model-416000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:14:47.844733: step 416100, loss = 0.015034, learning_rate = 0.000000 (2648.4 examples/sec)
=> 2021-11-11 11:15:08.186350: step 416200, loss = 0.015555, learning_rate = 0.000000 (2541.4 examples/sec)
=> 2021-11-11 11:15:28.515938: step 416300, loss = 0.052100, learning_rate = 0.000000 (2541.5 examples/sec)
=> 2021-11-11 11:15:48.749157: step 416400, loss = 0.093679, learning_rate = 0.000000 (2552.2 examples/sec)
=> 2021-11-11 11:16:09.863669: step 416500, loss = 0.021860, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 11:16:38.270095: step 416600, loss = 0.029331, learning_rate = 0.000000 (2766.3 examples/sec)
=> 2021-11-11 11:17:00.453558: step 416700, loss = 0.022020, learning_rate = 0.000000 (2603.9 examples/sec)
=> 2021-11-11 11:17:23.755728: step 416800, loss = 0.050363, learning_rate = 0.000000 (2655.7 examples/sec)
=> 2021-11-11 11:17:55.037295: step 416900, loss = 0.016789, learning_rate = 0.000000 (2835.4 examples/sec)
=> 2021-11-11 11:18:15.203350: step 417000, loss = 0.026916, learning_rate = 0.000000 (2559.4 examples/sec)
=> Model saved to file: ./logs_res/model-417000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:18:47.341535: step 417100, loss = 0.024200, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 11:19:07.493740: step 417200, loss = 0.039829, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 11:19:27.645164: step 417300, loss = 0.022048, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 11:19:48.667811: step 417400, loss = 0.034532, learning_rate = 0.000000 (2579.2 examples/sec)
=> 2021-11-11 11:20:08.827628: step 417500, loss = 0.017167, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 11:20:28.995956: step 417600, loss = 0.026058, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 11:20:49.178520: step 417700, loss = 0.019908, learning_rate = 0.000000 (2558.3 examples/sec)
=> 2021-11-11 11:21:10.759258: step 417800, loss = 0.017798, learning_rate = 0.000000 (2575.6 examples/sec)
=> 2021-11-11 11:21:34.690005: step 417900, loss = 0.040458, learning_rate = 0.000000 (2639.7 examples/sec)
=> 2021-11-11 11:21:54.872816: step 418000, loss = 0.022228, learning_rate = 0.000000 (2559.1 examples/sec)
=> Model saved to file: ./logs_res/model-418000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:22:32.814805: step 418100, loss = 0.023222, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 11:22:55.848782: step 418200, loss = 0.026922, learning_rate = 0.000000 (2631.8 examples/sec)
=> 2021-11-11 11:23:16.020240: step 418300, loss = 0.049877, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 11:23:40.557788: step 418400, loss = 0.033765, learning_rate = 0.000000 (2687.8 examples/sec)
=> 2021-11-11 11:24:00.730835: step 418500, loss = 0.038340, learning_rate = 0.000000 (2560.0 examples/sec)
=> 2021-11-11 11:24:21.825688: step 418600, loss = 0.030206, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 11:24:41.982650: step 418700, loss = 0.065844, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 11:25:02.138720: step 418800, loss = 0.010324, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 11:25:40.382384: step 418900, loss = 0.031054, learning_rate = 0.000000 (2997.4 examples/sec)
=> 2021-11-11 11:26:04.767511: step 419000, loss = 0.018610, learning_rate = 0.000000 (2666.7 examples/sec)
=> Model saved to file: ./logs_res/model-419000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:26:36.781538: step 419100, loss = 0.031603, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 11:26:56.920368: step 419200, loss = 0.049426, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 11:27:17.069261: step 419300, loss = 0.016257, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 11:27:38.928069: step 419400, loss = 0.040431, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-11 11:27:59.084587: step 419500, loss = 0.031372, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 11:28:21.051405: step 419600, loss = 0.042104, learning_rate = 0.000000 (2610.7 examples/sec)
=> 2021-11-11 11:28:43.393530: step 419700, loss = 0.021629, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-11 11:29:04.443756: step 419800, loss = 0.027049, learning_rate = 0.000000 (2574.5 examples/sec)
=> 2021-11-11 11:29:28.325909: step 419900, loss = 0.026140, learning_rate = 0.000000 (2665.1 examples/sec)
=> 2021-11-11 11:29:48.475971: step 420000, loss = 0.034050, learning_rate = 0.000000 (2562.6 examples/sec)
=> Model saved to file: ./logs_res/model-420000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:30:20.651081: step 420100, loss = 0.043555, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 11:30:40.786445: step 420200, loss = 0.013303, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 11:31:01.746860: step 420300, loss = 0.026278, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 11:31:21.856795: step 420400, loss = 0.014957, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 11:31:41.955000: step 420500, loss = 0.021320, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 11:32:02.055083: step 420600, loss = 0.019406, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 11:32:23.012094: step 420700, loss = 0.042311, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-11 11:32:43.357773: step 420800, loss = 0.035758, learning_rate = 0.000000 (2601.0 examples/sec)
=> 2021-11-11 11:33:03.392579: step 420900, loss = 0.011675, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-11 11:33:23.423798: step 421000, loss = 0.015174, learning_rate = 0.000000 (2577.9 examples/sec)
=> Model saved to file: ./logs_res/model-421000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:33:58.683427: step 421100, loss = 0.017783, learning_rate = 0.000000 (2665.5 examples/sec)
=> 2021-11-11 11:34:18.666364: step 421200, loss = 0.034241, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-11 11:34:38.688989: step 421300, loss = 0.039082, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 11:34:58.683373: step 421400, loss = 0.030494, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 11:35:19.603701: step 421500, loss = 0.018383, learning_rate = 0.000000 (2597.3 examples/sec)
=> 2021-11-11 11:35:39.591825: step 421600, loss = 0.017217, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-11 11:35:59.579214: step 421700, loss = 0.015347, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 11:36:19.646896: step 421800, loss = 0.036100, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 11:36:40.536700: step 421900, loss = 0.012999, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-11 11:37:00.477436: step 422000, loss = 0.011885, learning_rate = 0.000000 (2589.0 examples/sec)
=> Model saved to file: ./logs_res/model-422000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:37:32.635395: step 422100, loss = 0.034656, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-11 11:37:54.195458: step 422200, loss = 0.016375, learning_rate = 0.000000 (2672.5 examples/sec)
=> 2021-11-11 11:38:16.640003: step 422300, loss = 0.035303, learning_rate = 0.000000 (2691.3 examples/sec)
=> 2021-11-11 11:38:36.625472: step 422400, loss = 0.032560, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 11:38:56.551086: step 422500, loss = 0.043085, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-11 11:39:16.487604: step 422600, loss = 0.032496, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-11 11:39:37.440813: step 422700, loss = 0.015629, learning_rate = 0.000000 (2596.7 examples/sec)
=> 2021-11-11 11:39:57.390970: step 422800, loss = 0.019680, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-11 11:40:17.353933: step 422900, loss = 0.036695, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 11:40:37.329714: step 423000, loss = 0.016218, learning_rate = 0.000000 (2585.1 examples/sec)
=> Model saved to file: ./logs_res/model-423000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:41:09.396632: step 423100, loss = 0.021701, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 11:41:30.779595: step 423200, loss = 0.006817, learning_rate = 0.000000 (2638.9 examples/sec)
=> 2021-11-11 11:42:01.827960: step 423300, loss = 0.024434, learning_rate = 0.000000 (3075.6 examples/sec)
=> 2021-11-11 11:42:32.364123: step 423400, loss = 0.033338, learning_rate = 0.000000 (3068.5 examples/sec)
=> 2021-11-11 11:42:53.788109: step 423500, loss = 0.032493, learning_rate = 0.000000 (2679.6 examples/sec)
=> 2021-11-11 11:43:14.820666: step 423600, loss = 0.029739, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 11:43:35.343265: step 423700, loss = 0.013098, learning_rate = 0.000000 (2518.6 examples/sec)
=> 2021-11-11 11:43:55.502645: step 423800, loss = 0.027665, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 11:44:16.863278: step 423900, loss = 0.019431, learning_rate = 0.000000 (2422.2 examples/sec)
=> 2021-11-11 11:44:40.555172: step 424000, loss = 0.025329, learning_rate = 0.000000 (2776.7 examples/sec)
=> Model saved to file: ./logs_res/model-424000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:45:12.562888: step 424100, loss = 0.040563, learning_rate = 0.000000 (2596.2 examples/sec)
=> 2021-11-11 11:45:32.476345: step 424200, loss = 0.011619, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-11 11:45:52.869043: step 424300, loss = 0.036124, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-11 11:46:17.557928: step 424400, loss = 0.017353, learning_rate = 0.000000 (2812.0 examples/sec)
=> 2021-11-11 11:46:37.550134: step 424500, loss = 0.026179, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-11 11:46:57.514366: step 424600, loss = 0.034065, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 11:47:17.491903: step 424700, loss = 0.033430, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 11:47:38.441008: step 424800, loss = 0.026826, learning_rate = 0.000000 (2603.6 examples/sec)
=> 2021-11-11 11:47:58.409126: step 424900, loss = 0.021576, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 11:48:18.393469: step 425000, loss = 0.016119, learning_rate = 0.000000 (2584.0 examples/sec)
=> Model saved to file: ./logs_res/model-425000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:48:50.419874: step 425100, loss = 0.027121, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-11 11:49:11.291694: step 425200, loss = 0.011537, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-11 11:49:31.230373: step 425300, loss = 0.042707, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-11 11:49:51.165492: step 425400, loss = 0.010941, learning_rate = 0.000000 (2590.0 examples/sec)
=> 2021-11-11 11:50:11.119410: step 425500, loss = 0.015088, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 11:50:31.902670: step 425600, loss = 0.013854, learning_rate = 0.000000 (2603.4 examples/sec)
=> 2021-11-11 11:50:51.840430: step 425700, loss = 0.049306, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-11 11:51:11.797050: step 425800, loss = 0.029738, learning_rate = 0.000000 (2587.2 examples/sec)
=> 2021-11-11 11:51:31.751673: step 425900, loss = 0.020762, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-11 11:51:51.707553: step 426000, loss = 0.026167, learning_rate = 0.000000 (2588.0 examples/sec)
=> Model saved to file: ./logs_res/model-426000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:52:25.712212: step 426100, loss = 0.070304, learning_rate = 0.000000 (2646.8 examples/sec)
=> 2021-11-11 11:52:47.711795: step 426200, loss = 0.050074, learning_rate = 0.000000 (2694.4 examples/sec)
=> 2021-11-11 11:53:13.705750: step 426300, loss = 0.036066, learning_rate = 0.000000 (2886.3 examples/sec)
=> 2021-11-11 11:53:33.616430: step 426400, loss = 0.011552, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-11 11:53:55.127813: step 426500, loss = 0.029378, learning_rate = 0.000000 (2641.5 examples/sec)
=> 2021-11-11 11:54:20.067553: step 426600, loss = 0.017908, learning_rate = 0.000000 (2843.5 examples/sec)
=> 2021-11-11 11:54:40.805344: step 426700, loss = 0.026782, learning_rate = 0.000000 (2636.1 examples/sec)
=> 2021-11-11 11:55:10.185096: step 426800, loss = 0.030302, learning_rate = 0.000000 (3080.3 examples/sec)
=> 2021-11-11 11:55:33.990245: step 426900, loss = 0.046214, learning_rate = 0.000000 (2737.9 examples/sec)
=> 2021-11-11 11:56:00.305694: step 427000, loss = 0.019653, learning_rate = 0.000000 (2881.9 examples/sec)
=> Model saved to file: ./logs_res/model-427000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 11:56:35.007103: step 427100, loss = 0.062822, learning_rate = 0.000000 (2595.0 examples/sec)
=> 2021-11-11 11:56:54.899482: step 427200, loss = 0.018684, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-11 11:57:15.822190: step 427300, loss = 0.044508, learning_rate = 0.000000 (2608.7 examples/sec)
=> 2021-11-11 11:57:35.772032: step 427400, loss = 0.030988, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-11 11:57:55.771061: step 427500, loss = 0.012474, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 11:58:15.906866: step 427600, loss = 0.026239, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 11:58:37.024940: step 427700, loss = 0.022096, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-11 11:58:57.257167: step 427800, loss = 0.023544, learning_rate = 0.000000 (2609.2 examples/sec)
=> 2021-11-11 11:59:17.212761: step 427900, loss = 0.021723, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-11 11:59:37.171304: step 428000, loss = 0.016064, learning_rate = 0.000000 (2587.2 examples/sec)
=> Model saved to file: ./logs_res/model-428000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:00:10.225170: step 428100, loss = 0.025214, learning_rate = 0.000000 (2606.8 examples/sec)
=> 2021-11-11 12:00:30.129610: step 428200, loss = 0.023760, learning_rate = 0.000000 (2594.3 examples/sec)
=> 2021-11-11 12:00:50.041789: step 428300, loss = 0.014928, learning_rate = 0.000000 (2593.4 examples/sec)
=> 2021-11-11 12:01:11.671641: step 428400, loss = 0.046680, learning_rate = 0.000000 (2676.7 examples/sec)
=> 2021-11-11 12:01:34.036889: step 428500, loss = 0.015413, learning_rate = 0.000000 (2674.9 examples/sec)
=> 2021-11-11 12:01:53.962365: step 428600, loss = 0.021798, learning_rate = 0.000000 (2591.3 examples/sec)
=> 2021-11-11 12:02:13.914083: step 428700, loss = 0.032694, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 12:02:33.859989: step 428800, loss = 0.054741, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 12:02:53.806310: step 428900, loss = 0.014966, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-11 12:03:14.902189: step 429000, loss = 0.014996, learning_rate = 0.000000 (2600.3 examples/sec)
=> Model saved to file: ./logs_res/model-429000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:03:47.476425: step 429100, loss = 0.037193, learning_rate = 0.000000 (2532.6 examples/sec)
=> 2021-11-11 12:04:07.410100: step 429200, loss = 0.014870, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-11 12:04:28.711797: step 429300, loss = 0.027928, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-11 12:04:49.548743: step 429400, loss = 0.019093, learning_rate = 0.000000 (2601.6 examples/sec)
=> 2021-11-11 12:05:09.529470: step 429500, loss = 0.026011, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 12:05:29.510030: step 429600, loss = 0.044259, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 12:05:49.481912: step 429700, loss = 0.035249, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 12:06:10.413261: step 429800, loss = 0.037693, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-11 12:06:31.930290: step 429900, loss = 0.016234, learning_rate = 0.000000 (2671.1 examples/sec)
=> 2021-11-11 12:06:51.892060: step 430000, loss = 0.026940, learning_rate = 0.000000 (2586.7 examples/sec)
=> Model saved to file: ./logs_res/model-430000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:07:23.536693: step 430100, loss = 0.017270, learning_rate = 0.000000 (2595.2 examples/sec)
=> 2021-11-11 12:07:44.296104: step 430200, loss = 0.024376, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-11 12:08:04.204879: step 430300, loss = 0.018641, learning_rate = 0.000000 (2593.4 examples/sec)
=> 2021-11-11 12:08:24.149281: step 430400, loss = 0.014266, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-11 12:08:48.352338: step 430500, loss = 0.050832, learning_rate = 0.000000 (2746.7 examples/sec)
=> 2021-11-11 12:09:09.211102: step 430600, loss = 0.008403, learning_rate = 0.000000 (2603.1 examples/sec)
=> 2021-11-11 12:09:29.148457: step 430700, loss = 0.017826, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-11 12:09:49.097543: step 430800, loss = 0.019150, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-11 12:10:09.038088: step 430900, loss = 0.017398, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-11 12:10:30.028883: step 431000, loss = 0.011568, learning_rate = 0.000000 (2594.2 examples/sec)
=> Model saved to file: ./logs_res/model-431000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:11:01.663932: step 431100, loss = 0.034645, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-11 12:11:21.606103: step 431200, loss = 0.028616, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-11 12:11:41.554771: step 431300, loss = 0.031834, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 12:12:02.598652: step 431400, loss = 0.047876, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-11 12:12:22.541539: step 431500, loss = 0.023848, learning_rate = 0.000000 (2589.0 examples/sec)
=> 2021-11-11 12:12:43.010481: step 431600, loss = 0.038532, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-11 12:13:03.085815: step 431700, loss = 0.025220, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-11 12:13:23.051833: step 431800, loss = 0.030490, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 12:13:43.847896: step 431900, loss = 0.028593, learning_rate = 0.000000 (2602.3 examples/sec)
=> 2021-11-11 12:14:03.783773: step 432000, loss = 0.025080, learning_rate = 0.000000 (2589.8 examples/sec)
=> Model saved to file: ./logs_res/model-432000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:14:36.435455: step 432100, loss = 0.014662, learning_rate = 0.000000 (2517.7 examples/sec)
=> 2021-11-11 12:14:56.396472: step 432200, loss = 0.012596, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 12:15:17.209230: step 432300, loss = 0.052427, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-11 12:15:37.163108: step 432400, loss = 0.026016, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-11 12:15:57.101976: step 432500, loss = 0.028144, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-11 12:16:17.070266: step 432600, loss = 0.026480, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 12:16:37.872449: step 432700, loss = 0.020061, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-11 12:16:57.829638: step 432800, loss = 0.035841, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-11 12:17:17.782797: step 432900, loss = 0.053760, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 12:17:37.717461: step 433000, loss = 0.018095, learning_rate = 0.000000 (2590.1 examples/sec)
=> Model saved to file: ./logs_res/model-433000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:18:10.307137: step 433100, loss = 0.008041, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-11 12:18:30.232539: step 433200, loss = 0.069480, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-11 12:18:50.146431: step 433300, loss = 0.034243, learning_rate = 0.000000 (2592.7 examples/sec)
=> 2021-11-11 12:19:10.083832: step 433400, loss = 0.040928, learning_rate = 0.000000 (2589.6 examples/sec)
=> 2021-11-11 12:19:30.843316: step 433500, loss = 0.022310, learning_rate = 0.000000 (2606.4 examples/sec)
=> 2021-11-11 12:19:50.780453: step 433600, loss = 0.026934, learning_rate = 0.000000 (2589.7 examples/sec)
=> 2021-11-11 12:20:10.722300: step 433700, loss = 0.022496, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-11 12:20:30.730762: step 433800, loss = 0.028589, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 12:20:51.502968: step 433900, loss = 0.048607, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-11 12:21:11.467490: step 434000, loss = 0.017470, learning_rate = 0.000000 (2586.0 examples/sec)
=> Model saved to file: ./logs_res/model-434000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954852, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:21:43.332900: step 434100, loss = 0.024177, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-11 12:22:03.328620: step 434200, loss = 0.032268, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 12:22:24.134955: step 434300, loss = 0.042548, learning_rate = 0.000000 (2603.6 examples/sec)
=> 2021-11-11 12:22:44.149843: step 434400, loss = 0.026574, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 12:23:04.086532: step 434500, loss = 0.015037, learning_rate = 0.000000 (2590.1 examples/sec)
=> 2021-11-11 12:23:24.013342: step 434600, loss = 0.022617, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 12:23:43.953053: step 434700, loss = 0.016045, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-11 12:24:04.985239: step 434800, loss = 0.036552, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-11 12:24:24.924874: step 434900, loss = 0.023407, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-11 12:24:44.859906: step 435000, loss = 0.033843, learning_rate = 0.000000 (2589.9 examples/sec)
=> Model saved to file: ./logs_res/model-435000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:25:16.448369: step 435100, loss = 0.033233, learning_rate = 0.000000 (2597.0 examples/sec)
=> 2021-11-11 12:25:37.297807: step 435200, loss = 0.033728, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-11 12:25:57.256049: step 435300, loss = 0.014908, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-11 12:26:17.856462: step 435400, loss = 0.028004, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-11 12:26:42.303603: step 435500, loss = 0.029376, learning_rate = 0.000000 (2829.5 examples/sec)
=> 2021-11-11 12:27:03.420674: step 435600, loss = 0.039547, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 12:27:23.395619: step 435700, loss = 0.023583, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-11 12:27:43.378894: step 435800, loss = 0.024307, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 12:28:03.315810: step 435900, loss = 0.052427, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-11 12:28:24.130176: step 436000, loss = 0.029315, learning_rate = 0.000000 (2604.9 examples/sec)
=> Model saved to file: ./logs_res/model-436000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955158, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:28:56.238783: step 436100, loss = 0.011041, learning_rate = 0.000000 (2594.9 examples/sec)
=> 2021-11-11 12:29:16.215921: step 436200, loss = 0.021420, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 12:29:36.154036: step 436300, loss = 0.050227, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-11 12:29:56.968155: step 436400, loss = 0.037648, learning_rate = 0.000000 (2607.7 examples/sec)
=> 2021-11-11 12:30:17.003791: step 436500, loss = 0.030697, learning_rate = 0.000000 (2576.9 examples/sec)
=> 2021-11-11 12:30:36.962780: step 436600, loss = 0.020130, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 12:30:56.922048: step 436700, loss = 0.031168, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-11 12:31:22.815002: step 436800, loss = 0.030337, learning_rate = 0.000000 (2798.6 examples/sec)
=> 2021-11-11 12:31:42.749242: step 436900, loss = 0.020099, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-11 12:32:02.699755: step 437000, loss = 0.030906, learning_rate = 0.000000 (2588.7 examples/sec)
=> Model saved to file: ./logs_res/model-437000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:32:34.758518: step 437100, loss = 0.022969, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 12:32:55.557686: step 437200, loss = 0.010402, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-11 12:33:15.506143: step 437300, loss = 0.024647, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 12:33:35.457811: step 437400, loss = 0.053256, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-11 12:33:55.511159: step 437500, loss = 0.010478, learning_rate = 0.000000 (2576.3 examples/sec)
=> 2021-11-11 12:34:16.762269: step 437600, loss = 0.035134, learning_rate = 0.000000 (2596.0 examples/sec)
=> 2021-11-11 12:34:36.720254: step 437700, loss = 0.020712, learning_rate = 0.000000 (2587.2 examples/sec)
=> 2021-11-11 12:34:58.184439: step 437800, loss = 0.029731, learning_rate = 0.000000 (2655.3 examples/sec)
=> 2021-11-11 12:35:20.269594: step 437900, loss = 0.017421, learning_rate = 0.000000 (2676.6 examples/sec)
=> 2021-11-11 12:35:40.216600: step 438000, loss = 0.021191, learning_rate = 0.000000 (2588.6 examples/sec)
=> Model saved to file: ./logs_res/model-438000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:36:12.912239: step 438100, loss = 0.021795, learning_rate = 0.000000 (2603.8 examples/sec)
=> 2021-11-11 12:36:32.863040: step 438200, loss = 0.015242, learning_rate = 0.000000 (2588.2 examples/sec)
=> 2021-11-11 12:36:52.796885: step 438300, loss = 0.022906, learning_rate = 0.000000 (2590.2 examples/sec)
=> 2021-11-11 12:37:12.768893: step 438400, loss = 0.037721, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 12:37:33.936245: step 438500, loss = 0.048436, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-11 12:37:56.635075: step 438600, loss = 0.026110, learning_rate = 0.000000 (2489.9 examples/sec)
=> 2021-11-11 12:38:23.514038: step 438700, loss = 0.021864, learning_rate = 0.000000 (3071.6 examples/sec)
=> 2021-11-11 12:38:46.431272: step 438800, loss = 0.038240, learning_rate = 0.000000 (2747.9 examples/sec)
=> 2021-11-11 12:39:07.275004: step 438900, loss = 0.042974, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-11 12:39:27.228401: step 439000, loss = 0.026744, learning_rate = 0.000000 (2587.9 examples/sec)
=> Model saved to file: ./logs_res/model-439000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:39:59.173663: step 439100, loss = 0.019050, learning_rate = 0.000000 (2592.1 examples/sec)
=> 2021-11-11 12:40:19.103947: step 439200, loss = 0.010999, learning_rate = 0.000000 (2590.8 examples/sec)
=> 2021-11-11 12:40:40.318113: step 439300, loss = 0.022539, learning_rate = 0.000000 (2597.0 examples/sec)
=> 2021-11-11 12:41:00.249692: step 439400, loss = 0.035740, learning_rate = 0.000000 (2590.7 examples/sec)
=> 2021-11-11 12:41:20.188618: step 439500, loss = 0.018288, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-11 12:41:40.135201: step 439600, loss = 0.018943, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-11 12:42:01.033081: step 439700, loss = 0.024124, learning_rate = 0.000000 (2606.0 examples/sec)
=> 2021-11-11 12:42:20.964688: step 439800, loss = 0.024819, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-11 12:42:40.903572: step 439900, loss = 0.033455, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-11 12:43:00.854063: step 440000, loss = 0.023382, learning_rate = 0.000000 (2588.4 examples/sec)
=> Model saved to file: ./logs_res/model-440000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955464
=> patience = 99
=> 2021-11-11 12:43:33.745729: step 440100, loss = 0.018744, learning_rate = 0.000000 (2607.7 examples/sec)
=> 2021-11-11 12:43:53.648367: step 440200, loss = 0.019553, learning_rate = 0.000000 (2594.3 examples/sec)
=> 2021-11-11 12:44:13.570569: step 440300, loss = 0.017687, learning_rate = 0.000000 (2591.7 examples/sec)
=> 2021-11-11 12:44:33.494318: step 440400, loss = 0.020423, learning_rate = 0.000000 (2591.5 examples/sec)
=> 2021-11-11 12:44:54.439675: step 440500, loss = 0.023882, learning_rate = 0.000000 (2605.2 examples/sec)
=> 2021-11-11 12:45:14.396910: step 440600, loss = 0.018646, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 12:45:34.352773: step 440700, loss = 0.028977, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 12:45:54.288921: step 440800, loss = 0.044436, learning_rate = 0.000000 (2596.4 examples/sec)
=> 2021-11-11 12:46:14.234880: step 440900, loss = 0.043636, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-11 12:46:35.101531: step 441000, loss = 0.012450, learning_rate = 0.000000 (2596.7 examples/sec)
=> Model saved to file: ./logs_res/model-441000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955923, best accuracy 0.955464
=> Model saved to file: ./logs_res/model-441000.pdparams
=> patience = 100
=> 2021-11-11 12:47:08.179436: step 441100, loss = 0.019391, learning_rate = 0.000000 (2597.3 examples/sec)
=> 2021-11-11 12:47:28.098364: step 441200, loss = 0.037208, learning_rate = 0.000000 (2591.9 examples/sec)
=> 2021-11-11 12:47:48.015990: step 441300, loss = 0.027352, learning_rate = 0.000000 (2592.0 examples/sec)
=> 2021-11-11 12:48:08.792759: step 441400, loss = 0.030321, learning_rate = 0.000000 (2607.3 examples/sec)
=> 2021-11-11 12:48:28.749945: step 441500, loss = 0.013186, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 12:48:48.687932: step 441600, loss = 0.023163, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-11 12:49:08.627020: step 441700, loss = 0.026614, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-11 12:49:29.566648: step 441800, loss = 0.019589, learning_rate = 0.000000 (2593.6 examples/sec)
=> 2021-11-11 12:49:49.514688: step 441900, loss = 0.026769, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 12:50:09.449132: step 442000, loss = 0.010280, learning_rate = 0.000000 (2590.3 examples/sec)
=> Model saved to file: ./logs_res/model-442000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 12:50:41.168547: step 442100, loss = 0.016774, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 12:51:02.902989: step 442200, loss = 0.016686, learning_rate = 0.000000 (2647.1 examples/sec)
=> 2021-11-11 12:51:23.970937: step 442300, loss = 0.013071, learning_rate = 0.000000 (2657.9 examples/sec)
=> 2021-11-11 12:51:43.949628: step 442400, loss = 0.023809, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 12:52:03.947369: step 442500, loss = 0.026342, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 12:52:24.832132: step 442600, loss = 0.025208, learning_rate = 0.000000 (2598.3 examples/sec)
=> 2021-11-11 12:52:44.808820: step 442700, loss = 0.028604, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 12:53:04.794872: step 442800, loss = 0.032452, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 12:53:24.813569: step 442900, loss = 0.039005, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 12:53:45.649297: step 443000, loss = 0.032222, learning_rate = 0.000000 (2602.7 examples/sec)
=> Model saved to file: ./logs_res/model-443000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 12:54:18.387517: step 443100, loss = 0.047236, learning_rate = 0.000000 (2544.4 examples/sec)
=> 2021-11-11 12:54:38.318013: step 443200, loss = 0.039789, learning_rate = 0.000000 (2591.0 examples/sec)
=> 2021-11-11 12:54:58.246444: step 443300, loss = 0.027217, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 12:55:19.003553: step 443400, loss = 0.014000, learning_rate = 0.000000 (2607.2 examples/sec)
=> 2021-11-11 12:55:38.963217: step 443500, loss = 0.015580, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-11 12:55:59.085397: step 443600, loss = 0.014827, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 12:56:19.037630: step 443700, loss = 0.038883, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 12:56:39.016999: step 443800, loss = 0.034246, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 12:57:10.038260: step 443900, loss = 0.011398, learning_rate = 0.000000 (3026.5 examples/sec)
=> 2021-11-11 12:57:32.799336: step 444000, loss = 0.022690, learning_rate = 0.000000 (2710.2 examples/sec)
=> Model saved to file: ./logs_res/model-444000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 12:58:06.841551: step 444100, loss = 0.023309, learning_rate = 0.000000 (2672.2 examples/sec)
=> 2021-11-11 12:58:29.047324: step 444200, loss = 0.017489, learning_rate = 0.000000 (2681.0 examples/sec)
=> 2021-11-11 12:58:49.972923: step 444300, loss = 0.014211, learning_rate = 0.000000 (2605.7 examples/sec)
=> 2021-11-11 12:59:09.931567: step 444400, loss = 0.029054, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-11 12:59:29.924037: step 444500, loss = 0.032440, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-11 12:59:49.949822: step 444600, loss = 0.026867, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 13:00:10.787224: step 444700, loss = 0.035714, learning_rate = 0.000000 (2601.5 examples/sec)
=> 2021-11-11 13:00:33.816057: step 444800, loss = 0.039660, learning_rate = 0.000000 (2700.5 examples/sec)
=> 2021-11-11 13:00:54.707485: step 444900, loss = 0.037647, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-11 13:01:14.680045: step 445000, loss = 0.022042, learning_rate = 0.000000 (2585.2 examples/sec)
=> Model saved to file: ./logs_res/model-445000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:01:47.857295: step 445100, loss = 0.015809, learning_rate = 0.000000 (2607.7 examples/sec)
=> 2021-11-11 13:02:07.785587: step 445200, loss = 0.026524, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-11 13:02:27.738763: step 445300, loss = 0.056538, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 13:02:50.149812: step 445400, loss = 0.023274, learning_rate = 0.000000 (2750.4 examples/sec)
=> 2021-11-11 13:03:10.946070: step 445500, loss = 0.038568, learning_rate = 0.000000 (2604.5 examples/sec)
=> 2021-11-11 13:03:30.996636: step 445600, loss = 0.047001, learning_rate = 0.000000 (2575.3 examples/sec)
=> 2021-11-11 13:03:51.885884: step 445700, loss = 0.024635, learning_rate = 0.000000 (2635.0 examples/sec)
=> 2021-11-11 13:04:13.489173: step 445800, loss = 0.012408, learning_rate = 0.000000 (2668.9 examples/sec)
=> 2021-11-11 13:04:34.388945: step 445900, loss = 0.068126, learning_rate = 0.000000 (2604.2 examples/sec)
=> 2021-11-11 13:04:54.324127: step 446000, loss = 0.016416, learning_rate = 0.000000 (2589.9 examples/sec)
=> Model saved to file: ./logs_res/model-446000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:05:26.075091: step 446100, loss = 0.022531, learning_rate = 0.000000 (2592.4 examples/sec)
=> 2021-11-11 13:05:46.029002: step 446200, loss = 0.016416, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-11 13:06:06.840619: step 446300, loss = 0.008647, learning_rate = 0.000000 (2601.7 examples/sec)
=> 2021-11-11 13:06:26.806234: step 446400, loss = 0.011344, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-11 13:06:46.771134: step 446500, loss = 0.052227, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 13:07:06.758819: step 446600, loss = 0.030574, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 13:07:26.832839: step 446700, loss = 0.019494, learning_rate = 0.000000 (2573.9 examples/sec)
=> 2021-11-11 13:07:47.820244: step 446800, loss = 0.028171, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-11 13:08:07.785656: step 446900, loss = 0.014349, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 13:08:27.755962: step 447000, loss = 0.026835, learning_rate = 0.000000 (2585.7 examples/sec)
=> Model saved to file: ./logs_res/model-447000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:08:59.641116: step 447100, loss = 0.027734, learning_rate = 0.000000 (2593.1 examples/sec)
=> 2021-11-11 13:09:22.679425: step 447200, loss = 0.031901, learning_rate = 0.000000 (2713.9 examples/sec)
=> 2021-11-11 13:09:44.189726: step 447300, loss = 0.031988, learning_rate = 0.000000 (2667.9 examples/sec)
=> 2021-11-11 13:10:04.129019: step 447400, loss = 0.017065, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-11 13:10:24.081896: step 447500, loss = 0.011058, learning_rate = 0.000000 (2587.8 examples/sec)
=> 2021-11-11 13:10:46.302320: step 447600, loss = 0.012376, learning_rate = 0.000000 (2648.9 examples/sec)
=> 2021-11-11 13:11:06.248745: step 447700, loss = 0.024964, learning_rate = 0.000000 (2588.7 examples/sec)
=> 2021-11-11 13:11:26.188228: step 447800, loss = 0.045747, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-11 13:11:46.190533: step 447900, loss = 0.010221, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 13:12:07.747271: step 448000, loss = 0.021107, learning_rate = 0.000000 (2626.0 examples/sec)
=> Model saved to file: ./logs_res/model-448000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954469, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:12:39.764925: step 448100, loss = 0.018674, learning_rate = 0.000000 (2593.1 examples/sec)
=> 2021-11-11 13:12:59.711302: step 448200, loss = 0.021179, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-11 13:13:19.675102: step 448300, loss = 0.035248, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 13:13:40.621169: step 448400, loss = 0.015452, learning_rate = 0.000000 (2602.6 examples/sec)
=> 2021-11-11 13:14:00.557186: step 448500, loss = 0.014527, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-11 13:14:20.502504: step 448600, loss = 0.018767, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-11 13:14:40.456339: step 448700, loss = 0.020448, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 13:15:01.238022: step 448800, loss = 0.020281, learning_rate = 0.000000 (2605.0 examples/sec)
=> 2021-11-11 13:15:21.287652: step 448900, loss = 0.028417, learning_rate = 0.000000 (2575.1 examples/sec)
=> 2021-11-11 13:15:41.266638: step 449000, loss = 0.020596, learning_rate = 0.000000 (2584.9 examples/sec)
=> Model saved to file: ./logs_res/model-449000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:16:13.749795: step 449100, loss = 0.017056, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-11 13:16:34.766775: step 449200, loss = 0.042867, learning_rate = 0.000000 (2607.0 examples/sec)
=> 2021-11-11 13:16:54.730634: step 449300, loss = 0.025496, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 13:17:14.687330: step 449400, loss = 0.033897, learning_rate = 0.000000 (2587.5 examples/sec)
=> 2021-11-11 13:17:34.663668: step 449500, loss = 0.046660, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 13:17:54.608082: step 449600, loss = 0.047793, learning_rate = 0.000000 (2589.5 examples/sec)
=> 2021-11-11 13:18:15.401661: step 449700, loss = 0.014644, learning_rate = 0.000000 (2604.5 examples/sec)
=> 2021-11-11 13:18:35.333329: step 449800, loss = 0.027755, learning_rate = 0.000000 (2590.6 examples/sec)
=> 2021-11-11 13:18:55.292243: step 449900, loss = 0.026593, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 13:19:15.256699: step 450000, loss = 0.010770, learning_rate = 0.000000 (2586.3 examples/sec)
=> Model saved to file: ./logs_res/model-450000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:19:48.174721: step 450100, loss = 0.027954, learning_rate = 0.000000 (2605.0 examples/sec)
=> 2021-11-11 13:20:08.144984: step 450200, loss = 0.030047, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 13:20:28.109041: step 450300, loss = 0.025589, learning_rate = 0.000000 (2586.9 examples/sec)
=> 2021-11-11 13:20:48.072027: step 450400, loss = 0.036184, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 13:21:08.974907: step 450500, loss = 0.020252, learning_rate = 0.000000 (2604.7 examples/sec)
=> 2021-11-11 13:21:28.982182: step 450600, loss = 0.023688, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 13:21:49.119795: step 450700, loss = 0.026012, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 13:22:09.244813: step 450800, loss = 0.013263, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 13:22:30.630906: step 450900, loss = 0.019780, learning_rate = 0.000000 (2643.9 examples/sec)
=> 2021-11-11 13:22:51.067057: step 451000, loss = 0.033080, learning_rate = 0.000000 (2532.3 examples/sec)
=> Model saved to file: ./logs_res/model-451000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:23:26.959111: step 451100, loss = 0.023728, learning_rate = 0.000000 (2596.0 examples/sec)
=> 2021-11-11 13:23:46.878692: step 451200, loss = 0.045866, learning_rate = 0.000000 (2592.2 examples/sec)
=> 2021-11-11 13:24:07.784315: step 451300, loss = 0.018056, learning_rate = 0.000000 (2611.8 examples/sec)
=> 2021-11-11 13:24:27.746076: step 451400, loss = 0.024796, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-11 13:24:47.684784: step 451500, loss = 0.032458, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-11 13:25:07.673462: step 451600, loss = 0.024294, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 13:25:29.040024: step 451700, loss = 0.018295, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-11 13:25:48.989046: step 451800, loss = 0.045116, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-11 13:26:08.996439: step 451900, loss = 0.019117, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 13:26:29.186532: step 452000, loss = 0.030367, learning_rate = 0.000000 (2620.1 examples/sec)
=> Model saved to file: ./logs_res/model-452000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:27:02.437732: step 452100, loss = 0.023690, learning_rate = 0.000000 (2603.2 examples/sec)
=> 2021-11-11 13:27:22.370407: step 452200, loss = 0.021920, learning_rate = 0.000000 (2591.2 examples/sec)
=> 2021-11-11 13:27:42.317860: step 452300, loss = 0.020141, learning_rate = 0.000000 (2588.4 examples/sec)
=> 2021-11-11 13:28:02.247165: step 452400, loss = 0.010976, learning_rate = 0.000000 (2590.9 examples/sec)
=> 2021-11-11 13:28:22.193513: step 452500, loss = 0.038762, learning_rate = 0.000000 (2589.3 examples/sec)
=> 2021-11-11 13:28:43.091398: step 452600, loss = 0.019439, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-11 13:29:03.049371: step 452700, loss = 0.026421, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 13:29:23.016808: step 452800, loss = 0.021071, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 13:29:43.553314: step 452900, loss = 0.041285, learning_rate = 0.000000 (2517.0 examples/sec)
=> 2021-11-11 13:30:06.172215: step 453000, loss = 0.035063, learning_rate = 0.000000 (2643.9 examples/sec)
=> Model saved to file: ./logs_res/model-453000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:30:41.755948: step 453100, loss = 0.019279, learning_rate = 0.000000 (2802.3 examples/sec)
=> 2021-11-11 13:31:03.964256: step 453200, loss = 0.014559, learning_rate = 0.000000 (2719.1 examples/sec)
=> 2021-11-11 13:31:23.901055: step 453300, loss = 0.014463, learning_rate = 0.000000 (2590.3 examples/sec)
=> 2021-11-11 13:31:44.972636: step 453400, loss = 0.008491, learning_rate = 0.000000 (2607.5 examples/sec)
=> 2021-11-11 13:32:04.923065: step 453500, loss = 0.019210, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 13:32:24.903920: step 453600, loss = 0.025606, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-11 13:32:47.199934: step 453700, loss = 0.016772, learning_rate = 0.000000 (2723.7 examples/sec)
=> 2021-11-11 13:33:08.164299: step 453800, loss = 0.015293, learning_rate = 0.000000 (2604.6 examples/sec)
=> 2021-11-11 13:33:28.118705: step 453900, loss = 0.027871, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 13:33:48.088350: step 454000, loss = 0.019728, learning_rate = 0.000000 (2585.9 examples/sec)
=> Model saved to file: ./logs_res/model-454000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:34:19.999912: step 454100, loss = 0.015646, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-11 13:34:40.815258: step 454200, loss = 0.062108, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-11 13:35:00.771312: step 454300, loss = 0.024215, learning_rate = 0.000000 (2587.7 examples/sec)
=> 2021-11-11 13:35:20.697518: step 454400, loss = 0.013439, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-11 13:35:40.644217: step 454500, loss = 0.041930, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 13:36:01.626840: step 454600, loss = 0.012383, learning_rate = 0.000000 (2605.8 examples/sec)
=> 2021-11-11 13:36:21.589905: step 454700, loss = 0.036832, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 13:36:41.558671: step 454800, loss = 0.015619, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 13:37:02.646195: step 454900, loss = 0.060164, learning_rate = 0.000000 (2653.5 examples/sec)
=> 2021-11-11 13:37:23.508880: step 455000, loss = 0.037914, learning_rate = 0.000000 (2597.4 examples/sec)
=> Model saved to file: ./logs_res/model-455000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:37:55.802678: step 455100, loss = 0.012281, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 13:38:15.796683: step 455200, loss = 0.022670, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 13:38:35.837730: step 455300, loss = 0.012371, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 13:38:55.881129: step 455400, loss = 0.015723, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 13:39:16.934621: step 455500, loss = 0.009951, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 13:39:37.937879: step 455600, loss = 0.034114, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-11 13:40:08.624309: step 455700, loss = 0.031422, learning_rate = 0.000000 (3028.3 examples/sec)
=> 2021-11-11 13:40:36.653762: step 455800, loss = 0.036439, learning_rate = 0.000000 (2970.8 examples/sec)
=> 2021-11-11 13:40:57.562894: step 455900, loss = 0.035505, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-11 13:41:17.638405: step 456000, loss = 0.026220, learning_rate = 0.000000 (2572.0 examples/sec)
=> Model saved to file: ./logs_res/model-456000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954469, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:41:49.685500: step 456100, loss = 0.025337, learning_rate = 0.000000 (2574.9 examples/sec)
=> 2021-11-11 13:42:09.772333: step 456200, loss = 0.032274, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-11 13:42:30.717063: step 456300, loss = 0.041401, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 13:42:50.871676: step 456400, loss = 0.014236, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 13:43:11.070459: step 456500, loss = 0.029210, learning_rate = 0.000000 (2556.4 examples/sec)
=> 2021-11-11 13:43:31.246343: step 456600, loss = 0.058806, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 13:43:52.616539: step 456700, loss = 0.035019, learning_rate = 0.000000 (2543.5 examples/sec)
=> 2021-11-11 13:44:13.389378: step 456800, loss = 0.026360, learning_rate = 0.000000 (2592.3 examples/sec)
=> 2021-11-11 13:44:33.525106: step 456900, loss = 0.019806, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 13:44:53.660802: step 457000, loss = 0.023925, learning_rate = 0.000000 (2564.2 examples/sec)
=> Model saved to file: ./logs_res/model-457000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:45:27.046567: step 457100, loss = 0.018447, learning_rate = 0.000000 (2595.4 examples/sec)
=> 2021-11-11 13:45:47.183422: step 457200, loss = 0.010092, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 13:46:07.290380: step 457300, loss = 0.011057, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 13:46:27.428939: step 457400, loss = 0.041709, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 13:46:48.481781: step 457500, loss = 0.058438, learning_rate = 0.000000 (2591.4 examples/sec)
=> 2021-11-11 13:47:08.584364: step 457600, loss = 0.017902, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 13:47:28.691279: step 457700, loss = 0.014454, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 13:47:48.804250: step 457800, loss = 0.049990, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 13:48:09.750020: step 457900, loss = 0.012811, learning_rate = 0.000000 (2597.2 examples/sec)
=> 2021-11-11 13:48:31.314080: step 458000, loss = 0.026602, learning_rate = 0.000000 (2615.6 examples/sec)
=> Model saved to file: ./logs_res/model-458000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954469, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:49:04.212311: step 458100, loss = 0.017163, learning_rate = 0.000000 (2604.9 examples/sec)
=> 2021-11-11 13:49:33.570792: step 458200, loss = 0.066671, learning_rate = 0.000000 (3049.2 examples/sec)
=> 2021-11-11 13:49:54.569647: step 458300, loss = 0.025487, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 13:50:14.672380: step 458400, loss = 0.048090, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 13:50:34.807814: step 458500, loss = 0.030685, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 13:50:54.940598: step 458600, loss = 0.019583, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 13:51:15.057469: step 458700, loss = 0.021607, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 13:51:36.051430: step 458800, loss = 0.043385, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 13:51:56.158774: step 458900, loss = 0.023128, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 13:52:16.265818: step 459000, loss = 0.037787, learning_rate = 0.000000 (2567.8 examples/sec)
=> Model saved to file: ./logs_res/model-459000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:52:48.218056: step 459100, loss = 0.026761, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 13:53:09.304907: step 459200, loss = 0.019291, learning_rate = 0.000000 (2596.0 examples/sec)
=> 2021-11-11 13:53:29.419343: step 459300, loss = 0.028244, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 13:53:49.822843: step 459400, loss = 0.016010, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-11 13:54:09.952486: step 459500, loss = 0.041782, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 13:54:30.935655: step 459600, loss = 0.030041, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 13:54:51.062655: step 459700, loss = 0.024959, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 13:55:11.212884: step 459800, loss = 0.025903, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 13:55:31.334873: step 459900, loss = 0.015938, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 13:55:52.315707: step 460000, loss = 0.023021, learning_rate = 0.000000 (2580.2 examples/sec)
=> Model saved to file: ./logs_res/model-460000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:56:24.491722: step 460100, loss = 0.051798, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 13:56:44.584369: step 460200, loss = 0.007126, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 13:57:04.696793: step 460300, loss = 0.033391, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 13:57:25.679921: step 460400, loss = 0.015847, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 13:57:45.810029: step 460500, loss = 0.016749, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 13:58:05.939591: step 460600, loss = 0.014557, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 13:58:26.073926: step 460700, loss = 0.023382, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 13:58:47.060148: step 460800, loss = 0.035303, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-11 13:59:07.288866: step 460900, loss = 0.033685, learning_rate = 0.000000 (2552.4 examples/sec)
=> 2021-11-11 13:59:27.720458: step 461000, loss = 0.017236, learning_rate = 0.000000 (2527.1 examples/sec)
=> Model saved to file: ./logs_res/model-461000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 13:59:59.616934: step 461100, loss = 0.024319, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 14:00:22.508689: step 461200, loss = 0.012421, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-11 14:00:46.214621: step 461300, loss = 0.030564, learning_rate = 0.000000 (2764.2 examples/sec)
=> 2021-11-11 14:01:06.312337: step 461400, loss = 0.029306, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 14:01:26.428467: step 461500, loss = 0.022893, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 14:01:46.559698: step 461600, loss = 0.037835, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 14:02:07.497737: step 461700, loss = 0.032273, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 14:02:27.610233: step 461800, loss = 0.014290, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 14:02:47.747502: step 461900, loss = 0.022131, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 14:03:07.888212: step 462000, loss = 0.019081, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-462000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:03:40.655628: step 462100, loss = 0.013058, learning_rate = 0.000000 (2585.6 examples/sec)
=> 2021-11-11 14:04:00.759145: step 462200, loss = 0.030591, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 14:04:20.862322: step 462300, loss = 0.013906, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 14:04:40.986650: step 462400, loss = 0.024229, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 14:05:02.125622: step 462500, loss = 0.033383, learning_rate = 0.000000 (2578.7 examples/sec)
=> 2021-11-11 14:05:22.236436: step 462600, loss = 0.014340, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 14:05:42.336602: step 462700, loss = 0.028346, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 14:06:02.463120: step 462800, loss = 0.043879, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 14:06:23.412264: step 462900, loss = 0.014312, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 14:06:43.547640: step 463000, loss = 0.025908, learning_rate = 0.000000 (2564.0 examples/sec)
=> Model saved to file: ./logs_res/model-463000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:07:15.573141: step 463100, loss = 0.025422, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 14:07:35.679466: step 463200, loss = 0.037890, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 14:07:56.794197: step 463300, loss = 0.015307, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-11 14:08:16.903559: step 463400, loss = 0.029394, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 14:08:36.991395: step 463500, loss = 0.028658, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 14:08:57.087929: step 463600, loss = 0.025877, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 14:09:18.056256: step 463700, loss = 0.039980, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 14:09:38.160633: step 463800, loss = 0.016806, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 14:09:58.269439: step 463900, loss = 0.073548, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 14:10:18.397881: step 464000, loss = 0.014028, learning_rate = 0.000000 (2565.1 examples/sec)
=> Model saved to file: ./logs_res/model-464000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954928, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:10:51.004989: step 464100, loss = 0.027817, learning_rate = 0.000000 (2587.6 examples/sec)
=> 2021-11-11 14:11:11.143234: step 464200, loss = 0.014560, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 14:11:31.242303: step 464300, loss = 0.019911, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 14:11:51.350081: step 464400, loss = 0.020100, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 14:12:11.499947: step 464500, loss = 0.012946, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 14:12:32.581191: step 464600, loss = 0.012665, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 14:12:52.716770: step 464700, loss = 0.015183, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 14:13:12.851894: step 464800, loss = 0.032520, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 14:13:33.005298: step 464900, loss = 0.016523, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 14:13:54.017421: step 465000, loss = 0.031353, learning_rate = 0.000000 (2579.2 examples/sec)
=> Model saved to file: ./logs_res/model-465000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950566, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:14:25.886658: step 465100, loss = 0.021014, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 14:14:45.990487: step 465200, loss = 0.023241, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 14:15:06.127572: step 465300, loss = 0.035977, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 14:15:27.122291: step 465400, loss = 0.019290, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 14:15:47.254173: step 465500, loss = 0.022505, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 14:16:07.397097: step 465600, loss = 0.026786, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 14:16:27.547604: step 465700, loss = 0.048864, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 14:16:48.503426: step 465800, loss = 0.027005, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 14:17:08.624861: step 465900, loss = 0.051792, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 14:17:28.764548: step 466000, loss = 0.019698, learning_rate = 0.000000 (2563.5 examples/sec)
=> Model saved to file: ./logs_res/model-466000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:18:00.866082: step 466100, loss = 0.025638, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 14:18:21.824123: step 466200, loss = 0.020396, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 14:18:41.948365: step 466300, loss = 0.020661, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 14:19:02.035219: step 466400, loss = 0.028218, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 14:19:22.143884: step 466500, loss = 0.054478, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 14:19:43.165769: step 466600, loss = 0.031202, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 14:20:03.261142: step 466700, loss = 0.011050, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 14:20:23.378414: step 466800, loss = 0.023553, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 14:20:43.508133: step 466900, loss = 0.032845, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 14:21:04.509540: step 467000, loss = 0.017278, learning_rate = 0.000000 (2574.8 examples/sec)
=> Model saved to file: ./logs_res/model-467000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955081, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:21:36.536812: step 467100, loss = 0.029020, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-11 14:21:56.627580: step 467200, loss = 0.028712, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 14:22:16.727568: step 467300, loss = 0.039317, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 14:22:36.845104: step 467400, loss = 0.046092, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 14:22:57.883944: step 467500, loss = 0.046234, learning_rate = 0.000000 (2576.7 examples/sec)
=> 2021-11-11 14:23:17.997291: step 467600, loss = 0.026053, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 14:23:38.091324: step 467700, loss = 0.078802, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 14:23:58.205568: step 467800, loss = 0.009856, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 14:24:19.136034: step 467900, loss = 0.050467, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 14:24:39.258537: step 468000, loss = 0.018257, learning_rate = 0.000000 (2566.8 examples/sec)
=> Model saved to file: ./logs_res/model-468000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:25:11.329624: step 468100, loss = 0.043558, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-11 14:25:31.415886: step 468200, loss = 0.015650, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 14:25:52.510935: step 468300, loss = 0.011920, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 14:26:12.685423: step 468400, loss = 0.027733, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 14:26:32.799674: step 468500, loss = 0.005317, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 14:26:52.926469: step 468600, loss = 0.029095, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 14:27:13.905972: step 468700, loss = 0.022037, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 14:27:34.035717: step 468800, loss = 0.027744, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 14:27:54.159489: step 468900, loss = 0.021238, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 14:28:14.294208: step 469000, loss = 0.032869, learning_rate = 0.000000 (2564.3 examples/sec)
=> Model saved to file: ./logs_res/model-469000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955081, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:28:46.823591: step 469100, loss = 0.065366, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 14:29:06.934552: step 469200, loss = 0.028097, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 14:29:27.027273: step 469300, loss = 0.020691, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 14:29:47.114202: step 469400, loss = 0.039749, learning_rate = 0.000000 (2570.5 examples/sec)
=> 2021-11-11 14:30:08.059215: step 469500, loss = 0.038195, learning_rate = 0.000000 (2588.0 examples/sec)
=> 2021-11-11 14:30:28.166101: step 469600, loss = 0.020060, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 14:30:48.261098: step 469700, loss = 0.027503, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 14:31:08.361777: step 469800, loss = 0.010968, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 14:31:29.463871: step 469900, loss = 0.030752, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 14:31:49.570113: step 470000, loss = 0.029923, learning_rate = 0.000000 (2568.4 examples/sec)
=> Model saved to file: ./logs_res/model-470000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:32:21.922462: step 470100, loss = 0.033007, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 14:32:42.010720: step 470200, loss = 0.011240, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 14:33:02.107891: step 470300, loss = 0.044207, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 14:33:23.047480: step 470400, loss = 0.025903, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-11 14:33:43.161963: step 470500, loss = 0.029370, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 14:34:03.288662: step 470600, loss = 0.020917, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 14:34:23.436919: step 470700, loss = 0.037873, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 14:34:44.526857: step 470800, loss = 0.023841, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 14:35:04.624637: step 470900, loss = 0.029094, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 14:35:24.754538: step 471000, loss = 0.037022, learning_rate = 0.000000 (2564.8 examples/sec)
=> Model saved to file: ./logs_res/model-471000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:35:56.921549: step 471100, loss = 0.052402, learning_rate = 0.000000 (2572.1 examples/sec)
=> 2021-11-11 14:36:17.882563: step 471200, loss = 0.011526, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 14:36:38.007193: step 471300, loss = 0.010811, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 14:36:58.153451: step 471400, loss = 0.017640, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 14:37:18.307600: step 471500, loss = 0.031450, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 14:37:39.303665: step 471600, loss = 0.036308, learning_rate = 0.000000 (2587.0 examples/sec)
=> 2021-11-11 14:37:59.454014: step 471700, loss = 0.051365, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 14:38:19.591184: step 471800, loss = 0.018916, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 14:38:39.729640: step 471900, loss = 0.042051, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 14:39:00.704648: step 472000, loss = 0.045217, learning_rate = 0.000000 (2580.9 examples/sec)
=> Model saved to file: ./logs_res/model-472000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:39:32.756847: step 472100, loss = 0.012267, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-11 14:39:52.842225: step 472200, loss = 0.018640, learning_rate = 0.000000 (2570.6 examples/sec)
=> 2021-11-11 14:40:12.959926: step 472300, loss = 0.017557, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 14:40:33.882322: step 472400, loss = 0.012531, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 14:40:54.005584: step 472500, loss = 0.053042, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 14:41:14.112674: step 472600, loss = 0.014968, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 14:41:34.235089: step 472700, loss = 0.050343, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 14:41:55.261114: step 472800, loss = 0.011120, learning_rate = 0.000000 (2577.9 examples/sec)
=> 2021-11-11 14:42:15.411624: step 472900, loss = 0.043409, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 14:42:35.561791: step 473000, loss = 0.014933, learning_rate = 0.000000 (2562.2 examples/sec)
=> Model saved to file: ./logs_res/model-473000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:43:07.565348: step 473100, loss = 0.029379, learning_rate = 0.000000 (2557.8 examples/sec)
=> 2021-11-11 14:43:27.687426: step 473200, loss = 0.024139, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 14:43:48.664233: step 473300, loss = 0.022961, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 14:44:08.820928: step 473400, loss = 0.022786, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 14:44:28.947341: step 473500, loss = 0.030909, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 14:44:49.078827: step 473600, loss = 0.042098, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 14:45:10.046727: step 473700, loss = 0.043203, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-11 14:45:30.179955: step 473800, loss = 0.022970, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 14:45:50.310835: step 473900, loss = 0.041139, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 14:46:10.444170: step 474000, loss = 0.023974, learning_rate = 0.000000 (2564.6 examples/sec)
=> Model saved to file: ./logs_res/model-474000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955234, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:46:43.496141: step 474100, loss = 0.016907, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-11 14:47:03.646432: step 474200, loss = 0.028538, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 14:47:23.781973: step 474300, loss = 0.025265, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 14:47:43.922060: step 474400, loss = 0.022245, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 14:48:05.016249: step 474500, loss = 0.031293, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 14:48:25.154689: step 474600, loss = 0.015094, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 14:48:45.294254: step 474700, loss = 0.027915, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 14:49:05.405861: step 474800, loss = 0.038139, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 14:49:26.352272: step 474900, loss = 0.013304, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 14:49:46.484371: step 475000, loss = 0.025990, learning_rate = 0.000000 (2566.1 examples/sec)
=> Model saved to file: ./logs_res/model-475000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:50:18.503811: step 475100, loss = 0.018554, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-11 14:50:38.606477: step 475200, loss = 0.070030, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 14:50:59.567067: step 475300, loss = 0.025708, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 14:51:19.684752: step 475400, loss = 0.032871, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 14:51:39.855625: step 475500, loss = 0.030261, learning_rate = 0.000000 (2560.2 examples/sec)
=> 2021-11-11 14:51:59.962980: step 475600, loss = 0.017010, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 14:52:21.018158: step 475700, loss = 0.007821, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 14:52:41.151683: step 475800, loss = 0.035738, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 14:53:01.277520: step 475900, loss = 0.031053, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 14:53:21.423464: step 476000, loss = 0.026834, learning_rate = 0.000000 (2562.8 examples/sec)
=> Model saved to file: ./logs_res/model-476000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:53:53.248667: step 476100, loss = 0.032702, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 14:54:14.336763: step 476200, loss = 0.039523, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 14:54:34.521464: step 476300, loss = 0.010720, learning_rate = 0.000000 (2558.7 examples/sec)
=> 2021-11-11 14:54:54.663723: step 476400, loss = 0.024650, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 14:55:14.799353: step 476500, loss = 0.020273, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 14:55:35.752255: step 476600, loss = 0.018715, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 14:55:55.900710: step 476700, loss = 0.019873, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 14:56:16.053548: step 476800, loss = 0.027260, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 14:56:36.205041: step 476900, loss = 0.061007, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 14:56:57.190651: step 477000, loss = 0.018240, learning_rate = 0.000000 (2592.9 examples/sec)
=> Model saved to file: ./logs_res/model-477000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 14:57:29.087360: step 477100, loss = 0.011705, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 14:57:49.182664: step 477200, loss = 0.013146, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 14:58:09.277683: step 477300, loss = 0.040212, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 14:58:30.226136: step 477400, loss = 0.033583, learning_rate = 0.000000 (2583.1 examples/sec)
=> 2021-11-11 14:58:50.361761: step 477500, loss = 0.017444, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 14:59:10.496710: step 477600, loss = 0.018347, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 14:59:30.623871: step 477700, loss = 0.027857, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 14:59:51.648595: step 477800, loss = 0.031163, learning_rate = 0.000000 (2577.3 examples/sec)
=> 2021-11-11 15:00:11.807864: step 477900, loss = 0.020290, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 15:00:31.940764: step 478000, loss = 0.032388, learning_rate = 0.000000 (2564.5 examples/sec)
=> Model saved to file: ./logs_res/model-478000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:01:03.874278: step 478100, loss = 0.031034, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 15:01:24.833270: step 478200, loss = 0.026987, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-11 15:01:44.936306: step 478300, loss = 0.023160, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 15:02:05.040051: step 478400, loss = 0.014998, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 15:02:25.147233: step 478500, loss = 0.027191, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 15:02:46.075477: step 478600, loss = 0.018639, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-11 15:03:06.193449: step 478700, loss = 0.014889, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 15:03:26.315788: step 478800, loss = 0.023347, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 15:03:46.489113: step 478900, loss = 0.039811, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 15:04:07.540967: step 479000, loss = 0.031920, learning_rate = 0.000000 (2570.6 examples/sec)
=> Model saved to file: ./logs_res/model-479000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:04:39.678216: step 479100, loss = 0.035628, learning_rate = 0.000000 (2559.3 examples/sec)
=> 2021-11-11 15:04:59.885318: step 479200, loss = 0.034362, learning_rate = 0.000000 (2554.9 examples/sec)
=> 2021-11-11 15:05:20.095188: step 479300, loss = 0.030690, learning_rate = 0.000000 (2554.6 examples/sec)
=> 2021-11-11 15:05:40.312162: step 479400, loss = 0.032842, learning_rate = 0.000000 (2553.8 examples/sec)
=> 2021-11-11 15:06:01.357700: step 479500, loss = 0.016735, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 15:06:21.549008: step 479600, loss = 0.022214, learning_rate = 0.000000 (2557.2 examples/sec)
=> 2021-11-11 15:06:41.743473: step 479700, loss = 0.019271, learning_rate = 0.000000 (2556.6 examples/sec)
=> 2021-11-11 15:07:01.932808: step 479800, loss = 0.037915, learning_rate = 0.000000 (2557.4 examples/sec)
=> 2021-11-11 15:07:22.991374: step 479900, loss = 0.025987, learning_rate = 0.000000 (2575.0 examples/sec)
=> 2021-11-11 15:07:43.157048: step 480000, loss = 0.017306, learning_rate = 0.000000 (2560.5 examples/sec)
=> Model saved to file: ./logs_res/model-480000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954239, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:08:15.216843: step 480100, loss = 0.014346, learning_rate = 0.000000 (2572.2 examples/sec)
=> 2021-11-11 15:08:35.325272: step 480200, loss = 0.023134, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 15:08:56.311398: step 480300, loss = 0.039528, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 15:09:16.447477: step 480400, loss = 0.013580, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 15:09:36.579643: step 480500, loss = 0.009893, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 15:09:56.737808: step 480600, loss = 0.026362, learning_rate = 0.000000 (2561.2 examples/sec)
=> 2021-11-11 15:10:17.718624: step 480700, loss = 0.011923, learning_rate = 0.000000 (2580.7 examples/sec)
=> 2021-11-11 15:10:37.869648: step 480800, loss = 0.039215, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 15:10:57.993755: step 480900, loss = 0.030181, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 15:11:18.130542: step 481000, loss = 0.027934, learning_rate = 0.000000 (2564.1 examples/sec)
=> Model saved to file: ./logs_res/model-481000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:11:51.064471: step 481100, loss = 0.020682, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 15:12:11.173383: step 481200, loss = 0.010591, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 15:12:31.287544: step 481300, loss = 0.040069, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 15:12:51.418982: step 481400, loss = 0.021477, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 15:13:12.424090: step 481500, loss = 0.015481, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 15:13:32.564126: step 481600, loss = 0.021144, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 15:13:52.709721: step 481700, loss = 0.022704, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 15:14:12.854098: step 481800, loss = 0.020434, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 15:14:33.904121: step 481900, loss = 0.033695, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 15:14:54.038591: step 482000, loss = 0.030663, learning_rate = 0.000000 (2564.6 examples/sec)
=> Model saved to file: ./logs_res/model-482000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:15:26.122365: step 482100, loss = 0.006531, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 15:15:46.225388: step 482200, loss = 0.058349, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 15:16:06.408748: step 482300, loss = 0.022259, learning_rate = 0.000000 (2558.3 examples/sec)
=> 2021-11-11 15:16:27.412039: step 482400, loss = 0.017524, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 15:16:47.558541: step 482500, loss = 0.017941, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 15:17:07.708287: step 482600, loss = 0.044658, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 15:17:27.935744: step 482700, loss = 0.021287, learning_rate = 0.000000 (2552.4 examples/sec)
=> 2021-11-11 15:17:48.938519: step 482800, loss = 0.012750, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-11 15:18:09.087347: step 482900, loss = 0.034101, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 15:18:29.249663: step 483000, loss = 0.011443, learning_rate = 0.000000 (2560.8 examples/sec)
=> Model saved to file: ./logs_res/model-483000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954239, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:19:01.456181: step 483100, loss = 0.038123, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 15:19:22.416725: step 483200, loss = 0.025657, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 15:19:42.547663: step 483300, loss = 0.040543, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 15:20:02.663390: step 483400, loss = 0.021850, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 15:20:22.793867: step 483500, loss = 0.023862, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 15:20:43.960641: step 483600, loss = 0.014565, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 15:21:04.087551: step 483700, loss = 0.028495, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 15:21:24.228799: step 483800, loss = 0.042625, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 15:21:44.384932: step 483900, loss = 0.043335, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 15:22:05.348452: step 484000, loss = 0.025148, learning_rate = 0.000000 (2579.5 examples/sec)
=> Model saved to file: ./logs_res/model-484000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954086, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:22:37.511969: step 484100, loss = 0.033749, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 15:22:57.614222: step 484200, loss = 0.028205, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 15:23:17.717418: step 484300, loss = 0.017707, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 15:23:38.790610: step 484400, loss = 0.014935, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-11 15:23:58.921966: step 484500, loss = 0.028646, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 15:24:19.059424: step 484600, loss = 0.025620, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 15:24:39.203425: step 484700, loss = 0.013186, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 15:25:00.271390: step 484800, loss = 0.045005, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 15:25:20.408878: step 484900, loss = 0.043554, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 15:25:40.567208: step 485000, loss = 0.032224, learning_rate = 0.000000 (2561.3 examples/sec)
=> Model saved to file: ./logs_res/model-485000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:26:12.584722: step 485100, loss = 0.026339, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 15:26:32.708498: step 485200, loss = 0.042107, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 15:26:53.701577: step 485300, loss = 0.032264, learning_rate = 0.000000 (2578.5 examples/sec)
=> 2021-11-11 15:27:13.825724: step 485400, loss = 0.024296, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 15:27:33.962043: step 485500, loss = 0.026961, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 15:27:54.111928: step 485600, loss = 0.028811, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 15:28:15.101969: step 485700, loss = 0.031870, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-11 15:28:35.230777: step 485800, loss = 0.027024, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 15:28:55.367266: step 485900, loss = 0.036824, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 15:29:15.496555: step 486000, loss = 0.025648, learning_rate = 0.000000 (2565.4 examples/sec)
=> Model saved to file: ./logs_res/model-486000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954928, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:29:48.555445: step 486100, loss = 0.013296, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 15:30:08.700378: step 486200, loss = 0.017177, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 15:30:28.839976: step 486300, loss = 0.038257, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 15:30:48.959599: step 486400, loss = 0.020515, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 15:31:10.006088: step 486500, loss = 0.019000, learning_rate = 0.000000 (2575.6 examples/sec)
=> 2021-11-11 15:31:30.149680: step 486600, loss = 0.027233, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 15:31:50.263207: step 486700, loss = 0.023711, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 15:32:10.416502: step 486800, loss = 0.034506, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 15:32:31.400535: step 486900, loss = 0.019601, learning_rate = 0.000000 (2587.1 examples/sec)
=> 2021-11-11 15:32:51.527840: step 487000, loss = 0.029886, learning_rate = 0.000000 (2565.2 examples/sec)
=> Model saved to file: ./logs_res/model-487000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955923, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:33:23.785980: step 487100, loss = 0.013460, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 15:33:43.890306: step 487200, loss = 0.024594, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 15:34:04.862719: step 487300, loss = 0.029863, learning_rate = 0.000000 (2581.4 examples/sec)
=> 2021-11-11 15:34:24.987105: step 487400, loss = 0.017433, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 15:34:45.101642: step 487500, loss = 0.025032, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 15:35:05.233987: step 487600, loss = 0.015586, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 15:35:26.308610: step 487700, loss = 0.013098, learning_rate = 0.000000 (2580.0 examples/sec)
=> 2021-11-11 15:35:46.425729: step 487800, loss = 0.016338, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 15:36:06.558188: step 487900, loss = 0.019044, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 15:36:26.700847: step 488000, loss = 0.018214, learning_rate = 0.000000 (2563.6 examples/sec)
=> Model saved to file: ./logs_res/model-488000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954852, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:36:58.667831: step 488100, loss = 0.036007, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 15:37:19.787006: step 488200, loss = 0.020765, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 15:37:39.909258: step 488300, loss = 0.019133, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 15:38:00.052228: step 488400, loss = 0.019091, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 15:38:20.156717: step 488500, loss = 0.017387, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 15:38:41.109720: step 488600, loss = 0.020937, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 15:39:01.233371: step 488700, loss = 0.024933, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 15:39:21.345648: step 488800, loss = 0.023520, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 15:39:41.462950: step 488900, loss = 0.027308, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 15:40:02.538911: step 489000, loss = 0.022595, learning_rate = 0.000000 (2583.4 examples/sec)
=> Model saved to file: ./logs_res/model-489000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954163, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:40:34.612836: step 489100, loss = 0.037207, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 15:40:54.750234: step 489200, loss = 0.018822, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 15:41:14.886920: step 489300, loss = 0.021274, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 15:41:35.915245: step 489400, loss = 0.009248, learning_rate = 0.000000 (2577.2 examples/sec)
=> 2021-11-11 15:41:56.072282: step 489500, loss = 0.033361, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 15:42:16.244855: step 489600, loss = 0.026571, learning_rate = 0.000000 (2560.4 examples/sec)
=> 2021-11-11 15:42:36.415086: step 489700, loss = 0.022968, learning_rate = 0.000000 (2559.8 examples/sec)
=> 2021-11-11 15:42:57.750318: step 489800, loss = 0.012068, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 15:43:17.889954: step 489900, loss = 0.023620, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 15:43:38.050642: step 490000, loss = 0.020165, learning_rate = 0.000000 (2561.3 examples/sec)
=> Model saved to file: ./logs_res/model-490000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:44:10.122232: step 490100, loss = 0.011999, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 15:44:31.169166: step 490200, loss = 0.011738, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-11 15:44:51.267428: step 490300, loss = 0.029602, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 15:45:11.402513: step 490400, loss = 0.023829, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 15:45:31.497379: step 490500, loss = 0.028936, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 15:45:52.656153: step 490600, loss = 0.016946, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-11 15:46:12.839858: step 490700, loss = 0.006662, learning_rate = 0.000000 (2558.0 examples/sec)
=> 2021-11-11 15:46:32.961550: step 490800, loss = 0.029373, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 15:46:53.111267: step 490900, loss = 0.025124, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 15:47:13.254693: step 491000, loss = 0.021142, learning_rate = 0.000000 (2563.2 examples/sec)
=> Model saved to file: ./logs_res/model-491000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:47:46.009998: step 491100, loss = 0.044038, learning_rate = 0.000000 (2582.4 examples/sec)
=> 2021-11-11 15:48:06.122530: step 491200, loss = 0.021871, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 15:48:26.250749: step 491300, loss = 0.019257, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 15:48:46.375993: step 491400, loss = 0.020999, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 15:49:07.496033: step 491500, loss = 0.020913, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 15:49:27.645688: step 491600, loss = 0.029808, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 15:49:47.768756: step 491700, loss = 0.013089, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 15:50:07.883552: step 491800, loss = 0.046794, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 15:50:29.122658: step 491900, loss = 0.021319, learning_rate = 0.000000 (2582.0 examples/sec)
=> 2021-11-11 15:50:49.248823: step 492000, loss = 0.012813, learning_rate = 0.000000 (2565.3 examples/sec)
=> Model saved to file: ./logs_res/model-492000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:51:21.576929: step 492100, loss = 0.016886, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 15:51:41.674737: step 492200, loss = 0.017073, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 15:52:02.795194: step 492300, loss = 0.024118, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 15:52:22.928309: step 492400, loss = 0.026984, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 15:52:43.058215: step 492500, loss = 0.045573, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 15:53:03.185466: step 492600, loss = 0.020751, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 15:53:24.174214: step 492700, loss = 0.042560, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-11 15:53:44.308923: step 492800, loss = 0.030708, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 15:54:04.439226: step 492900, loss = 0.014876, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 15:54:24.569083: step 493000, loss = 0.047983, learning_rate = 0.000000 (2564.9 examples/sec)
=> Model saved to file: ./logs_res/model-493000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:54:57.693773: step 493100, loss = 0.041845, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-11 15:55:17.781207: step 493200, loss = 0.039125, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 15:55:37.880681: step 493300, loss = 0.028768, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 15:55:57.984132: step 493400, loss = 0.012910, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 15:56:18.956733: step 493500, loss = 0.020352, learning_rate = 0.000000 (2583.0 examples/sec)
=> 2021-11-11 15:56:39.140625: step 493600, loss = 0.028995, learning_rate = 0.000000 (2558.0 examples/sec)
=> 2021-11-11 15:56:59.263647: step 493700, loss = 0.012045, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 15:57:19.397928: step 493800, loss = 0.016729, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 15:57:39.528760: step 493900, loss = 0.024845, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 15:58:00.685148: step 494000, loss = 0.028573, learning_rate = 0.000000 (2574.8 examples/sec)
=> Model saved to file: ./logs_res/model-494000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 15:58:33.056780: step 494100, loss = 0.034027, learning_rate = 0.000000 (2572.6 examples/sec)
=> 2021-11-11 15:58:53.172075: step 494200, loss = 0.014014, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 15:59:13.278572: step 494300, loss = 0.019906, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 15:59:34.231409: step 494400, loss = 0.022047, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 15:59:54.364749: step 494500, loss = 0.020965, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 16:00:14.483499: step 494600, loss = 0.035353, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 16:00:34.605343: step 494700, loss = 0.043465, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 16:00:55.581345: step 494800, loss = 0.015834, learning_rate = 0.000000 (2580.0 examples/sec)
=> 2021-11-11 16:01:15.705567: step 494900, loss = 0.027466, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:01:35.820155: step 495000, loss = 0.031906, learning_rate = 0.000000 (2567.2 examples/sec)
=> Model saved to file: ./logs_res/model-495000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:02:08.093790: step 495100, loss = 0.024956, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 16:02:29.093667: step 495200, loss = 0.011826, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 16:02:49.208761: step 495300, loss = 0.019213, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 16:03:09.329528: step 495400, loss = 0.021134, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 16:03:29.474945: step 495500, loss = 0.015235, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 16:03:50.486130: step 495600, loss = 0.018189, learning_rate = 0.000000 (2576.5 examples/sec)
=> 2021-11-11 16:04:10.610621: step 495700, loss = 0.017117, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 16:04:30.733019: step 495800, loss = 0.019342, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 16:04:50.864866: step 495900, loss = 0.013005, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 16:05:11.840080: step 496000, loss = 0.016208, learning_rate = 0.000000 (2594.6 examples/sec)
=> Model saved to file: ./logs_res/model-496000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:05:43.676249: step 496100, loss = 0.019445, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 16:06:03.772971: step 496200, loss = 0.035745, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 16:06:23.867620: step 496300, loss = 0.010358, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 16:06:45.015343: step 496400, loss = 0.042360, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 16:07:05.152460: step 496500, loss = 0.044195, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 16:07:25.289410: step 496600, loss = 0.012988, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 16:07:45.416425: step 496700, loss = 0.026945, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 16:08:05.556669: step 496800, loss = 0.016501, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 16:08:26.679819: step 496900, loss = 0.014661, learning_rate = 0.000000 (2559.6 examples/sec)
=> 2021-11-11 16:08:46.818557: step 497000, loss = 0.043284, learning_rate = 0.000000 (2564.1 examples/sec)
=> Model saved to file: ./logs_res/model-497000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:09:18.855941: step 497100, loss = 0.026166, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 16:09:38.964187: step 497200, loss = 0.057573, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 16:09:59.918950: step 497300, loss = 0.031953, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 16:10:20.041766: step 497400, loss = 0.010989, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 16:10:40.192699: step 497500, loss = 0.023108, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 16:11:00.339872: step 497600, loss = 0.010797, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 16:11:21.346000: step 497700, loss = 0.017563, learning_rate = 0.000000 (2580.2 examples/sec)
=> 2021-11-11 16:11:41.506129: step 497800, loss = 0.024614, learning_rate = 0.000000 (2561.3 examples/sec)
=> 2021-11-11 16:12:01.649815: step 497900, loss = 0.026565, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 16:12:21.803030: step 498000, loss = 0.017262, learning_rate = 0.000000 (2562.0 examples/sec)
=> Model saved to file: ./logs_res/model-498000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:12:54.883495: step 498100, loss = 0.032787, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 16:13:15.003218: step 498200, loss = 0.014725, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 16:13:35.109315: step 498300, loss = 0.026653, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 16:13:55.247789: step 498400, loss = 0.009011, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 16:14:16.223906: step 498500, loss = 0.018174, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-11 16:14:36.355269: step 498600, loss = 0.016920, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 16:14:56.504987: step 498700, loss = 0.029944, learning_rate = 0.000000 (2562.4 examples/sec)
=> 2021-11-11 16:15:16.627792: step 498800, loss = 0.016973, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 16:15:37.720849: step 498900, loss = 0.014605, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 16:15:57.922051: step 499000, loss = 0.063914, learning_rate = 0.000000 (2556.0 examples/sec)
=> Model saved to file: ./logs_res/model-499000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:16:29.973103: step 499100, loss = 0.031226, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-11 16:16:50.102856: step 499200, loss = 0.019769, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 16:17:11.183826: step 499300, loss = 0.029279, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-11 16:17:31.317213: step 499400, loss = 0.050938, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 16:17:51.456634: step 499500, loss = 0.006463, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 16:18:11.597202: step 499600, loss = 0.018389, learning_rate = 0.000000 (2563.7 examples/sec)
=> 2021-11-11 16:18:32.561837: step 499700, loss = 0.048291, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 16:18:52.715635: step 499800, loss = 0.016549, learning_rate = 0.000000 (2561.9 examples/sec)
=> 2021-11-11 16:19:12.904050: step 499900, loss = 0.054542, learning_rate = 0.000000 (2557.9 examples/sec)
=> 2021-11-11 16:19:33.044020: step 500000, loss = 0.015616, learning_rate = 0.000000 (2563.5 examples/sec)
=> Model saved to file: ./logs_res/model-500000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:20:05.388428: step 500100, loss = 0.012639, learning_rate = 0.000000 (2571.3 examples/sec)
=> 2021-11-11 16:20:26.444825: step 500200, loss = 0.008280, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 16:20:46.560054: step 500300, loss = 0.021286, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 16:21:06.681564: step 500400, loss = 0.014987, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 16:21:26.802920: step 500500, loss = 0.014061, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 16:21:47.790598: step 500600, loss = 0.013906, learning_rate = 0.000000 (2580.0 examples/sec)
=> 2021-11-11 16:22:07.937678: step 500700, loss = 0.024607, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 16:22:28.101241: step 500800, loss = 0.039438, learning_rate = 0.000000 (2561.1 examples/sec)
=> 2021-11-11 16:22:48.247201: step 500900, loss = 0.029629, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 16:23:09.287042: step 501000, loss = 0.011294, learning_rate = 0.000000 (2575.5 examples/sec)
=> Model saved to file: ./logs_res/model-501000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:23:41.542590: step 501100, loss = 0.027001, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 16:24:01.666533: step 501200, loss = 0.010157, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 16:24:21.780819: step 501300, loss = 0.024868, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 16:24:42.849106: step 501400, loss = 0.024318, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 16:25:02.986833: step 501500, loss = 0.020241, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 16:25:23.164290: step 501600, loss = 0.039416, learning_rate = 0.000000 (2559.1 examples/sec)
=> 2021-11-11 16:25:43.289509: step 501700, loss = 0.032133, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:26:04.248650: step 501800, loss = 0.019452, learning_rate = 0.000000 (2580.6 examples/sec)
=> 2021-11-11 16:26:24.374520: step 501900, loss = 0.011458, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 16:26:44.515564: step 502000, loss = 0.032608, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-502000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:27:16.521134: step 502100, loss = 0.013133, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 16:27:37.478411: step 502200, loss = 0.025376, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 16:27:57.628526: step 502300, loss = 0.045146, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 16:28:17.736612: step 502400, loss = 0.026116, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 16:28:37.830966: step 502500, loss = 0.029166, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 16:28:58.804211: step 502600, loss = 0.017202, learning_rate = 0.000000 (2591.9 examples/sec)
=> 2021-11-11 16:29:18.913549: step 502700, loss = 0.010000, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 16:29:39.031684: step 502800, loss = 0.033174, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 16:29:59.147125: step 502900, loss = 0.032836, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 16:30:19.255829: step 503000, loss = 0.030787, learning_rate = 0.000000 (2567.4 examples/sec)
=> Model saved to file: ./logs_res/model-503000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:30:52.048253: step 503100, loss = 0.012040, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 16:31:12.141006: step 503200, loss = 0.035185, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 16:31:32.248612: step 503300, loss = 0.027944, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 16:31:52.366593: step 503400, loss = 0.015268, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 16:32:13.505987: step 503500, loss = 0.018454, learning_rate = 0.000000 (2581.9 examples/sec)
=> 2021-11-11 16:32:33.612052: step 503600, loss = 0.010777, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 16:32:53.712322: step 503700, loss = 0.030012, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 16:33:13.805390: step 503800, loss = 0.008049, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 16:33:34.818712: step 503900, loss = 0.020619, learning_rate = 0.000000 (2596.6 examples/sec)
=> 2021-11-11 16:33:54.935007: step 504000, loss = 0.025826, learning_rate = 0.000000 (2566.6 examples/sec)
=> Model saved to file: ./logs_res/model-504000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:34:26.991854: step 504100, loss = 0.017058, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 16:34:47.098373: step 504200, loss = 0.020900, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 16:35:08.051315: step 504300, loss = 0.026957, learning_rate = 0.000000 (2582.7 examples/sec)
=> 2021-11-11 16:35:28.182029: step 504400, loss = 0.051455, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 16:35:48.294506: step 504500, loss = 0.017704, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 16:36:08.424549: step 504600, loss = 0.030959, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 16:36:29.377325: step 504700, loss = 0.031061, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 16:36:49.479664: step 504800, loss = 0.021128, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 16:37:09.619019: step 504900, loss = 0.018395, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 16:37:29.759880: step 505000, loss = 0.028197, learning_rate = 0.000000 (2563.7 examples/sec)
=> Model saved to file: ./logs_res/model-505000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954239, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:38:02.589537: step 505100, loss = 0.027220, learning_rate = 0.000000 (2587.3 examples/sec)
=> 2021-11-11 16:38:22.685978: step 505200, loss = 0.036354, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 16:38:42.808746: step 505300, loss = 0.009320, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 16:39:02.933883: step 505400, loss = 0.027606, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:39:24.042990: step 505500, loss = 0.026088, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 16:39:44.158385: step 505600, loss = 0.032344, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 16:40:04.281965: step 505700, loss = 0.034323, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:40:24.394774: step 505800, loss = 0.012165, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 16:40:44.525230: step 505900, loss = 0.029013, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:41:05.671070: step 506000, loss = 0.039789, learning_rate = 0.000000 (2577.2 examples/sec)
=> Model saved to file: ./logs_res/model-506000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954239, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:41:37.992596: step 506100, loss = 0.028262, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 16:41:58.116660: step 506200, loss = 0.054675, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 16:42:18.222190: step 506300, loss = 0.025786, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 16:42:39.178698: step 506400, loss = 0.013889, learning_rate = 0.000000 (2581.0 examples/sec)
=> 2021-11-11 16:42:59.325217: step 506500, loss = 0.026293, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 16:43:19.464669: step 506600, loss = 0.028665, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 16:43:39.598135: step 506700, loss = 0.036045, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 16:44:00.592337: step 506800, loss = 0.033546, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 16:44:20.712125: step 506900, loss = 0.022366, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 16:44:40.846637: step 507000, loss = 0.025862, learning_rate = 0.000000 (2564.3 examples/sec)
=> Model saved to file: ./logs_res/model-507000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:45:13.064591: step 507100, loss = 0.035158, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 16:45:33.994447: step 507200, loss = 0.031754, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 16:45:54.133291: step 507300, loss = 0.010591, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 16:46:14.267962: step 507400, loss = 0.019211, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 16:46:34.404034: step 507500, loss = 0.034649, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 16:46:55.457916: step 507600, loss = 0.014192, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 16:47:15.594082: step 507700, loss = 0.027893, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 16:47:35.707488: step 507800, loss = 0.025271, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 16:47:55.856059: step 507900, loss = 0.039062, learning_rate = 0.000000 (2562.9 examples/sec)
=> 2021-11-11 16:48:16.864781: step 508000, loss = 0.017747, learning_rate = 0.000000 (2578.1 examples/sec)
=> Model saved to file: ./logs_res/model-508000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:48:49.014498: step 508100, loss = 0.014742, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 16:49:09.119292: step 508200, loss = 0.033443, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 16:49:29.221352: step 508300, loss = 0.060004, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 16:49:50.261067: step 508400, loss = 0.023395, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 16:50:10.367948: step 508500, loss = 0.022936, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 16:50:30.473899: step 508600, loss = 0.040919, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 16:50:50.608060: step 508700, loss = 0.010589, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 16:51:10.722468: step 508800, loss = 0.014844, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 16:51:31.691817: step 508900, loss = 0.024122, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 16:51:51.794203: step 509000, loss = 0.031305, learning_rate = 0.000000 (2568.5 examples/sec)
=> Model saved to file: ./logs_res/model-509000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954392, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:52:24.109119: step 509100, loss = 0.024548, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-11 16:52:44.209704: step 509200, loss = 0.032987, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 16:53:05.219044: step 509300, loss = 0.027777, learning_rate = 0.000000 (2584.7 examples/sec)
=> 2021-11-11 16:53:25.345836: step 509400, loss = 0.016558, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 16:53:45.483333: step 509500, loss = 0.059561, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 16:54:05.616244: step 509600, loss = 0.017194, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 16:54:26.702651: step 509700, loss = 0.017051, learning_rate = 0.000000 (2575.2 examples/sec)
=> 2021-11-11 16:54:46.859412: step 509800, loss = 0.009302, learning_rate = 0.000000 (2561.6 examples/sec)
=> 2021-11-11 16:55:07.003288: step 509900, loss = 0.034997, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 16:55:27.160526: step 510000, loss = 0.022007, learning_rate = 0.000000 (2561.5 examples/sec)
=> Model saved to file: ./logs_res/model-510000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:55:59.943022: step 510100, loss = 0.045548, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 16:56:20.085910: step 510200, loss = 0.016820, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 16:56:40.214147: step 510300, loss = 0.023261, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 16:57:00.329759: step 510400, loss = 0.023765, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 16:57:21.448459: step 510500, loss = 0.028861, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-11 16:57:41.576024: step 510600, loss = 0.025767, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 16:58:01.710605: step 510700, loss = 0.020443, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 16:58:21.828283: step 510800, loss = 0.024449, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 16:58:42.918417: step 510900, loss = 0.077746, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 16:59:03.021230: step 511000, loss = 0.011881, learning_rate = 0.000000 (2568.1 examples/sec)
=> Model saved to file: ./logs_res/model-511000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955234, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 16:59:35.195595: step 511100, loss = 0.027218, learning_rate = 0.000000 (2570.7 examples/sec)
=> 2021-11-11 16:59:55.287008: step 511200, loss = 0.025612, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 17:00:16.246087: step 511300, loss = 0.021644, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 17:00:36.353561: step 511400, loss = 0.028223, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 17:00:56.482602: step 511500, loss = 0.057355, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 17:01:16.596597: step 511600, loss = 0.014839, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 17:01:36.730261: step 511700, loss = 0.025649, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 17:01:57.768936: step 511800, loss = 0.018932, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 17:02:17.904842: step 511900, loss = 0.018445, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 17:02:38.033459: step 512000, loss = 0.022757, learning_rate = 0.000000 (2565.1 examples/sec)
=> Model saved to file: ./logs_res/model-512000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954469, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:03:10.113641: step 512100, loss = 0.012330, learning_rate = 0.000000 (2574.0 examples/sec)
=> 2021-11-11 17:03:31.244085: step 512200, loss = 0.031222, learning_rate = 0.000000 (2586.3 examples/sec)
=> 2021-11-11 17:03:51.347130: step 512300, loss = 0.012878, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 17:04:11.471026: step 512400, loss = 0.029435, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 17:04:31.608703: step 512500, loss = 0.016034, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 17:04:52.595898: step 512600, loss = 0.020447, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 17:05:12.736103: step 512700, loss = 0.016415, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 17:05:32.860723: step 512800, loss = 0.028875, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 17:05:52.989641: step 512900, loss = 0.028639, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 17:06:13.935038: step 513000, loss = 0.059822, learning_rate = 0.000000 (2582.9 examples/sec)
=> Model saved to file: ./logs_res/model-513000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:06:45.934893: step 513100, loss = 0.015755, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 17:07:06.024740: step 513200, loss = 0.049733, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 17:07:26.131226: step 513300, loss = 0.015172, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 17:07:47.091320: step 513400, loss = 0.021087, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 17:08:07.215180: step 513500, loss = 0.044870, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 17:08:27.319791: step 513600, loss = 0.020676, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 17:08:47.452626: step 513700, loss = 0.009101, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 17:09:08.466857: step 513800, loss = 0.022902, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 17:09:28.608181: step 513900, loss = 0.029412, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 17:09:48.744937: step 514000, loss = 0.018150, learning_rate = 0.000000 (2564.0 examples/sec)
=> Model saved to file: ./logs_res/model-514000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:10:20.696101: step 514100, loss = 0.013683, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 17:10:41.616637: step 514200, loss = 0.016452, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 17:11:01.718940: step 514300, loss = 0.025245, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 17:11:21.812634: step 514400, loss = 0.020619, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 17:11:41.934126: step 514500, loss = 0.018220, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 17:12:02.027145: step 514600, loss = 0.034264, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 17:12:23.091161: step 514700, loss = 0.036454, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 17:12:43.213948: step 514800, loss = 0.015387, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 17:13:03.333502: step 514900, loss = 0.024052, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 17:13:23.468124: step 515000, loss = 0.054740, learning_rate = 0.000000 (2564.3 examples/sec)
=> Model saved to file: ./logs_res/model-515000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:13:56.389024: step 515100, loss = 0.019875, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 17:14:16.479455: step 515200, loss = 0.021010, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 17:14:36.595327: step 515300, loss = 0.035471, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 17:14:56.723594: step 515400, loss = 0.043999, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 17:15:17.682968: step 515500, loss = 0.031648, learning_rate = 0.000000 (2580.5 examples/sec)
=> 2021-11-11 17:15:37.799477: step 515600, loss = 0.011696, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 17:15:57.932594: step 515700, loss = 0.018271, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 17:16:18.056616: step 515800, loss = 0.022717, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 17:16:39.171769: step 515900, loss = 0.011670, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 17:16:59.313377: step 516000, loss = 0.049833, learning_rate = 0.000000 (2563.4 examples/sec)
=> Model saved to file: ./logs_res/model-516000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:17:31.477627: step 516100, loss = 0.018581, learning_rate = 0.000000 (2571.8 examples/sec)
=> 2021-11-11 17:17:51.575730: step 516200, loss = 0.021321, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 17:18:12.596166: step 516300, loss = 0.038912, learning_rate = 0.000000 (2579.6 examples/sec)
=> 2021-11-11 17:18:32.721187: step 516400, loss = 0.015983, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 17:18:52.845107: step 516500, loss = 0.046133, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 17:19:12.985118: step 516600, loss = 0.042158, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 17:19:34.076560: step 516700, loss = 0.012615, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 17:19:54.200885: step 516800, loss = 0.019345, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 17:20:14.339899: step 516900, loss = 0.029718, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 17:20:34.461098: step 517000, loss = 0.023944, learning_rate = 0.000000 (2566.1 examples/sec)
=> Model saved to file: ./logs_res/model-517000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:21:07.372135: step 517100, loss = 0.023845, learning_rate = 0.000000 (2588.1 examples/sec)
=> 2021-11-11 17:21:27.467553: step 517200, loss = 0.026846, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 17:21:47.580706: step 517300, loss = 0.020268, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 17:22:07.701603: step 517400, loss = 0.018980, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 17:22:27.800065: step 517500, loss = 0.035352, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 17:22:49.055278: step 517600, loss = 0.024001, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 17:23:09.175502: step 517700, loss = 0.014933, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 17:23:29.296619: step 517800, loss = 0.031531, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 17:23:49.432083: step 517900, loss = 0.024683, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 17:24:10.435679: step 518000, loss = 0.026593, learning_rate = 0.000000 (2578.8 examples/sec)
=> Model saved to file: ./logs_res/model-518000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955540, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:24:42.619083: step 518100, loss = 0.046092, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 17:25:02.721242: step 518200, loss = 0.042114, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 17:25:22.812525: step 518300, loss = 0.030877, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 17:25:43.892847: step 518400, loss = 0.018856, learning_rate = 0.000000 (2579.3 examples/sec)
=> 2021-11-11 17:26:04.026461: step 518500, loss = 0.016637, learning_rate = 0.000000 (2564.3 examples/sec)
=> 2021-11-11 17:26:24.137157: step 518600, loss = 0.023680, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 17:26:44.272328: step 518700, loss = 0.012212, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 17:27:05.379474: step 518800, loss = 0.017274, learning_rate = 0.000000 (2579.9 examples/sec)
=> 2021-11-11 17:27:25.527639: step 518900, loss = 0.023498, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 17:27:45.676358: step 519000, loss = 0.037167, learning_rate = 0.000000 (2562.8 examples/sec)
=> Model saved to file: ./logs_res/model-519000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:28:17.737388: step 519100, loss = 0.013950, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 17:28:38.883403: step 519200, loss = 0.012378, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 17:28:59.009535: step 519300, loss = 0.018084, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 17:29:19.105036: step 519400, loss = 0.049794, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 17:29:39.221970: step 519500, loss = 0.061231, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 17:30:00.183325: step 519600, loss = 0.036477, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 17:30:20.293321: step 519700, loss = 0.016417, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 17:30:40.408699: step 519800, loss = 0.019058, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 17:31:00.530670: step 519900, loss = 0.020604, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 17:31:21.452647: step 520000, loss = 0.020751, learning_rate = 0.000000 (2585.9 examples/sec)
=> Model saved to file: ./logs_res/model-520000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:31:53.765810: step 520100, loss = 0.014718, learning_rate = 0.000000 (2575.5 examples/sec)
=> 2021-11-11 17:32:13.857941: step 520200, loss = 0.013254, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 17:32:33.950586: step 520300, loss = 0.023670, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 17:32:55.042818: step 520400, loss = 0.017389, learning_rate = 0.000000 (2580.4 examples/sec)
=> 2021-11-11 17:33:15.161790: step 520500, loss = 0.027163, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 17:33:35.265202: step 520600, loss = 0.030544, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 17:33:55.379866: step 520700, loss = 0.026630, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 17:34:15.487492: step 520800, loss = 0.045039, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 17:34:36.487432: step 520900, loss = 0.020239, learning_rate = 0.000000 (2581.6 examples/sec)
=> 2021-11-11 17:34:56.580532: step 521000, loss = 0.040032, learning_rate = 0.000000 (2569.6 examples/sec)
=> Model saved to file: ./logs_res/model-521000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:35:28.768015: step 521100, loss = 0.013083, learning_rate = 0.000000 (2573.9 examples/sec)
=> 2021-11-11 17:35:48.858743: step 521200, loss = 0.026722, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 17:36:10.012307: step 521300, loss = 0.020461, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 17:36:30.110392: step 521400, loss = 0.016693, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 17:36:50.210111: step 521500, loss = 0.027666, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 17:37:10.314433: step 521600, loss = 0.020929, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 17:37:31.417430: step 521700, loss = 0.009105, learning_rate = 0.000000 (2579.4 examples/sec)
=> 2021-11-11 17:37:51.561655: step 521800, loss = 0.014195, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 17:38:11.691799: step 521900, loss = 0.011389, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 17:38:31.813256: step 522000, loss = 0.008823, learning_rate = 0.000000 (2566.2 examples/sec)
=> Model saved to file: ./logs_res/model-522000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:39:04.594770: step 522100, loss = 0.026955, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-11 17:39:24.684321: step 522200, loss = 0.031394, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 17:39:44.788015: step 522300, loss = 0.027467, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 17:40:04.891491: step 522400, loss = 0.022479, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 17:40:25.868583: step 522500, loss = 0.007570, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 17:40:46.021869: step 522600, loss = 0.019245, learning_rate = 0.000000 (2562.0 examples/sec)
=> 2021-11-11 17:41:06.141120: step 522700, loss = 0.028867, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 17:41:26.280474: step 522800, loss = 0.043544, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 17:41:47.360453: step 522900, loss = 0.031609, learning_rate = 0.000000 (2575.8 examples/sec)
=> 2021-11-11 17:42:07.512613: step 523000, loss = 0.031019, learning_rate = 0.000000 (2561.9 examples/sec)
=> Model saved to file: ./logs_res/model-523000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954852, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:42:39.502031: step 523100, loss = 0.018095, learning_rate = 0.000000 (2573.0 examples/sec)
=> 2021-11-11 17:42:59.598826: step 523200, loss = 0.027421, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 17:43:20.539603: step 523300, loss = 0.012955, learning_rate = 0.000000 (2584.3 examples/sec)
=> 2021-11-11 17:43:40.663315: step 523400, loss = 0.011589, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 17:44:00.776891: step 523500, loss = 0.018995, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 17:44:20.880964: step 523600, loss = 0.057076, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 17:44:41.005575: step 523700, loss = 0.072468, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 17:45:02.099405: step 523800, loss = 0.012244, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 17:45:22.224337: step 523900, loss = 0.023715, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 17:45:42.329344: step 524000, loss = 0.022758, learning_rate = 0.000000 (2568.0 examples/sec)
=> Model saved to file: ./logs_res/model-524000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955923, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:46:14.726748: step 524100, loss = 0.008561, learning_rate = 0.000000 (2571.0 examples/sec)
=> 2021-11-11 17:46:35.703775: step 524200, loss = 0.049180, learning_rate = 0.000000 (2587.9 examples/sec)
=> 2021-11-11 17:46:55.845829: step 524300, loss = 0.018115, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 17:47:15.944491: step 524400, loss = 0.027431, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 17:47:36.046211: step 524500, loss = 0.029384, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 17:47:57.040624: step 524600, loss = 0.012185, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 17:48:17.158251: step 524700, loss = 0.025961, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 17:48:37.323007: step 524800, loss = 0.017451, learning_rate = 0.000000 (2560.6 examples/sec)
=> 2021-11-11 17:48:57.594274: step 524900, loss = 0.009677, learning_rate = 0.000000 (2546.9 examples/sec)
=> 2021-11-11 17:49:18.708648: step 525000, loss = 0.051084, learning_rate = 0.000000 (2580.9 examples/sec)
=> Model saved to file: ./logs_res/model-525000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:49:50.494207: step 525100, loss = 0.012623, learning_rate = 0.000000 (2571.9 examples/sec)
=> 2021-11-11 17:50:10.599275: step 525200, loss = 0.016873, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 17:50:30.723264: step 525300, loss = 0.027167, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 17:50:51.932179: step 525400, loss = 0.033312, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 17:51:12.033786: step 525500, loss = 0.044897, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 17:51:32.134491: step 525600, loss = 0.012669, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 17:51:52.240122: step 525700, loss = 0.026700, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 17:52:13.357234: step 525800, loss = 0.028385, learning_rate = 0.000000 (2584.0 examples/sec)
=> 2021-11-11 17:52:33.468259: step 525900, loss = 0.010256, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 17:52:53.575994: step 526000, loss = 0.029143, learning_rate = 0.000000 (2567.9 examples/sec)
=> Model saved to file: ./logs_res/model-526000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:53:25.478162: step 526100, loss = 0.020756, learning_rate = 0.000000 (2574.6 examples/sec)
=> 2021-11-11 17:53:46.446445: step 526200, loss = 0.030075, learning_rate = 0.000000 (2588.9 examples/sec)
=> 2021-11-11 17:54:06.567870: step 526300, loss = 0.022452, learning_rate = 0.000000 (2566.3 examples/sec)
=> 2021-11-11 17:54:26.658966: step 526400, loss = 0.006358, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 17:54:46.744654: step 526500, loss = 0.045589, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 17:55:06.839329: step 526600, loss = 0.027773, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 17:55:27.774800: step 526700, loss = 0.020670, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 17:55:47.880225: step 526800, loss = 0.012838, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 17:56:07.988754: step 526900, loss = 0.019359, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 17:56:28.109737: step 527000, loss = 0.018479, learning_rate = 0.000000 (2565.9 examples/sec)
=> Model saved to file: ./logs_res/model-527000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 17:57:01.016648: step 527100, loss = 0.019875, learning_rate = 0.000000 (2589.2 examples/sec)
=> 2021-11-11 17:57:21.110780: step 527200, loss = 0.014057, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 17:57:41.204267: step 527300, loss = 0.025660, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 17:58:01.298154: step 527400, loss = 0.047326, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 17:58:22.218143: step 527500, loss = 0.047089, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 17:58:42.357267: step 527600, loss = 0.057515, learning_rate = 0.000000 (2563.6 examples/sec)
=> 2021-11-11 17:59:02.459051: step 527700, loss = 0.016095, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 17:59:22.557992: step 527800, loss = 0.028399, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 17:59:43.571037: step 527900, loss = 0.023837, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 18:00:03.698850: step 528000, loss = 0.025506, learning_rate = 0.000000 (2565.3 examples/sec)
=> Model saved to file: ./logs_res/model-528000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:00:35.568402: step 528100, loss = 0.034478, learning_rate = 0.000000 (2572.7 examples/sec)
=> 2021-11-11 18:00:55.680797: step 528200, loss = 0.033457, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 18:01:16.680541: step 528300, loss = 0.031179, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-11 18:01:36.782610: step 528400, loss = 0.017524, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:01:56.894213: step 528500, loss = 0.040011, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 18:02:16.987298: step 528600, loss = 0.026310, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 18:02:38.122548: step 528700, loss = 0.021665, learning_rate = 0.000000 (2585.2 examples/sec)
=> 2021-11-11 18:02:58.230260: step 528800, loss = 0.017974, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:03:18.333135: step 528900, loss = 0.024411, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:03:38.514300: step 529000, loss = 0.024343, learning_rate = 0.000000 (2558.2 examples/sec)
=> Model saved to file: ./logs_res/model-529000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955693, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:04:11.244499: step 529100, loss = 0.016437, learning_rate = 0.000000 (2584.1 examples/sec)
=> 2021-11-11 18:04:31.337999: step 529200, loss = 0.010159, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 18:04:51.480395: step 529300, loss = 0.015204, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 18:05:11.618907: step 529400, loss = 0.018247, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 18:05:31.727060: step 529500, loss = 0.037788, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:05:52.657899: step 529600, loss = 0.014648, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-11 18:06:12.780482: step 529700, loss = 0.013785, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 18:06:32.887224: step 529800, loss = 0.011173, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 18:06:52.996933: step 529900, loss = 0.010329, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 18:07:13.988240: step 530000, loss = 0.021646, learning_rate = 0.000000 (2580.4 examples/sec)
=> Model saved to file: ./logs_res/model-530000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:07:45.886897: step 530100, loss = 0.013414, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:08:06.023505: step 530200, loss = 0.015787, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 18:08:26.123880: step 530300, loss = 0.022228, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 18:08:47.076340: step 530400, loss = 0.018024, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 18:09:07.168057: step 530500, loss = 0.022850, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 18:09:27.263366: step 530600, loss = 0.019814, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 18:09:47.376528: step 530700, loss = 0.017714, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 18:10:08.339543: step 530800, loss = 0.032320, learning_rate = 0.000000 (2601.0 examples/sec)
=> 2021-11-11 18:10:28.458463: step 530900, loss = 0.007044, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 18:10:48.568179: step 531000, loss = 0.006927, learning_rate = 0.000000 (2567.5 examples/sec)
=> Model saved to file: ./logs_res/model-531000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:11:20.617864: step 531100, loss = 0.032081, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-11 18:11:41.768232: step 531200, loss = 0.034837, learning_rate = 0.000000 (2595.1 examples/sec)
=> 2021-11-11 18:12:01.870004: step 531300, loss = 0.017470, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 18:12:21.977828: step 531400, loss = 0.009091, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 18:12:42.087857: step 531500, loss = 0.011200, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 18:13:03.019213: step 531600, loss = 0.027079, learning_rate = 0.000000 (2599.6 examples/sec)
=> 2021-11-11 18:13:23.118219: step 531700, loss = 0.018437, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 18:13:43.254232: step 531800, loss = 0.018425, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 18:14:03.362943: step 531900, loss = 0.009728, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 18:14:24.306710: step 532000, loss = 0.026774, learning_rate = 0.000000 (2583.0 examples/sec)
=> Model saved to file: ./logs_res/model-532000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:14:56.581270: step 532100, loss = 0.024351, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 18:15:16.669896: step 532200, loss = 0.036054, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 18:15:36.795723: step 532300, loss = 0.023316, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 18:15:56.897860: step 532400, loss = 0.019005, learning_rate = 0.000000 (2569.1 examples/sec)
=> 2021-11-11 18:16:17.846037: step 532500, loss = 0.017820, learning_rate = 0.000000 (2588.5 examples/sec)
=> 2021-11-11 18:16:37.980444: step 532600, loss = 0.018792, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 18:16:58.107357: step 532700, loss = 0.072884, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 18:17:18.243263: step 532800, loss = 0.032931, learning_rate = 0.000000 (2564.4 examples/sec)
=> 2021-11-11 18:17:39.184314: step 532900, loss = 0.034850, learning_rate = 0.000000 (2601.4 examples/sec)
=> 2021-11-11 18:17:59.283814: step 533000, loss = 0.034552, learning_rate = 0.000000 (2569.3 examples/sec)
=> Model saved to file: ./logs_res/model-533000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:18:31.281264: step 533100, loss = 0.020535, learning_rate = 0.000000 (2572.6 examples/sec)
=> 2021-11-11 18:18:51.387466: step 533200, loss = 0.064607, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 18:19:12.472338: step 533300, loss = 0.015873, learning_rate = 0.000000 (2581.2 examples/sec)
=> 2021-11-11 18:19:32.587324: step 533400, loss = 0.079671, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 18:19:52.716542: step 533500, loss = 0.032239, learning_rate = 0.000000 (2564.9 examples/sec)
=> 2021-11-11 18:20:12.838283: step 533600, loss = 0.010268, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 18:20:33.796852: step 533700, loss = 0.047644, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 18:20:53.927528: step 533800, loss = 0.025956, learning_rate = 0.000000 (2564.8 examples/sec)
=> 2021-11-11 18:21:14.059809: step 533900, loss = 0.026175, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 18:21:34.197824: step 534000, loss = 0.021763, learning_rate = 0.000000 (2563.9 examples/sec)
=> Model saved to file: ./logs_res/model-534000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:22:07.079908: step 534100, loss = 0.041608, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 18:22:27.242762: step 534200, loss = 0.013204, learning_rate = 0.000000 (2560.7 examples/sec)
=> 2021-11-11 18:22:47.358719: step 534300, loss = 0.024824, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 18:23:07.496456: step 534400, loss = 0.011529, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 18:23:28.532181: step 534500, loss = 0.027443, learning_rate = 0.000000 (2574.2 examples/sec)
=> 2021-11-11 18:23:48.637174: step 534600, loss = 0.026366, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 18:24:08.742725: step 534700, loss = 0.025111, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 18:24:28.854348: step 534800, loss = 0.028329, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 18:24:49.810481: step 534900, loss = 0.024334, learning_rate = 0.000000 (2592.0 examples/sec)
=> 2021-11-11 18:25:09.918187: step 535000, loss = 0.020138, learning_rate = 0.000000 (2567.7 examples/sec)
=> Model saved to file: ./logs_res/model-535000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955540, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:25:42.101051: step 535100, loss = 0.016089, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 18:26:02.208617: step 535200, loss = 0.031141, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 18:26:22.333251: step 535300, loss = 0.015934, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 18:26:43.359235: step 535400, loss = 0.025970, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 18:27:03.480402: step 535500, loss = 0.012217, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 18:27:23.592899: step 535600, loss = 0.017747, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 18:27:43.717678: step 535700, loss = 0.030765, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 18:28:04.842363: step 535800, loss = 0.015824, learning_rate = 0.000000 (2585.9 examples/sec)
=> 2021-11-11 18:28:24.970940: step 535900, loss = 0.021941, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 18:28:45.185850: step 536000, loss = 0.018004, learning_rate = 0.000000 (2553.9 examples/sec)
=> Model saved to file: ./logs_res/model-536000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:29:17.138236: step 536100, loss = 0.018811, learning_rate = 0.000000 (2573.6 examples/sec)
=> 2021-11-11 18:29:38.074061: step 536200, loss = 0.029041, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 18:29:58.201685: step 536300, loss = 0.015753, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 18:30:18.306440: step 536400, loss = 0.015809, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 18:30:38.466216: step 536500, loss = 0.037835, learning_rate = 0.000000 (2561.4 examples/sec)
=> 2021-11-11 18:30:59.521768: step 536600, loss = 0.007591, learning_rate = 0.000000 (2578.2 examples/sec)
=> 2021-11-11 18:31:19.673677: step 536700, loss = 0.054248, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 18:31:39.843432: step 536800, loss = 0.038838, learning_rate = 0.000000 (2559.9 examples/sec)
=> 2021-11-11 18:31:59.991209: step 536900, loss = 0.039660, learning_rate = 0.000000 (2562.6 examples/sec)
=> 2021-11-11 18:32:20.990524: step 537000, loss = 0.011318, learning_rate = 0.000000 (2577.5 examples/sec)
=> Model saved to file: ./logs_res/model-537000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:32:52.966058: step 537100, loss = 0.034855, learning_rate = 0.000000 (2573.1 examples/sec)
=> 2021-11-11 18:33:13.082903: step 537200, loss = 0.015950, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 18:33:33.173676: step 537300, loss = 0.029075, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 18:33:54.101929: step 537400, loss = 0.031506, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 18:34:14.226119: step 537500, loss = 0.018048, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 18:34:34.344409: step 537600, loss = 0.017997, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 18:34:54.462213: step 537700, loss = 0.050027, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 18:35:15.414743: step 537800, loss = 0.012730, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-11 18:35:35.534583: step 537900, loss = 0.028320, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 18:35:55.641236: step 538000, loss = 0.020164, learning_rate = 0.000000 (2567.7 examples/sec)
=> Model saved to file: ./logs_res/model-538000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:36:27.766474: step 538100, loss = 0.050985, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 18:36:47.867345: step 538200, loss = 0.025324, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 18:37:09.013864: step 538300, loss = 0.043524, learning_rate = 0.000000 (2557.4 examples/sec)
=> 2021-11-11 18:37:29.113174: step 538400, loss = 0.027371, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 18:37:49.223175: step 538500, loss = 0.039618, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 18:38:09.347740: step 538600, loss = 0.007457, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 18:38:30.277762: step 538700, loss = 0.015930, learning_rate = 0.000000 (2584.4 examples/sec)
=> 2021-11-11 18:38:50.385949: step 538800, loss = 0.024466, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 18:39:10.504717: step 538900, loss = 0.024442, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 18:39:30.635390: step 539000, loss = 0.019110, learning_rate = 0.000000 (2564.9 examples/sec)
=> Model saved to file: ./logs_res/model-539000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:40:03.453118: step 539100, loss = 0.013154, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-11 18:40:23.547327: step 539200, loss = 0.023865, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 18:40:43.638751: step 539300, loss = 0.014839, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 18:41:03.763984: step 539400, loss = 0.012504, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 18:41:24.699755: step 539500, loss = 0.017571, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 18:41:44.855623: step 539600, loss = 0.036927, learning_rate = 0.000000 (2561.8 examples/sec)
=> 2021-11-11 18:42:04.980277: step 539700, loss = 0.031895, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 18:42:25.108685: step 539800, loss = 0.043843, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 18:42:46.212066: step 539900, loss = 0.032574, learning_rate = 0.000000 (2576.4 examples/sec)
=> 2021-11-11 18:43:06.344572: step 540000, loss = 0.029657, learning_rate = 0.000000 (2564.6 examples/sec)
=> Model saved to file: ./logs_res/model-540000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:43:38.617424: step 540100, loss = 0.025590, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 18:43:58.760177: step 540200, loss = 0.006917, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 18:44:19.769521: step 540300, loss = 0.024270, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 18:44:39.896318: step 540400, loss = 0.025232, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 18:45:00.039741: step 540500, loss = 0.020292, learning_rate = 0.000000 (2563.3 examples/sec)
=> 2021-11-11 18:45:20.192472: step 540600, loss = 0.020157, learning_rate = 0.000000 (2562.2 examples/sec)
=> 2021-11-11 18:45:41.253827: step 540700, loss = 0.010488, learning_rate = 0.000000 (2579.0 examples/sec)
=> 2021-11-11 18:46:01.384833: step 540800, loss = 0.022692, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 18:46:21.511544: step 540900, loss = 0.012012, learning_rate = 0.000000 (2565.1 examples/sec)
=> 2021-11-11 18:46:41.639262: step 541000, loss = 0.028088, learning_rate = 0.000000 (2565.1 examples/sec)
=> Model saved to file: ./logs_res/model-541000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955770, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:47:14.662026: step 541100, loss = 0.046485, learning_rate = 0.000000 (2586.4 examples/sec)
=> 2021-11-11 18:47:34.751707: step 541200, loss = 0.029003, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 18:47:54.865269: step 541300, loss = 0.013315, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 18:48:14.960950: step 541400, loss = 0.008103, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 18:48:35.058095: step 541500, loss = 0.014146, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 18:48:56.033104: step 541600, loss = 0.025391, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-11 18:49:16.134711: step 541700, loss = 0.023059, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 18:49:36.241466: step 541800, loss = 0.028825, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 18:49:56.349929: step 541900, loss = 0.019370, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 18:50:17.320456: step 542000, loss = 0.021615, learning_rate = 0.000000 (2578.8 examples/sec)
=> Model saved to file: ./logs_res/model-542000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:50:49.312977: step 542100, loss = 0.038990, learning_rate = 0.000000 (2572.1 examples/sec)
=> 2021-11-11 18:51:09.400549: step 542200, loss = 0.008631, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 18:51:29.499345: step 542300, loss = 0.024408, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 18:51:50.407358: step 542400, loss = 0.012170, learning_rate = 0.000000 (2585.5 examples/sec)
=> 2021-11-11 18:52:10.523504: step 542500, loss = 0.013678, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 18:52:30.616519: step 542600, loss = 0.011332, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 18:52:50.708982: step 542700, loss = 0.021982, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 18:53:11.670371: step 542800, loss = 0.019846, learning_rate = 0.000000 (2581.7 examples/sec)
=> 2021-11-11 18:53:31.793217: step 542900, loss = 0.033802, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 18:53:51.901777: step 543000, loss = 0.029828, learning_rate = 0.000000 (2567.8 examples/sec)
=> Model saved to file: ./logs_res/model-543000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:54:24.055660: step 543100, loss = 0.025576, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 18:54:44.984949: step 543200, loss = 0.018102, learning_rate = 0.000000 (2584.2 examples/sec)
=> 2021-11-11 18:55:05.104551: step 543300, loss = 0.021121, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 18:55:25.235285: step 543400, loss = 0.019409, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 18:55:45.343058: step 543500, loss = 0.020107, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 18:56:06.358280: step 543600, loss = 0.014566, learning_rate = 0.000000 (2593.0 examples/sec)
=> 2021-11-11 18:56:26.485312: step 543700, loss = 0.020983, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 18:56:46.603588: step 543800, loss = 0.014781, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 18:57:06.741854: step 543900, loss = 0.006137, learning_rate = 0.000000 (2563.8 examples/sec)
=> 2021-11-11 18:57:27.751690: step 544000, loss = 0.014458, learning_rate = 0.000000 (2584.3 examples/sec)
=> Model saved to file: ./logs_res/model-544000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954622, best accuracy 0.955923
=> patience = 99
=> 2021-11-11 18:57:59.945308: step 544100, loss = 0.017219, learning_rate = 0.000000 (2571.4 examples/sec)
=> 2021-11-11 18:58:20.021567: step 544200, loss = 0.013160, learning_rate = 0.000000 (2571.5 examples/sec)
=> 2021-11-11 18:58:40.122764: step 544300, loss = 0.032781, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 18:59:00.225742: step 544400, loss = 0.026682, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 18:59:21.145310: step 544500, loss = 0.015989, learning_rate = 0.000000 (2585.3 examples/sec)
=> 2021-11-11 18:59:41.255685: step 544600, loss = 0.039680, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 19:00:01.399224: step 544700, loss = 0.016987, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 19:00:21.492992: step 544800, loss = 0.018713, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 19:00:42.403772: step 544900, loss = 0.069417, learning_rate = 0.000000 (2586.0 examples/sec)
=> 2021-11-11 19:01:02.510866: step 545000, loss = 0.012487, learning_rate = 0.000000 (2568.1 examples/sec)
=> Model saved to file: ./logs_res/model-545000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.956688, best accuracy 0.955923
=> Model saved to file: ./logs_res/model-545000.pdparams
=> patience = 100
=> 2021-11-11 19:01:35.099183: step 545100, loss = 0.038036, learning_rate = 0.000000 (2573.9 examples/sec)
=> 2021-11-11 19:01:55.201918: step 545200, loss = 0.023244, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 19:02:16.114605: step 545300, loss = 0.029995, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 19:02:36.234079: step 545400, loss = 0.020597, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 19:02:56.354699: step 545500, loss = 0.026823, learning_rate = 0.000000 (2566.1 examples/sec)
=> 2021-11-11 19:03:16.460370: step 545600, loss = 0.023373, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 19:03:37.632882: step 545700, loss = 0.064408, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 19:03:57.741023: step 545800, loss = 0.032628, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 19:04:17.842687: step 545900, loss = 0.020571, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 19:04:37.958981: step 546000, loss = 0.043980, learning_rate = 0.000000 (2566.5 examples/sec)
=> Model saved to file: ./logs_res/model-546000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:05:10.864912: step 546100, loss = 0.016542, learning_rate = 0.000000 (2588.6 examples/sec)
=> 2021-11-11 19:05:30.945948: step 546200, loss = 0.020202, learning_rate = 0.000000 (2570.8 examples/sec)
=> 2021-11-11 19:05:51.036482: step 546300, loss = 0.029622, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 19:06:11.125012: step 546400, loss = 0.052069, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 19:06:32.063878: step 546500, loss = 0.018252, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-11 19:06:52.174148: step 546600, loss = 0.015198, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 19:07:12.363350: step 546700, loss = 0.008443, learning_rate = 0.000000 (2557.4 examples/sec)
=> 2021-11-11 19:07:32.468171: step 546800, loss = 0.014121, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 19:07:53.444329: step 546900, loss = 0.017550, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 19:08:13.535164: step 547000, loss = 0.026900, learning_rate = 0.000000 (2570.3 examples/sec)
=> Model saved to file: ./logs_res/model-547000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:08:45.920838: step 547100, loss = 0.028168, learning_rate = 0.000000 (2572.9 examples/sec)
=> 2021-11-11 19:09:05.992825: step 547200, loss = 0.029712, learning_rate = 0.000000 (2572.3 examples/sec)
=> 2021-11-11 19:09:26.104154: step 547300, loss = 0.015617, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 19:09:47.082873: step 547400, loss = 0.012989, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 19:10:07.189386: step 547500, loss = 0.008593, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 19:10:27.300321: step 547600, loss = 0.028078, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 19:10:47.407888: step 547700, loss = 0.049344, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 19:11:08.528477: step 547800, loss = 0.026304, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 19:11:28.724974: step 547900, loss = 0.023308, learning_rate = 0.000000 (2556.3 examples/sec)
=> 2021-11-11 19:11:48.844640: step 548000, loss = 0.015812, learning_rate = 0.000000 (2566.4 examples/sec)
=> Model saved to file: ./logs_res/model-548000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:12:21.061429: step 548100, loss = 0.007968, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-11 19:12:42.095537: step 548200, loss = 0.034014, learning_rate = 0.000000 (2582.8 examples/sec)
=> 2021-11-11 19:13:02.195850: step 548300, loss = 0.025118, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 19:13:22.302513: step 548400, loss = 0.012303, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 19:13:42.418738: step 548500, loss = 0.023991, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 19:14:03.391282: step 548600, loss = 0.023094, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-11 19:14:23.502108: step 548700, loss = 0.009385, learning_rate = 0.000000 (2567.1 examples/sec)
=> 2021-11-11 19:14:43.619661: step 548800, loss = 0.014212, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 19:15:03.720381: step 548900, loss = 0.026797, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 19:15:24.667996: step 549000, loss = 0.018517, learning_rate = 0.000000 (2584.1 examples/sec)
=> Model saved to file: ./logs_res/model-549000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:15:56.980477: step 549100, loss = 0.021862, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 19:16:17.069453: step 549200, loss = 0.012181, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 19:16:37.164693: step 549300, loss = 0.019934, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 19:16:58.120589: step 549400, loss = 0.027080, learning_rate = 0.000000 (2583.7 examples/sec)
=> 2021-11-11 19:17:18.237367: step 549500, loss = 0.020425, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 19:17:38.339859: step 549600, loss = 0.019600, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 19:17:58.458443: step 549700, loss = 0.026829, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 19:18:19.374273: step 549800, loss = 0.020550, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 19:18:39.466870: step 549900, loss = 0.019405, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 19:18:59.582658: step 550000, loss = 0.021832, learning_rate = 0.000000 (2566.6 examples/sec)
=> Model saved to file: ./logs_res/model-550000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:19:31.447025: step 550100, loss = 0.012137, learning_rate = 0.000000 (2573.9 examples/sec)
=> 2021-11-11 19:19:51.541550: step 550200, loss = 0.038354, learning_rate = 0.000000 (2569.9 examples/sec)
=> 2021-11-11 19:20:12.461779: step 550300, loss = 0.016855, learning_rate = 0.000000 (2584.8 examples/sec)
=> 2021-11-11 19:20:32.579914: step 550400, loss = 0.028144, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 19:20:52.669021: step 550500, loss = 0.023551, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 19:21:12.770667: step 550600, loss = 0.061182, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 19:21:33.713009: step 550700, loss = 0.040798, learning_rate = 0.000000 (2600.3 examples/sec)
=> 2021-11-11 19:21:53.829308: step 550800, loss = 0.049715, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 19:22:13.943677: step 550900, loss = 0.023476, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 19:22:34.051764: step 551000, loss = 0.040657, learning_rate = 0.000000 (2567.7 examples/sec)
=> Model saved to file: ./logs_res/model-551000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:23:06.865189: step 551100, loss = 0.019540, learning_rate = 0.000000 (2584.9 examples/sec)
=> 2021-11-11 19:23:26.967033: step 551200, loss = 0.012132, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 19:23:47.066627: step 551300, loss = 0.025731, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 19:24:07.187594: step 551400, loss = 0.027035, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 19:24:28.390675: step 551500, loss = 0.022630, learning_rate = 0.000000 (2581.5 examples/sec)
=> 2021-11-11 19:24:48.506734: step 551600, loss = 0.013079, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 19:25:08.644573: step 551700, loss = 0.013406, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 19:25:28.785607: step 551800, loss = 0.023684, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 19:25:49.785035: step 551900, loss = 0.017322, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 19:26:09.902988: step 552000, loss = 0.033750, learning_rate = 0.000000 (2566.2 examples/sec)
=> Model saved to file: ./logs_res/model-552000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:26:41.855274: step 552100, loss = 0.019615, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 19:27:01.956308: step 552200, loss = 0.019109, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 19:27:22.918575: step 552300, loss = 0.019530, learning_rate = 0.000000 (2582.5 examples/sec)
=> 2021-11-11 19:27:43.026788: step 552400, loss = 0.047866, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 19:28:03.135978: step 552500, loss = 0.037662, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 19:28:23.254344: step 552600, loss = 0.021684, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 19:28:44.255295: step 552700, loss = 0.052001, learning_rate = 0.000000 (2578.8 examples/sec)
=> 2021-11-11 19:29:04.382463: step 552800, loss = 0.016708, learning_rate = 0.000000 (2565.3 examples/sec)
=> 2021-11-11 19:29:24.533710: step 552900, loss = 0.030287, learning_rate = 0.000000 (2562.3 examples/sec)
=> 2021-11-11 19:29:44.656831: step 553000, loss = 0.024819, learning_rate = 0.000000 (2565.7 examples/sec)
=> Model saved to file: ./logs_res/model-553000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:30:16.965043: step 553100, loss = 0.027914, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-11 19:30:37.932694: step 553200, loss = 0.005640, learning_rate = 0.000000 (2583.6 examples/sec)
=> 2021-11-11 19:30:58.038287: step 553300, loss = 0.021547, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 19:31:18.210763: step 553400, loss = 0.026918, learning_rate = 0.000000 (2559.2 examples/sec)
=> 2021-11-11 19:31:38.326865: step 553500, loss = 0.026035, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 19:31:59.350344: step 553600, loss = 0.015579, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 19:32:19.486099: step 553700, loss = 0.019307, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 19:32:39.616678: step 553800, loss = 0.025004, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 19:32:59.762150: step 553900, loss = 0.045684, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 19:33:20.844829: step 554000, loss = 0.014855, learning_rate = 0.000000 (2578.3 examples/sec)
=> Model saved to file: ./logs_res/model-554000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955846, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:33:52.910782: step 554100, loss = 0.017386, learning_rate = 0.000000 (2567.4 examples/sec)
=> 2021-11-11 19:34:13.036644: step 554200, loss = 0.041276, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 19:34:33.199661: step 554300, loss = 0.013012, learning_rate = 0.000000 (2561.5 examples/sec)
=> 2021-11-11 19:34:54.222348: step 554400, loss = 0.046850, learning_rate = 0.000000 (2580.9 examples/sec)
=> 2021-11-11 19:35:14.489922: step 554500, loss = 0.029217, learning_rate = 0.000000 (2547.5 examples/sec)
=> 2021-11-11 19:35:34.634031: step 554600, loss = 0.017840, learning_rate = 0.000000 (2563.4 examples/sec)
=> 2021-11-11 19:35:54.784039: step 554700, loss = 0.014935, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 19:36:15.826460: step 554800, loss = 0.037052, learning_rate = 0.000000 (2578.0 examples/sec)
=> 2021-11-11 19:36:35.962593: step 554900, loss = 0.030751, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 19:36:56.129362: step 555000, loss = 0.038346, learning_rate = 0.000000 (2560.6 examples/sec)
=> Model saved to file: ./logs_res/model-555000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955387, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:37:28.448213: step 555100, loss = 0.017261, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 19:37:49.564154: step 555200, loss = 0.048743, learning_rate = 0.000000 (2576.2 examples/sec)
=> 2021-11-11 19:38:09.661926: step 555300, loss = 0.034452, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 19:38:29.765235: step 555400, loss = 0.030517, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 19:38:49.878679: step 555500, loss = 0.045909, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 19:39:10.865736: step 555600, loss = 0.007530, learning_rate = 0.000000 (2585.1 examples/sec)
=> 2021-11-11 19:39:30.981716: step 555700, loss = 0.019433, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 19:39:51.110713: step 555800, loss = 0.025565, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 19:40:11.233141: step 555900, loss = 0.013477, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 19:40:31.345777: step 556000, loss = 0.019488, learning_rate = 0.000000 (2567.7 examples/sec)
=> Model saved to file: ./logs_res/model-556000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:41:04.209411: step 556100, loss = 0.020331, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-11 19:41:24.339479: step 556200, loss = 0.027409, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 19:41:44.427665: step 556300, loss = 0.023467, learning_rate = 0.000000 (2570.3 examples/sec)
=> 2021-11-11 19:42:04.551286: step 556400, loss = 0.035882, learning_rate = 0.000000 (2565.7 examples/sec)
=> 2021-11-11 19:42:25.592547: step 556500, loss = 0.015336, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-11 19:42:45.799823: step 556600, loss = 0.031034, learning_rate = 0.000000 (2554.9 examples/sec)
=> 2021-11-11 19:43:05.905767: step 556700, loss = 0.016906, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 19:43:26.010472: step 556800, loss = 0.021609, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 19:43:47.020115: step 556900, loss = 0.010430, learning_rate = 0.000000 (2584.5 examples/sec)
=> 2021-11-11 19:44:07.133912: step 557000, loss = 0.011747, learning_rate = 0.000000 (2566.9 examples/sec)
=> Model saved to file: ./logs_res/model-557000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954622, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:44:39.221567: step 557100, loss = 0.025999, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 19:44:59.351600: step 557200, loss = 0.021197, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 19:45:20.377094: step 557300, loss = 0.023749, learning_rate = 0.000000 (2578.1 examples/sec)
=> 2021-11-11 19:45:40.494055: step 557400, loss = 0.024142, learning_rate = 0.000000 (2566.7 examples/sec)
=> 2021-11-11 19:46:00.617016: step 557500, loss = 0.050326, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 19:46:20.739838: step 557600, loss = 0.028300, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 19:46:41.686990: step 557700, loss = 0.019386, learning_rate = 0.000000 (2588.8 examples/sec)
=> 2021-11-11 19:47:01.844033: step 557800, loss = 0.024679, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 19:47:21.980739: step 557900, loss = 0.034792, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 19:47:42.095650: step 558000, loss = 0.033584, learning_rate = 0.000000 (2566.7 examples/sec)
=> Model saved to file: ./logs_res/model-558000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:48:14.866378: step 558100, loss = 0.034513, learning_rate = 0.000000 (2589.4 examples/sec)
=> 2021-11-11 19:48:34.963408: step 558200, loss = 0.017868, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 19:48:55.080984: step 558300, loss = 0.045899, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 19:49:15.236332: step 558400, loss = 0.016327, learning_rate = 0.000000 (2561.7 examples/sec)
=> 2021-11-11 19:49:36.222104: step 558500, loss = 0.015206, learning_rate = 0.000000 (2580.1 examples/sec)
=> 2021-11-11 19:49:56.348933: step 558600, loss = 0.015494, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 19:50:16.485176: step 558700, loss = 0.020394, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 19:50:36.613012: step 558800, loss = 0.019113, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 19:50:56.742768: step 558900, loss = 0.034712, learning_rate = 0.000000 (2565.2 examples/sec)
=> 2021-11-11 19:51:17.825027: step 559000, loss = 0.023081, learning_rate = 0.000000 (2562.9 examples/sec)
=> Model saved to file: ./logs_res/model-559000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955005, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:51:49.840691: step 559100, loss = 0.008114, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 19:52:09.942402: step 559200, loss = 0.018166, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 19:52:30.049528: step 559300, loss = 0.027594, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 19:52:51.028653: step 559400, loss = 0.043251, learning_rate = 0.000000 (2595.7 examples/sec)
=> 2021-11-11 19:53:11.133893: step 559500, loss = 0.018754, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 19:53:31.252556: step 559600, loss = 0.035893, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 19:53:51.373951: step 559700, loss = 0.054168, learning_rate = 0.000000 (2565.8 examples/sec)
=> 2021-11-11 19:54:12.368471: step 559800, loss = 0.010212, learning_rate = 0.000000 (2580.3 examples/sec)
=> 2021-11-11 19:54:32.541949: step 559900, loss = 0.021379, learning_rate = 0.000000 (2559.4 examples/sec)
=> 2021-11-11 19:54:52.692707: step 560000, loss = 0.015299, learning_rate = 0.000000 (2562.4 examples/sec)
=> Model saved to file: ./logs_res/model-560000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:55:24.730146: step 560100, loss = 0.019907, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 19:55:45.711245: step 560200, loss = 0.011816, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-11 19:56:05.831341: step 560300, loss = 0.019850, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 19:56:25.976572: step 560400, loss = 0.018613, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 19:56:46.112571: step 560500, loss = 0.027164, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 19:57:07.081141: step 560600, loss = 0.027025, learning_rate = 0.000000 (2579.7 examples/sec)
=> 2021-11-11 19:57:27.181691: step 560700, loss = 0.036944, learning_rate = 0.000000 (2568.9 examples/sec)
=> 2021-11-11 19:57:47.318859: step 560800, loss = 0.018415, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 19:58:07.447760: step 560900, loss = 0.033169, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 19:58:28.381396: step 561000, loss = 0.022994, learning_rate = 0.000000 (2583.5 examples/sec)
=> Model saved to file: ./logs_res/model-561000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 19:59:00.439314: step 561100, loss = 0.019658, learning_rate = 0.000000 (2573.4 examples/sec)
=> 2021-11-11 19:59:20.541647: step 561200, loss = 0.015722, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 19:59:40.632102: step 561300, loss = 0.016931, learning_rate = 0.000000 (2569.8 examples/sec)
=> 2021-11-11 20:00:01.572894: step 561400, loss = 0.004217, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 20:00:21.686741: step 561500, loss = 0.014744, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 20:00:41.782620: step 561600, loss = 0.015162, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 20:01:01.891742: step 561700, loss = 0.022932, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 20:01:22.841519: step 561800, loss = 0.015472, learning_rate = 0.000000 (2582.1 examples/sec)
=> 2021-11-11 20:01:42.985318: step 561900, loss = 0.036399, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 20:02:03.112311: step 562000, loss = 0.018053, learning_rate = 0.000000 (2565.9 examples/sec)
=> Model saved to file: ./logs_res/model-562000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 20:02:35.110956: step 562100, loss = 0.018553, learning_rate = 0.000000 (2573.2 examples/sec)
=> 2021-11-11 20:02:55.204747: step 562200, loss = 0.050864, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 20:03:16.247792: step 562300, loss = 0.021028, learning_rate = 0.000000 (2586.5 examples/sec)
=> 2021-11-11 20:03:36.349354: step 562400, loss = 0.021778, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 20:03:56.451508: step 562500, loss = 0.016918, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 20:04:16.561742: step 562600, loss = 0.010897, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 20:04:37.509767: step 562700, loss = 0.012694, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-11 20:04:57.648146: step 562800, loss = 0.014501, learning_rate = 0.000000 (2563.9 examples/sec)
=> 2021-11-11 20:05:17.785779: step 562900, loss = 0.028778, learning_rate = 0.000000 (2564.1 examples/sec)
=> 2021-11-11 20:05:37.926378: step 563000, loss = 0.009906, learning_rate = 0.000000 (2563.5 examples/sec)
=> Model saved to file: ./logs_res/model-563000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 20:06:11.446561: step 563100, loss = 0.022756, learning_rate = 0.000000 (2586.1 examples/sec)
=> 2021-11-11 20:06:31.533353: step 563200, loss = 0.017582, learning_rate = 0.000000 (2570.2 examples/sec)
=> 2021-11-11 20:06:51.643045: step 563300, loss = 0.076094, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 20:07:11.753092: step 563400, loss = 0.014653, learning_rate = 0.000000 (2567.3 examples/sec)
=> 2021-11-11 20:07:32.687647: step 563500, loss = 0.020432, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-11 20:07:52.798601: step 563600, loss = 0.023229, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 20:08:13.004740: step 563700, loss = 0.012861, learning_rate = 0.000000 (2555.1 examples/sec)
=> 2021-11-11 20:08:33.139000: step 563800, loss = 0.024539, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 20:08:54.085094: step 563900, loss = 0.020365, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 20:09:14.225440: step 564000, loss = 0.020629, learning_rate = 0.000000 (2563.3 examples/sec)
=> Model saved to file: ./logs_res/model-564000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 20:09:46.255654: step 564100, loss = 0.028468, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-11 20:10:06.351814: step 564200, loss = 0.017201, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 20:10:27.337747: step 564300, loss = 0.019373, learning_rate = 0.000000 (2582.2 examples/sec)
=> 2021-11-11 20:10:47.452001: step 564400, loss = 0.017719, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 20:11:07.576460: step 564500, loss = 0.025264, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 20:11:27.683125: step 564600, loss = 0.023942, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 20:11:48.762087: step 564700, loss = 0.029404, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 20:12:08.879808: step 564800, loss = 0.006954, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 20:12:29.013396: step 564900, loss = 0.036979, learning_rate = 0.000000 (2564.5 examples/sec)
=> 2021-11-11 20:12:49.133514: step 565000, loss = 0.016474, learning_rate = 0.000000 (2566.0 examples/sec)
=> Model saved to file: ./logs_res/model-565000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.956688
=> patience = 99
=> 2021-11-11 20:13:21.078772: step 565100, loss = 0.022910, learning_rate = 0.000000 (2573.6 examples/sec)
=> 2021-11-11 20:13:42.029714: step 565200, loss = 0.020910, learning_rate = 0.000000 (2583.5 examples/sec)
=> 2021-11-11 20:14:02.138311: step 565300, loss = 0.015801, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 20:14:22.259836: step 565400, loss = 0.013854, learning_rate = 0.000000 (2565.9 examples/sec)
=> 2021-11-11 20:14:42.374493: step 565500, loss = 0.030292, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 20:15:03.313485: step 565600, loss = 0.011742, learning_rate = 0.000000 (2583.9 examples/sec)
=> 2021-11-11 20:15:23.431637: step 565700, loss = 0.020070, learning_rate = 0.000000 (2566.2 examples/sec)
=> 2021-11-11 20:15:43.557157: step 565800, loss = 0.051674, learning_rate = 0.000000 (2565.4 examples/sec)
=> 2021-11-11 20:16:03.679042: step 565900, loss = 0.049492, learning_rate = 0.000000 (2566.0 examples/sec)
=> 2021-11-11 20:16:24.628042: step 566000, loss = 0.016569, learning_rate = 0.000000 (2583.5 examples/sec)
=> Model saved to file: ./logs_res/model-566000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.957147, best accuracy 0.956688
=> Model saved to file: ./logs_res/model-566000.pdparams
=> patience = 100
=> 2021-11-11 20:16:57.278032: step 566100, loss = 0.012326, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-11 20:17:17.359859: step 566200, loss = 0.026934, learning_rate = 0.000000 (2570.9 examples/sec)
=> 2021-11-11 20:17:37.452912: step 566300, loss = 0.043795, learning_rate = 0.000000 (2569.4 examples/sec)
=> 2021-11-11 20:17:58.432317: step 566400, loss = 0.014417, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-11 20:18:18.537487: step 566500, loss = 0.027374, learning_rate = 0.000000 (2568.1 examples/sec)
=> 2021-11-11 20:18:38.647051: step 566600, loss = 0.053105, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 20:18:58.794556: step 566700, loss = 0.021639, learning_rate = 0.000000 (2562.8 examples/sec)
=> 2021-11-11 20:19:19.768341: step 566800, loss = 0.017850, learning_rate = 0.000000 (2579.8 examples/sec)
=> 2021-11-11 20:19:39.884936: step 566900, loss = 0.023640, learning_rate = 0.000000 (2566.5 examples/sec)
=> 2021-11-11 20:20:00.010230: step 567000, loss = 0.016083, learning_rate = 0.000000 (2565.6 examples/sec)
=> Model saved to file: ./logs_res/model-567000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954316, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:20:32.109962: step 567100, loss = 0.021507, learning_rate = 0.000000 (2570.4 examples/sec)
=> 2021-11-11 20:20:53.053611: step 567200, loss = 0.026500, learning_rate = 0.000000 (2583.3 examples/sec)
=> 2021-11-11 20:21:13.149424: step 567300, loss = 0.019708, learning_rate = 0.000000 (2569.3 examples/sec)
=> 2021-11-11 20:21:33.280848: step 567400, loss = 0.022569, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 20:21:53.405195: step 567500, loss = 0.012945, learning_rate = 0.000000 (2565.6 examples/sec)
=> 2021-11-11 20:22:14.362782: step 567600, loss = 0.018131, learning_rate = 0.000000 (2586.6 examples/sec)
=> 2021-11-11 20:22:34.498467: step 567700, loss = 0.010995, learning_rate = 0.000000 (2564.7 examples/sec)
=> 2021-11-11 20:22:54.642075: step 567800, loss = 0.022915, learning_rate = 0.000000 (2563.5 examples/sec)
=> 2021-11-11 20:23:14.788358: step 567900, loss = 0.015491, learning_rate = 0.000000 (2563.0 examples/sec)
=> 2021-11-11 20:23:34.923132: step 568000, loss = 0.027673, learning_rate = 0.000000 (2564.8 examples/sec)
=> Model saved to file: ./logs_res/model-568000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:24:08.141721: step 568100, loss = 0.022505, learning_rate = 0.000000 (2585.8 examples/sec)
=> 2021-11-11 20:24:28.233424: step 568200, loss = 0.024157, learning_rate = 0.000000 (2570.1 examples/sec)
=> 2021-11-11 20:24:48.350034: step 568300, loss = 0.029954, learning_rate = 0.000000 (2566.9 examples/sec)
=> 2021-11-11 20:25:08.451140: step 568400, loss = 0.034913, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 20:25:29.437173: step 568500, loss = 0.014638, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 20:25:49.547857: step 568600, loss = 0.030469, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 20:26:09.664427: step 568700, loss = 0.026124, learning_rate = 0.000000 (2566.6 examples/sec)
=> 2021-11-11 20:26:29.809295: step 568800, loss = 0.016100, learning_rate = 0.000000 (2563.2 examples/sec)
=> 2021-11-11 20:26:50.833747: step 568900, loss = 0.023920, learning_rate = 0.000000 (2585.4 examples/sec)
=> 2021-11-11 20:27:10.946169: step 569000, loss = 0.044377, learning_rate = 0.000000 (2567.1 examples/sec)
=> Model saved to file: ./logs_res/model-569000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:27:43.008601: step 569100, loss = 0.068836, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 20:28:03.104369: step 569200, loss = 0.026280, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 20:28:24.100817: step 569300, loss = 0.059502, learning_rate = 0.000000 (2581.1 examples/sec)
=> 2021-11-11 20:28:44.204457: step 569400, loss = 0.024870, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 20:29:04.315178: step 569500, loss = 0.021210, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 20:29:24.429220: step 569600, loss = 0.017666, learning_rate = 0.000000 (2566.8 examples/sec)
=> 2021-11-11 20:29:45.573953: step 569700, loss = 0.031292, learning_rate = 0.000000 (2574.7 examples/sec)
=> 2021-11-11 20:30:05.678189: step 569800, loss = 0.023627, learning_rate = 0.000000 (2567.9 examples/sec)
=> 2021-11-11 20:30:25.791645: step 569900, loss = 0.026126, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 20:30:45.887362: step 570000, loss = 0.027303, learning_rate = 0.000000 (2569.0 examples/sec)
=> Model saved to file: ./logs_res/model-570000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:31:18.921759: step 570100, loss = 0.012173, learning_rate = 0.000000 (2586.7 examples/sec)
=> 2021-11-11 20:31:39.000453: step 570200, loss = 0.006635, learning_rate = 0.000000 (2571.2 examples/sec)
=> 2021-11-11 20:31:59.096669: step 570300, loss = 0.028138, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 20:32:19.195261: step 570400, loss = 0.024034, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 20:32:40.145571: step 570500, loss = 0.035063, learning_rate = 0.000000 (2589.9 examples/sec)
=> 2021-11-11 20:33:00.242365: step 570600, loss = 0.007286, learning_rate = 0.000000 (2569.7 examples/sec)
=> 2021-11-11 20:33:20.343874: step 570700, loss = 0.024305, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 20:33:40.432336: step 570800, loss = 0.020157, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 20:34:00.531243: step 570900, loss = 0.049434, learning_rate = 0.000000 (2569.6 examples/sec)
=> 2021-11-11 20:34:21.501079: step 571000, loss = 0.017940, learning_rate = 0.000000 (2580.7 examples/sec)
=> Model saved to file: ./logs_res/model-571000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:34:53.444281: step 571100, loss = 0.069629, learning_rate = 0.000000 (2574.4 examples/sec)
=> 2021-11-11 20:35:13.547436: step 571200, loss = 0.013834, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 20:35:33.650782: step 571300, loss = 0.030949, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 20:35:54.590824: step 571400, loss = 0.029151, learning_rate = 0.000000 (2582.9 examples/sec)
=> 2021-11-11 20:36:14.700615: step 571500, loss = 0.015846, learning_rate = 0.000000 (2567.5 examples/sec)
=> 2021-11-11 20:36:34.805474: step 571600, loss = 0.024486, learning_rate = 0.000000 (2568.2 examples/sec)
=> 2021-11-11 20:36:54.897917: step 571700, loss = 0.009655, learning_rate = 0.000000 (2570.0 examples/sec)
=> 2021-11-11 20:37:15.925459: step 571800, loss = 0.053151, learning_rate = 0.000000 (2582.3 examples/sec)
=> 2021-11-11 20:37:36.031931: step 571900, loss = 0.024747, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 20:37:56.145139: step 572000, loss = 0.009731, learning_rate = 0.000000 (2567.1 examples/sec)
=> Model saved to file: ./logs_res/model-572000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955234, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:38:28.216700: step 572100, loss = 0.033138, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 20:38:49.186882: step 572200, loss = 0.022421, learning_rate = 0.000000 (2584.6 examples/sec)
=> 2021-11-11 20:39:09.298261: step 572300, loss = 0.028068, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 20:39:29.436714: step 572400, loss = 0.025698, learning_rate = 0.000000 (2564.0 examples/sec)
=> 2021-11-11 20:39:49.561564: step 572500, loss = 0.030696, learning_rate = 0.000000 (2565.5 examples/sec)
=> 2021-11-11 20:40:10.579214: step 572600, loss = 0.008688, learning_rate = 0.000000 (2583.2 examples/sec)
=> 2021-11-11 20:40:30.690834: step 572700, loss = 0.021571, learning_rate = 0.000000 (2567.2 examples/sec)
=> 2021-11-11 20:40:50.786118: step 572800, loss = 0.023081, learning_rate = 0.000000 (2569.2 examples/sec)
=> 2021-11-11 20:41:10.883294: step 572900, loss = 0.012605, learning_rate = 0.000000 (2569.0 examples/sec)
=> 2021-11-11 20:41:31.867608: step 573000, loss = 0.015847, learning_rate = 0.000000 (2584.5 examples/sec)
=> Model saved to file: ./logs_res/model-573000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954163, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:42:03.863589: step 573100, loss = 0.022659, learning_rate = 0.000000 (2571.7 examples/sec)
=> 2021-11-11 20:42:23.959316: step 573200, loss = 0.055297, learning_rate = 0.000000 (2569.5 examples/sec)
=> 2021-11-11 20:42:44.062114: step 573300, loss = 0.020357, learning_rate = 0.000000 (2568.7 examples/sec)
=> 2021-11-11 20:43:05.067017: step 573400, loss = 0.014658, learning_rate = 0.000000 (2585.0 examples/sec)
=> 2021-11-11 20:43:25.168685: step 573500, loss = 0.029542, learning_rate = 0.000000 (2568.6 examples/sec)
=> 2021-11-11 20:43:45.273864: step 573600, loss = 0.016563, learning_rate = 0.000000 (2568.0 examples/sec)
=> 2021-11-11 20:44:05.375296: step 573700, loss = 0.016541, learning_rate = 0.000000 (2568.5 examples/sec)
=> 2021-11-11 20:44:25.481097: step 573800, loss = 0.010142, learning_rate = 0.000000 (2568.4 examples/sec)
=> 2021-11-11 20:44:46.543083: step 573900, loss = 0.023332, learning_rate = 0.000000 (2583.8 examples/sec)
=> 2021-11-11 20:45:06.644130: step 574000, loss = 0.024066, learning_rate = 0.000000 (2568.6 examples/sec)
=> Model saved to file: ./logs_res/model-574000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:45:38.532593: step 574100, loss = 0.024094, learning_rate = 0.000000 (2572.0 examples/sec)
=> 2021-11-11 20:45:58.615158: step 574200, loss = 0.046247, learning_rate = 0.000000 (2571.1 examples/sec)
=> 2021-11-11 20:46:19.529448: step 574300, loss = 0.015577, learning_rate = 0.000000 (2587.4 examples/sec)
=> 2021-11-11 20:46:39.637592: step 574400, loss = 0.026993, learning_rate = 0.000000 (2567.6 examples/sec)
=> 2021-11-11 20:46:59.756642: step 574500, loss = 0.060997, learning_rate = 0.000000 (2566.4 examples/sec)
=> 2021-11-11 20:47:19.887748: step 574600, loss = 0.014704, learning_rate = 0.000000 (2564.6 examples/sec)
=> 2021-11-11 20:47:41.052093: step 574700, loss = 0.034010, learning_rate = 0.000000 (2582.6 examples/sec)
=> 2021-11-11 20:48:01.213461: step 574800, loss = 0.015657, learning_rate = 0.000000 (2560.9 examples/sec)
=> 2021-11-11 20:48:21.320442: step 574900, loss = 0.021513, learning_rate = 0.000000 (2567.8 examples/sec)
=> 2021-11-11 20:48:41.431168: step 575000, loss = 0.045103, learning_rate = 0.000000 (2567.3 examples/sec)
=> Model saved to file: ./logs_res/model-575000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:49:14.167797: step 575100, loss = 0.022692, learning_rate = 0.000000 (2589.8 examples/sec)
=> 2021-11-11 20:49:34.270320: step 575200, loss = 0.027207, learning_rate = 0.000000 (2568.3 examples/sec)
=> 2021-11-11 20:49:54.368732: step 575300, loss = 0.008515, learning_rate = 0.000000 (2568.8 examples/sec)
=> 2021-11-11 20:50:14.476246: step 575400, loss = 0.021457, learning_rate = 0.000000 (2567.7 examples/sec)
=> 2021-11-11 20:50:35.444061: step 575500, loss = 0.020767, learning_rate = 0.000000 (2581.8 examples/sec)
=> 2021-11-11 20:50:55.557102: step 575600, loss = 0.020147, learning_rate = 0.000000 (2567.0 examples/sec)
=> 2021-11-11 20:51:15.686093: step 575700, loss = 0.010874, learning_rate = 0.000000 (2565.0 examples/sec)
=> 2021-11-11 20:51:35.831890: step 575800, loss = 0.038024, learning_rate = 0.000000 (2562.7 examples/sec)
=> 2021-11-11 20:51:56.866004: step 575900, loss = 0.016688, learning_rate = 0.000000 (2578.4 examples/sec)
=> 2021-11-11 20:52:16.990397: step 576000, loss = 0.011268, learning_rate = 0.000000 (2565.6 examples/sec)
=> Model saved to file: ./logs_res/model-576000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.957147
=> patience = 99
=> 2021-11-11 20:52:49.723475: step 576100, loss = 0.012846, learning_rate = 0.000000 (2538.9 examples/sec)
=> 2021-11-11 20:53:13.668982: step 576200, loss = 0.053414, learning_rate = 0.000000 (2155.6 examples/sec)
=> 2021-11-11 20:53:39.502312: step 576300, loss = 0.011967, learning_rate = 0.000000 (2087.3 examples/sec)
=> 2021-11-11 20:54:04.364307: step 576400, loss = 0.035410, learning_rate = 0.000000 (2075.6 examples/sec)
=> 2021-11-11 20:54:27.379298: step 576500, loss = 0.024235, learning_rate = 0.000000 (2243.9 examples/sec)
=> 2021-11-11 20:54:47.515390: step 576600, loss = 0.015154, learning_rate = 0.000000 (2564.2 examples/sec)
=> 2021-11-11 20:55:07.673160: step 576700, loss = 0.021191, learning_rate = 0.000000 (2562.1 examples/sec)
=> 2021-11-11 20:55:28.744533: step 576800, loss = 0.041986, learning_rate = 0.000000 (2578.6 examples/sec)
=> 2021-11-11 20:55:48.886593: step 576900, loss = 0.053736, learning_rate = 0.000000 (2563.1 examples/sec)
=> 2021-11-11 20:56:09.019032: step 577000, loss = 0.025185, learning_rate = 0.000000 (2564.4 examples/sec)
=> Model saved to file: ./logs_res/model-577000.pdparams
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954545, best accuracy 0.957147

